{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f19032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from  matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "rc('text',usetex=True)\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from yadlt.model import load_trained_model, compute_ntk_static\n",
    "from yadlt.distribution import Distribution\n",
    "from yadlt import load_data\n",
    "from yadlt.context import FitContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85aee2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitname = \"250604-ac-01-L0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad4a2d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extension for the weights file\n",
    "WEIGHTS_TOKEN = 'weights.h5'\n",
    "def select_weight(epoch: int):\n",
    "  return f\"epoch_{int(epoch)}.{WEIGHTS_TOKEN}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2172b4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load context\n",
    "context = FitContext(fitname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8d799cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder for the serialization\n",
    "SERIALIZATION_FOLDER = context.fit_folder / \"serialization\"\n",
    "SERIALIZATION_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Path to plot folder\n",
    "PLOT_FOLDER = context.fit_folder / \"plots\"\n",
    "PLOT_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SAVE_PLOT = True\n",
    "SAVE_NB = False\n",
    "\n",
    "# Plot error bars instead of lines\n",
    "PLOT_ERROR_BARS = True\n",
    "\n",
    "# Force serialization\n",
    "FORCE_SERIALIZATION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e835cb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tommaso's file\n",
    "fk_grid = load_data.load_bcdms_grid()\n",
    "FK = load_data.load_bcdms_fk()\n",
    "f_bcdms = load_data.load_bcdms_pdf()\n",
    "Cy = load_data.load_bcdms_cov()\n",
    "Cinv = np.linalg.inv(Cy)\n",
    "\n",
    "# Compute M\n",
    "M = FK.T @ Cinv @ FK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f290eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get learning rate from config file\n",
    "import yaml\n",
    "try:\n",
    "  with open(FIT_FOLDER / 'metadata.yaml', 'r') as f:\n",
    "    metadata = yaml.safe_load(f)\n",
    "    learning_rate = metadata['arguments']['learning_rate']\n",
    "\n",
    "except FileNotFoundError:\n",
    "  print(\"Metadata file not found. Using default learning rate.\")\n",
    "  learning_rate = 1.e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1ce35d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract replicas from the fit folder\n",
    "replicas_folders = [f for f in FIT_FOLDER.iterdir() if f.is_dir() and 'replica' in str(f)]\n",
    "replicas_folders.sort()\n",
    "replicas = len(replicas_folders)\n",
    "\n",
    "# For each replicas, load the epochs and data\n",
    "replica_epochs_dict = {}\n",
    "for replica_folder in replicas_folders:\n",
    "  epochs = [f for f in replica_folder.iterdir() if f.is_file() and WEIGHTS_TOKEN in str(f)]\n",
    "  epochs.sort()\n",
    "  replica_epochs_dict[replica_folder.name] = epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d12f83cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common epochs: [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000]\n"
     ]
    }
   ],
   "source": [
    "# Find common epochs\n",
    "# Different replicas may have different epochs, so we need to find the common ones\n",
    "common_epochs = set()\n",
    "for replica, epochs in replica_epochs_dict.items():\n",
    "  aux = set()\n",
    "  for epoch in epochs:\n",
    "    epoch_num = int(epoch.name.split('.')[0].split('_')[1])\n",
    "    aux.add(epoch_num)\n",
    "  \n",
    "  if len(common_epochs) == 0:\n",
    "    common_epochs = aux\n",
    "  else:\n",
    "    common_epochs.intersection_update(aux)\n",
    "\n",
    "common_epochs = sorted(list(common_epochs))\n",
    "print(f\"Common epochs: {common_epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bd3e0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1 replicas...\tDone!\n"
     ]
    }
   ],
   "source": [
    "# Extract the last common epoch from the ensemble of replicas\n",
    "xT3_training = Distribution('xT3_training')\n",
    "print(f'Loading {len(replicas_folders)} replicas...', end='\\t')\n",
    "for replica_path in replicas_folders:\n",
    "    model,_ = load_trained_model(replica_path, epoch=common_epochs[-1])\n",
    "    preds = model(fk_grid.reshape(1, -1, 1)).numpy().squeeze()\n",
    "    xT3_training.add(preds)\n",
    "print('Done!')\n",
    "\n",
    "# Compute T3 from xT3\n",
    "T3_training = xT3_training.apply_operator(b=fk_grid, operator=lambda a, b: np.true_divide(a, b), axis=0, name=f'T3 at the end of the training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec1edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data used to fit the replicas\n",
    "data_by_replica_original = Distribution(\"Original replicas of the data\")\n",
    "\n",
    "for rep in range(replicas):\n",
    "  data = np.load(FIT_FOLDER / f'replica_{rep+1}' / 'data.npy')\n",
    "  data_by_replica_original.add(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3b8540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ensemble of xT3 at the end of the training\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(fk_grid, xT3_training.get_mean(), label='Mean')\n",
    "plt.fill_between(fk_grid, xT3_training.get_mean() - xT3_training.get_std(), xT3_training.get_mean() + xT3_training.get_std(), alpha=0.5)\n",
    "plt.plot(fk_grid, f_bcdms, label='True function')\n",
    "plt.xlabel(r'$x$', fontsize=14)\n",
    "plt.ylabel(r'$xT_3$', fontsize=14)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "if SAVE_PLOT:\n",
    "  plt.savefig(PLOT_FOLDER / 'pdf_mean_std.png', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb479a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one model structure to use for NTK computation\n",
    "dummy_model = PDFmodel.load_model(replicas_folders[0] / 'config.json', replicas_folders[0] / select_weight(0)).model\n",
    "\n",
    "# Calling the model with a dummy input makes sure the model is built\n",
    "# Not sure this is strictly necessary, but it is a good practice\n",
    "_ = dummy_model(tf.convert_to_tensor(fk_grid.reshape(-1, 1)))\n",
    "\n",
    "def process_replica_by_epoch(replica_path: Path, epoch: int, tol=1e-7):\n",
    "    \"\"\"\n",
    "    Process a single replica for a given epoch,\n",
    "    \"\"\"\n",
    "    # Compute the NTK for the current replica and epoch\n",
    "    dummy_model.load_weights(replica_path / select_weight(epoch))\n",
    "    NTK = compute_ntk_static(tf.convert_to_tensor(fk_grid.reshape(-1, 1)), dummy_model, outputs=1)\n",
    "\n",
    "    size = NTK.shape[0]\n",
    "\n",
    "    # Compute eigenvalues and eigenvectors of the NTK\n",
    "    Z, eigenvalues, ZrT = np.linalg.svd(NTK, hermitian=True)\n",
    "\n",
    "    # Compute frobenius norm\n",
    "    frob_norm = np.sqrt(np.sum([s**2 for s in eigenvalues]))\n",
    "\n",
    "    # Split the NTK space\n",
    "    # rtol = tol * eigenvalues.max()\n",
    "    # perp_mask = eigenvalues > rtol\n",
    "    # parallel_mask = ~perp_mask\n",
    "\n",
    "    for idx in range(len(eigenvalues)):\n",
    "      if not np.allclose(Z[:,idx], ZrT.T[:,idx]):\n",
    "        cut = idx\n",
    "        break\n",
    "    \n",
    "    for i in range(cut, 0, -1):\n",
    "        if eigenvalues[i] / eigenvalues[0] > 1.e-7:\n",
    "            cut = np.int64(i + 1)\n",
    "            break\n",
    "               \n",
    "\n",
    "    perp_mask = [True] * cut + [False] * (size - cut)\n",
    "    parallel_mask = ~np.array(perp_mask)\n",
    "\n",
    "    Lambda_perp  = eigenvalues[perp_mask]\n",
    "    Z_perp = Z[:, perp_mask]\n",
    "    Z_parallel = Z[:, parallel_mask]\n",
    "\n",
    "    # Parallel projector\n",
    "    P_parallel = np.empty((size, size))\n",
    "    P_perp = np.empty((size, size))\n",
    "    P_parallel = np.dot(Z_parallel, Z_parallel.T)\n",
    "    P_perp = np.dot(Z_perp, Z_perp.T)\n",
    "\n",
    "    # Compute similarity transformation\n",
    "    Lambda_perp_sqrt = np.sqrt(Lambda_perp)\n",
    "    Lambda_perp_sqrt_inv = 1.0 / Lambda_perp_sqrt\n",
    "    P = np.diag(Lambda_perp_sqrt_inv) @ Z_perp.T\n",
    "    P_inv = Z_perp @ np.diag(Lambda_perp_sqrt)\n",
    "\n",
    "    # Symmetric operator\n",
    "    H_perp = np.diag(Lambda_perp_sqrt) @ Z_perp.T @ M @ Z_perp @ np.diag(Lambda_perp_sqrt)\n",
    "\n",
    "    # Eigendecomposition of H_perp\n",
    "    h, W = np.linalg.eigh(H_perp)\n",
    "    # Sort eigenvalues and eigenvectors in descending order\n",
    "    idx = np.argsort(h)[::-1]\n",
    "    h, W = h[idx], W[:, idx]\n",
    "\n",
    "    hinv = 1 / h\n",
    "\n",
    "    # Compute Q and its inverse\n",
    "    Q = P_inv @ W\n",
    "    Qinv = W.T @ P\n",
    "\n",
    "    # Pad quantities to ensure they are square matrices\n",
    "    Q = np.pad(Q, ((0, 0), (0, Q.shape[0] - Q.shape[1])), mode='constant', constant_values=0)\n",
    "    Qinv = np.pad(Qinv, ((0, Qinv.shape[1] - Qinv.shape[0]), (0, 0)), mode='constant', constant_values=0)\n",
    "    hinv = np.pad(hinv, (0, Q.shape[0] - hinv.shape[0]), mode='constant', constant_values=0)\n",
    "    h = np.pad(h, (0, Q.shape[0] - h.shape[0]), mode='constant', constant_values=0)\n",
    "\n",
    "    return {\n",
    "        'NTK': NTK,\n",
    "        'Z': Z,\n",
    "        'frob_norm': frob_norm,\n",
    "        'eigenvalues': eigenvalues,\n",
    "        'P_parallel': P_parallel,\n",
    "        'P_perp': P_perp,\n",
    "        'Q': Q,\n",
    "        'Qinv': Qinv,\n",
    "        'h': h,\n",
    "        'hinv': hinv,\n",
    "        'cut': cut\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea9ca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularise using go kernel\n",
    "sigma = 0.6\n",
    "l0 = 5.0\n",
    "delta = 1.e-5\n",
    "\n",
    "def gibbs_fn(i1, i2):\n",
    "  x1 = fk_grid[i1]\n",
    "  x2 = fk_grid[i2]\n",
    "  def l(x):\n",
    "    return l0 * (x + delta)\n",
    "  \n",
    "  return x1 * x2 * sigma**2 * np.sqrt( 2 * l(x1) * l(x2) / ( np.power(l(x1),2) + np.power(l(x2),2) ) ) * np.exp(- np.power(x1 - x2, 2) / (np.power(l(x1), 2) + np.power(l(x2), 2)))\n",
    "\n",
    "gp_kernel =  np.fromfunction(gibbs_fn, (fk_grid.size, fk_grid.size), dtype=int)\n",
    "\n",
    "gp_kernel_inv = np.linalg.inv(gp_kernel)\n",
    "\n",
    "M_gibbs = M + gp_kernel_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deb3c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(20, 10))\n",
    "from matplotlib import cm\n",
    "from matplotlib import colors as mcolors\n",
    "\n",
    "matrixplot = axs.matshow(\n",
    "    gp_kernel,\n",
    "    cmap=cm.Spectral_r,\n",
    "    norm=mcolors.SymLogNorm(\n",
    "        linthresh=0.00001, linscale=1, vmin=gp_kernel.min(), vmax=gp_kernel.max()\n",
    "    ),\n",
    ")\n",
    "cbar = fig.colorbar(matrixplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ac40c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect NTK data and other quantities over time\n",
    "#TODO Maybe I serialize too many quantities, I should only keep the ones I need\n",
    "#TODO This is too much of a boilerplate, I should refactor this code to avoid repetition\n",
    "#TODO This process can be parallelized\n",
    "\n",
    "# Tolerance for NTK splitting\n",
    "#tol = 0.001 # Tolerance for zero eigenvalues\n",
    "\n",
    "if not any(SERIALIZATION_FOLDER.iterdir()) or FORCE_SERIALIZATION:\n",
    "  print('Data have not been serialized. Serializing now...')\n",
    "  NTK_time = [Distribution(name=f'NTK at epoch {epoch}', size=replicas, shape=(fk_grid.size, fk_grid.size,)) for epoch in common_epochs]\n",
    "  frob_norm_time = [Distribution(name=f'Frobenius norm at epoch {epoch}', size=replicas, shape=()) for epoch in common_epochs]\n",
    "  eigvals_time = [Distribution(name=f'Eigenvalues of the NTK at epoch {epoch}', size=replicas, shape=(fk_grid.size,)) for epoch in common_epochs]\n",
    "  eigvecs_time = [Distribution(name=f'Eigenvectors of the NTK at epoch {epoch}', size=replicas, shape=(fk_grid.size, fk_grid.size)) for epoch in common_epochs]\n",
    "\n",
    "  P_parallel_by_epoch = [Distribution(name=f'P at parallel epoch {epoch}', size=replicas, shape=(fk_grid.size, fk_grid.size,)) for epoch in common_epochs]\n",
    "  P_perp_by_epoch = [Distribution(name=f'P at perpendicular epoch {epoch}', size=replicas, shape=(fk_grid.size, fk_grid.size,)) for epoch in common_epochs]\n",
    "\n",
    "  Q_by_epoch = [Distribution(name=f'Q at epoch {epoch}', size=replicas, shape=(fk_grid.size, fk_grid.size,)) for epoch in common_epochs]\n",
    "  Qinv_by_epoch = [Distribution(name=f'Q inv. at epoch {epoch}', size=replicas, shape=(fk_grid.size, fk_grid.size,)) for epoch in common_epochs]\n",
    "  h_by_epoch = [Distribution(name=f'h at epoch {epoch}', size=replicas, shape=(fk_grid.size,)) for epoch in common_epochs]\n",
    "  hinv_by_epoch = [Distribution(name=f'h at epoch {epoch}', size=replicas, shape=(fk_grid.size,)) for epoch in common_epochs]\n",
    "  cut_by_epoch = [Distribution(name=f'cut at epoch {epoch}', size=replicas, shape=()) for epoch in common_epochs]\n",
    "\n",
    "  for epoch in common_epochs:\n",
    "    print(f\"Epoch {epoch} / {common_epochs[-1]}\")\n",
    "\n",
    "    # Loop over each replica\n",
    "    for replica_path in replicas_folders:\n",
    "      \n",
    "      result = process_replica_by_epoch(replica_path, epoch)\n",
    "\n",
    "      NTK_time[common_epochs.index(epoch)].add(result['NTK'])\n",
    "      frob_norm_time[common_epochs.index(epoch)].add(result['frob_norm'])\n",
    "      eigvals_time[common_epochs.index(epoch)].add(result['eigenvalues'])\n",
    "      eigvecs_time[common_epochs.index(epoch)].add(result['Z'])\n",
    "\n",
    "      P_parallel_by_epoch[common_epochs.index(epoch)].add(result['P_parallel'])\n",
    "      P_perp_by_epoch[common_epochs.index(epoch)].add(result['P_perp'])\n",
    "\n",
    "      h_by_epoch[common_epochs.index(epoch)].add(result['h'])\n",
    "      hinv_by_epoch[common_epochs.index(epoch)].add(result['hinv'])\n",
    "      Q_by_epoch[common_epochs.index(epoch)].add(result['Q'])\n",
    "      Qinv_by_epoch[common_epochs.index(epoch)].add(result['Qinv'])\n",
    "      cut_by_epoch[common_epochs.index(epoch)].add(result['cut'])\n",
    "\n",
    "\n",
    "  pickle.dump(NTK_time, open(SERIALIZATION_FOLDER / 'NTK_time.pickle', 'wb'))\n",
    "  pickle.dump(frob_norm_time, open(SERIALIZATION_FOLDER / 'frob_norm_time.pickle', 'wb'))\n",
    "  pickle.dump(eigvals_time, open(SERIALIZATION_FOLDER / 'eigvals_time.pickle', 'wb'))\n",
    "  pickle.dump(eigvecs_time, open(SERIALIZATION_FOLDER / 'eigvecs_time.pickle', 'wb'))\n",
    "  pickle.dump(Q_by_epoch, open(SERIALIZATION_FOLDER / 'Q_by_epoch.pickle', 'wb'))\n",
    "  pickle.dump(Qinv_by_epoch, open(SERIALIZATION_FOLDER / 'Qinv_by_epoch.pickle', 'wb'))\n",
    "  pickle.dump(h_by_epoch, open(SERIALIZATION_FOLDER / 'h_by_epoch.pickle', 'wb'))\n",
    "  pickle.dump(hinv_by_epoch, open(SERIALIZATION_FOLDER / 'hinv_by_epoch.pickle', 'wb'))\n",
    "  pickle.dump(P_parallel_by_epoch, open(SERIALIZATION_FOLDER / 'P_parallel_by_epoch.pickle', 'wb'))\n",
    "  pickle.dump(P_perp_by_epoch, open(SERIALIZATION_FOLDER / 'P_perp_by_epoch.pickle', 'wb'))\n",
    "  pickle.dump(cut_by_epoch, open(SERIALIZATION_FOLDER / 'cut.pickle', 'wb'))\n",
    "  pickle.dump(common_epochs, open(SERIALIZATION_FOLDER / 'common_epochs.pickle', 'wb'))\n",
    "else:\n",
    "  print('Data have already been serialized. Loading from disk...')\n",
    "  NTK_time = pickle.load(open(SERIALIZATION_FOLDER / 'NTK_time.pickle', 'rb'))\n",
    "  frob_norm_time = pickle.load(open(SERIALIZATION_FOLDER / 'frob_norm_time.pickle', 'rb'))\n",
    "  eigvals_time = pickle.load(open(SERIALIZATION_FOLDER / 'eigvals_time.pickle', 'rb'))\n",
    "  eigvecs_time = pickle.load(open(SERIALIZATION_FOLDER / 'eigvecs_time.pickle', 'rb'))\n",
    "  Q_by_epoch = pickle.load(open(SERIALIZATION_FOLDER / 'Q_by_epoch.pickle', 'rb'))\n",
    "  Qinv_by_epoch = pickle.load(open(SERIALIZATION_FOLDER / 'Qinv_by_epoch.pickle', 'rb'))\n",
    "  h_by_epoch = pickle.load(open(SERIALIZATION_FOLDER / 'h_by_epoch.pickle', 'rb'))\n",
    "  hinv_by_epoch = pickle.load(open(SERIALIZATION_FOLDER / 'hinv_by_epoch.pickle', 'rb'))\n",
    "  P_parallel_by_epoch = pickle.load(open(SERIALIZATION_FOLDER / 'P_parallel_by_epoch.pickle', 'rb'))\n",
    "  P_perp_by_epoch = pickle.load(open(SERIALIZATION_FOLDER / 'P_perp_by_epoch.pickle', 'rb'))\n",
    "  cut_by_epoch = pickle.load(open(SERIALIZATION_FOLDER / 'cut.pickle', 'rb'))\n",
    "  print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5085946",
   "metadata": {},
   "source": [
    "# Norm of the NTK over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340644b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_NAME = \"ntk_norms\"\n",
    "SAVEDIR = PLOT_FOLDER / FOLDER_NAME\n",
    "SAVEDIR.mkdir(parents=False, exist_ok=True)\n",
    "\n",
    "frob_means = np.array([frob.get_mean().squeeze() for frob in frob_norm_time])\n",
    "frob_stds = np.array([frob.get_std().squeeze() for frob in frob_norm_time])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "if PLOT_ERROR_BARS:\n",
    "  ax.errorbar(common_epochs, frob_means, yerr=frob_stds, label=r'$\\textrm{Frob. norm NTK}$', fmt='o', capsize=5)\n",
    "else:\n",
    "  ax.plot(common_epochs, frob_means, label=r'$\\textrm{Frob. norm NTK}$')\n",
    "  ax.fill_between(common_epochs, frob_means - frob_stds, frob_means + frob_stds, alpha=0.5)\n",
    "  \n",
    "ax.set_xlabel(r'${\\rm Epoch}$', fontsize=16)\n",
    "ax.set_ylabel(r'$\\textrm{Frob. norm NTK}$', fontsize=16)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "if SAVE_PLOT:\n",
    "  fig.savefig(SAVEDIR / \"NTK_norm.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce949f47",
   "metadata": {},
   "source": [
    "# Change in the NTK over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e704c8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_NAME = \"delta_ntk\"\n",
    "SAVEDIR = PLOT_FOLDER / FOLDER_NAME\n",
    "SAVEDIR.mkdir(parents=False, exist_ok=True)\n",
    "\n",
    "# Compute  \\Delta\\Theta_t = || \\Theta_{t+1} - \\Theta_t}||\n",
    "Delta_ntk_t = []\n",
    "for i in range(len(NTK_time) - 1):\n",
    "  delta_ntk_dist = Distribution(f'Delta NTK {i}')\n",
    "  for rep in range(replicas):\n",
    "    delta_ntk = np.linalg.norm(NTK_time[i + 1][rep] - NTK_time[i][rep])\n",
    "    delta_ntk_dist.add(delta_ntk)\n",
    "  Delta_ntk_t.append(delta_ntk_dist)\n",
    "\n",
    "delta_ntk_means = np.array([delta.get_mean() for delta in Delta_ntk_t])\n",
    "delta_ntk_stds = np.array([delta.get_std() for delta in Delta_ntk_t])\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10), gridspec_kw={'hspace': 0.1, 'wspace': 0.1})\n",
    "\n",
    "if PLOT_ERROR_BARS:\n",
    "  axs[0].errorbar(common_epochs[1:], delta_ntk_means, yerr=delta_ntk_stds, label=r'$\\Delta \\Theta_t$', fmt='o', capsize=5)\n",
    "  axs[1].errorbar(common_epochs[1:], delta_ntk_means, yerr=delta_ntk_stds, label=r'$\\Delta \\Theta_t$', fmt='o', capsize=5)\n",
    "else:\n",
    "  axs[0].plot(common_epochs[1:], delta_ntk_means, label=r'$\\Delta \\Theta_t$')\n",
    "  axs[0].fill_between(common_epochs[1:], delta_ntk_means - delta_ntk_stds, delta_ntk_means + delta_ntk_stds, alpha=0.5)\n",
    "  \n",
    "  axs[1].plot(common_epochs[1:], delta_ntk_means, label=r'$\\Delta \\Theta_t$')\n",
    "  axs[1].fill_between(common_epochs[1:], delta_ntk_means - delta_ntk_stds, delta_ntk_means + delta_ntk_stds, alpha=0.5)\n",
    "\n",
    "\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel(r'$\\Delta \\Theta_t$', fontsize=16)\n",
    "axs[0].set_xmargin(0.02)\n",
    "\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].set_ylabel(r'$\\Delta \\Theta_t$', fontsize=16)\n",
    "axs[1].set_xmargin(0.02)\n",
    "\n",
    "fig.suptitle(r'$\\Delta \\Theta_t = || \\Theta_{t+1} - \\Theta_{t}||$', fontsize=20, y=0.95)\n",
    "if SAVE_PLOT:\n",
    "  fig.savefig(SAVEDIR / 'delta_ntk.pdf', dpi=300)\n",
    "\n",
    "  # Save plot separately\n",
    "  extent_lin = axs[0].get_tightbbox(fig.canvas.get_renderer())\n",
    "  extent_log = axs[1].get_tightbbox(fig.canvas.get_renderer())\n",
    "  \n",
    "  fig.savefig(\n",
    "    SAVEDIR / \"delta_ntk_lin.pdf\", dpi=300,\n",
    "    bbox_inches=extent_lin.transformed(fig.dpi_scale_trans.inverted()).padded(0.15)\n",
    "  )\n",
    "\n",
    "  fig.savefig(\n",
    "    SAVEDIR / \"delta_ntk_log.pdf\", dpi=300,\n",
    "    bbox_inches=extent_log.transformed(fig.dpi_scale_trans.inverted()).padded(0.15)\n",
    "  )\n",
    "\n",
    "del delta_ntk_means\n",
    "del delta_ntk_stds\n",
    "del Delta_ntk_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1944e92c",
   "metadata": {},
   "source": [
    "# Plot of the eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3df26e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_NAME = \"ntk_eigenvalues\"\n",
    "SAVEDIR = PLOT_FOLDER / FOLDER_NAME\n",
    "SAVEDIR.mkdir(parents=False, exist_ok=True)\n",
    "\n",
    "eigvals_mean = np.array([eigvals.get_mean(axis=0) for eigvals in eigvals_time])\n",
    "eigvals_std = np.array([eigvals.get_std(axis=0) for eigvals in eigvals_time])\n",
    "\n",
    "num_eigvals_to_plot = 5  # Number of eigenvalues to plot\n",
    "\n",
    "for i in range(num_eigvals_to_plot):\n",
    "\n",
    "  fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "  if PLOT_ERROR_BARS:\n",
    "    ax.errorbar(common_epochs, eigvals_mean[:,i], yerr=eigvals_std[:,i], fmt='o', label=r'$\\lambda^{(' + str(i+1) + ')}$', capsize=5, elinewidth=1, markeredgewidth=1)\n",
    "  else:\n",
    "    ax.plot(common_epochs, eigvals_mean[:,i], label=r'$\\lambda^{(' + str(i+1) + ')}$')\n",
    "    ax.fill_between(common_epochs, eigvals_mean[:,i] - eigvals_std[:,i], eigvals_mean[:,i] + eigvals_std[:,i], alpha=0.5)\n",
    "\n",
    "  ax.set_xlabel(r'${\\rm Epoch}$', fontsize=16)\n",
    "  ax.set_ylabel(r'$\\lambda^{(' + str(i+1) + ')}(t)$', fontsize=16)\n",
    "  ax.legend()\n",
    "\n",
    "  if SAVE_PLOT:\n",
    "    fig.savefig(SAVEDIR / f\"eigval_{i+1}.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64402c05",
   "metadata": {},
   "source": [
    "# Plot the error in function of the epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e1f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_NAME = \"ntk_errors\"\n",
    "SAVEDIR = PLOT_FOLDER / FOLDER_NAME\n",
    "SAVEDIR.mkdir(parents=False, exist_ok=True)\n",
    "\n",
    "num_eigvals_to_plot = 3  # Number of eigenvalues to plot\n",
    "\n",
    "point_markers = ['o', 's', '^', 'D', 'x']  # Different markers for each eigenvalue\n",
    "\n",
    "fig_glob, ax_glob = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "for i in range(num_eigvals_to_plot):\n",
    "\n",
    "  fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "  ax.scatter(common_epochs, eigvals_std[:,i] / eigvals_mean[:,i], label=r'$\\delta_{\\lambda^{(' + str(i+1) + ')}}$', s=15)\n",
    "  ax.set_xlabel(r'${\\rm Epoch}$', fontsize=16)\n",
    "  ax.set_ylabel(r'$\\delta_{\\lambda^{(' + str(i+1) + ')}}(t)$', fontsize=16)\n",
    "  ax.legend()\n",
    "\n",
    "  ax_glob.scatter(common_epochs, eigvals_std[:,i] / eigvals_mean[:,i], label=r'$\\delta_{\\lambda^{(' + str(i+1) + ')}}$', s=15, marker=point_markers[i])\n",
    "\n",
    "  if SAVE_PLOT:\n",
    "    fig.savefig(SAVEDIR / f\"eigval_{i+1}.pdf\", dpi=300)\n",
    "\n",
    "ax_glob.set_xlabel(r'${\\rm Epoch}$', fontsize=16)\n",
    "ax_glob.set_ylabel(r'$\\delta_{\\lambda^{(' + str(i+1) + ')}}(t)$', fontsize=16)\n",
    "ax_glob.legend()\n",
    "\n",
    "if SAVE_PLOT:\n",
    "  fig_glob.savefig(SAVEDIR / \"glob_eigval_errors.pdf\", dpi=300)\n",
    "\n",
    "del eigvals_std\n",
    "del eigvals_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f45f4ef",
   "metadata": {},
   "source": [
    "# Model at initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8570a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_NAME = \"model_at_initialisation\"\n",
    "SAVEDIR = PLOT_FOLDER / FOLDER_NAME\n",
    "SAVEDIR.mkdir(parents=False, exist_ok=True)\n",
    "\n",
    "# Generating and ensemble of models\n",
    "replicas = len(replicas_folders)\n",
    "seed = 1423413\n",
    "xT3_0 = Distribution('xT3 at initialisation')\n",
    "for rep in range(replicas):\n",
    "  model = PDFmodel(\n",
    "          dense_layer='Dense',\n",
    "          input=fk_grid,\n",
    "          outputs=1,\n",
    "          architecture=metadata['model_info']['architecture'],\n",
    "          activations=['tanh', 'tanh'],\n",
    "          kernel_initializer='GlorotNormal',\n",
    "          user_ki_args=None,\n",
    "          seed=seed + rep)\n",
    "\n",
    "  xT3_0.add(model.predict().numpy().reshape(-1))\n",
    "\n",
    "T3_0 = xT3_0.apply_operator(b=fk_grid, operator=lambda a, b: np.true_divide(a, b), axis=0, name=f'T3 at initialisation')\n",
    "\n",
    "(xt3_lower_bound, xt3_upper_bound) = xT3_0.get_68_percentile()\n",
    "(t3_lower_bound, t3_upper_bound) = T3_0.get_68_percentile()\n",
    "\n",
    "# Plot the distribution at initialisation\n",
    "fig, axs = plt.subplots(2,1, figsize=(10, 10))\n",
    "axs[0].plot(fk_grid, xT3_0.get_mean(), label=r'${\\rm Mean}$', color='C0')\n",
    "axs[0].plot(fk_grid, xt3_upper_bound, linestyle='--', color='C0', label=r'$\\textrm{68\\% c.l.}$')\n",
    "axs[0].plot(fk_grid, xt3_lower_bound, linestyle='--', color='C0')\n",
    "axs[0].fill_between(fk_grid, xT3_0.get_mean()  - xT3_0.get_std(), xT3_0.get_mean() + xT3_0.get_std(), alpha=0.5, color='C0', label=r'$\\sigma$')\n",
    "axs[0].set_ylabel(r'$xT_3$')\n",
    "axs[0].set_xlabel(r'$x$')\n",
    "axs[0].set_xlim([1.e-5,1])\n",
    "\n",
    "axs[1].plot(fk_grid, T3_0.get_mean(), label=r'${\\rm Mean}$', color='C0')\n",
    "axs[1].fill_between(fk_grid, T3_0.get_mean()  - T3_0.get_std(), T3_0.get_mean() + T3_0.get_std(), alpha=0.5)\n",
    "axs[1].plot(fk_grid, t3_upper_bound, linestyle='--', color='C0')\n",
    "axs[1].plot(fk_grid, t3_lower_bound, linestyle='--', color='C0')\n",
    "axs[1].set_ylabel(r'$T_3$')\n",
    "axs[1].set_xlabel(r'$x$')\n",
    "axs[1].set_xlim([1.e-5,1])\n",
    "\n",
    "axs[0].legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "if SAVE_PLOT:\n",
    "\n",
    "  axs[0].set_xscale('linear')\n",
    "  axs[1].set_xscale('linear')\n",
    "  \n",
    "  fig.savefig(SAVEDIR / 'initialisation_distribution_lin.pdf', dpi=300)\n",
    "\n",
    "  extent_xt3 = axs[0].get_tightbbox(fig.canvas.get_renderer())\n",
    "  extent_t3 = axs[1].get_tightbbox(fig.canvas.get_renderer())\n",
    "\n",
    "  fig.savefig(\n",
    "    SAVEDIR / \"xt3_lin_init.pdf\", dpi=300,\n",
    "    bbox_inches=extent_xt3.transformed(fig.dpi_scale_trans.inverted()).padded(0.15)\n",
    "  )\n",
    "\n",
    "  fig.savefig(\n",
    "    SAVEDIR / \"t3_lin_init.pdf\", dpi=300,\n",
    "    bbox_inches=extent_t3.transformed(fig.dpi_scale_trans.inverted()).padded(0.15)\n",
    "  )\n",
    "\n",
    "  axs[0].set_xscale('log')\n",
    "  axs[1].set_xscale('log')\n",
    "\n",
    "  fig.savefig(SAVEDIR / 'initialisation_distribution_log.pdf', dpi=300)\n",
    "\n",
    "  extent_xt3 = axs[0].get_tightbbox(fig.canvas.get_renderer())\n",
    "  extent_t3 = axs[1].get_tightbbox(fig.canvas.get_renderer())\n",
    "\n",
    "  fig.savefig(\n",
    "    SAVEDIR / \"xt3_log_init.pdf\", dpi=300,\n",
    "    bbox_inches=extent_xt3.transformed(fig.dpi_scale_trans.inverted()).padded(0.15)\n",
    "  )\n",
    "\n",
    "  fig.savefig(\n",
    "    SAVEDIR / \"t3_log_init.pdf\", dpi=300,\n",
    "    bbox_inches=extent_t3.transformed(fig.dpi_scale_trans.inverted()).padded(0.15)\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0bd6a6",
   "metadata": {},
   "source": [
    "# Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899d5572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_evolution_operator(reference_epoch, t):\n",
    "    \"\"\"\n",
    "    Computes the evolution operator U(t) based on equation 41 in the solution.\n",
    "    \n",
    "    Parameters:\n",
    "    - NTK: Neural Tangent Kernel matrix\n",
    "    - FK: Forward map matrix\n",
    "    - Cy: Covariance matrix\n",
    "    - M: M matrix (typically FK^T @ Cy^-1 @ FK)\n",
    "    - t: time (epoch)\n",
    "    \n",
    "    Returns:\n",
    "    - U: Evolution operator at time t\n",
    "    - V: Second operator needed for the full solution\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract index of the reference epoch\n",
    "    epoch_index = common_epochs.index(reference_epoch)\n",
    "\n",
    "    Q = Q_by_epoch[epoch_index]\n",
    "    Qinv = Qinv_by_epoch[epoch_index]\n",
    "    P_parallel = P_parallel_by_epoch[epoch_index]\n",
    "    h = h_by_epoch[epoch_index]\n",
    "    hinv = hinv_by_epoch[epoch_index].make_diagonal()\n",
    "\n",
    "    Qt = Q.transpose()\n",
    "    Qtilde = Qt @ M @ P_parallel\n",
    "    T_tilde = Qt @ FK.T @ Cinv\n",
    "\n",
    "    exp_ht = h.apply_operator(b=t, operator=lambda a, b: np.exp(- a * b), axis=0, name=f'T3 at initialisation').make_diagonal()\n",
    "    one_minus_exp = h.apply_operator(b=t, operator=lambda a, b: 1.0 - np.exp(- a * b), axis=0, name=f'T3 at initialisation').make_diagonal()\n",
    "\n",
    "    U_hat = Q @ exp_ht @ Qinv\n",
    "    U_check = Q @ hinv @ one_minus_exp @ Qtilde\n",
    "    V = Q @ hinv @ one_minus_exp @ T_tilde\n",
    "    \n",
    "    U = U_hat + U_check + P_parallel\n",
    "    \n",
    "    return U, V\n",
    "\n",
    "def compute_evolution_operator_at_inf(reference_epoch):\n",
    "    \"\"\"\n",
    "    Computes operators at infinity\n",
    "    \n",
    "    Parameters:\n",
    "    - NTK: Neural Tangent Kernel matrix\n",
    "    - FK: Forward map matrix\n",
    "    - Cy: Covariance matrix\n",
    "    - M: M matrix (typically FK^T @ Cy^-1 @ FK)\n",
    "    - t: time (epoch)\n",
    "    \n",
    "    Returns:\n",
    "    - U: Evolution operator at time t\n",
    "    - V: Second operator needed for the full solution\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract index of the reference epoch\n",
    "    epoch_index = common_epochs.index(reference_epoch)\n",
    "\n",
    "    Q = Q_by_epoch[epoch_index]\n",
    "    P_parallel = P_parallel_by_epoch[epoch_index]\n",
    "    hinv = hinv_by_epoch[epoch_index].make_diagonal()\n",
    "  \n",
    "    Qt = Q.transpose()\n",
    "    Qtilde = Qt @ M @ P_parallel\n",
    "    T_tilde = Qt @ FK.T @ Cinv\n",
    "\n",
    "    U_check = Q @ hinv @ Qtilde\n",
    "    V = Q @ hinv @ T_tilde\n",
    "    \n",
    "    U = U_check + P_parallel\n",
    "    \n",
    "    return U, V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeccc39",
   "metadata": {},
   "source": [
    "# Check analytical solution at initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06212e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, V = compute_evolution_operator(20000, 0.0)\n",
    "xf_t = U @ xT3_0 + V @ data_by_replica_original\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10), sharey=False, gridspec_kw={'hspace': 0., 'wspace': 0.})\n",
    "# xf linaer\n",
    "axs[0].plot(fk_grid, xT3_0.get_mean(), label=r'$\\textrm{Empirical ensemble at initialisation}$')\n",
    "axs[0].fill_between(fk_grid, xT3_0.get_mean() - xT3_0.get_std(), xT3_0.get_mean() + xT3_0.get_std(), alpha=0.5)\n",
    "axs[0].plot(fk_grid, xf_t.get_mean(), label=r'$\\textrm{Analytical solution at initialisation}$')\n",
    "axs[0].fill_between(fk_grid, xf_t.get_mean() - xf_t.get_std(), xf_t.get_mean() + xf_t.get_std(), alpha=0.5)\n",
    "\n",
    "# xf log\n",
    "axs[1].plot(fk_grid, xT3_0.get_mean())\n",
    "axs[1].fill_between(fk_grid, xT3_0.get_mean() - xT3_0.get_std(), xT3_0.get_mean() + xT3_0.get_std(), alpha=0.5)\n",
    "axs[1].plot(fk_grid, xf_t.get_mean())\n",
    "axs[1].fill_between(fk_grid, xf_t.get_mean() - xf_t.get_std(), xf_t.get_mean() + xf_t.get_std(), alpha=0.5)\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].tick_params(axis='y', which='both', left=False, right=True, labelleft=False, labelright=True)\n",
    "\n",
    "\n",
    "axs[0].set_ylabel(r'$xT_3$', fontsize=16)\n",
    "axs[0].set_xlabel(r'$x$', fontsize=16)\n",
    "axs[1].set_xlabel(r'$x$', fontsize=16)\n",
    "\n",
    "axs[0].legend(fontsize=20)\n",
    "\n",
    "fig.suptitle(r'$\\textrm{Check at initialisation}$', fontsize=16)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bccfb1",
   "metadata": {},
   "source": [
    "# Check solution at infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ab4ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, V = compute_evolution_operator(30000, 100000)\n",
    "U_inf, V_inf = compute_evolution_operator_at_inf(30000)\n",
    "\n",
    "xf_t = U @ xT3_0 + V @ data_by_replica_original\n",
    "xf_inf = U_inf @ xT3_0 + V_inf @ data_by_replica_original\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10), sharey=False, gridspec_kw={'hspace': 0., 'wspace': 0.})\n",
    "# xf linaer\n",
    "axs[0].plot(fk_grid, xf_t.get_mean(), label=r'$\\textrm{Numerical limit } t\\rightarrow \\infty$')\n",
    "axs[0].fill_between(fk_grid, xf_t.get_mean() - xf_t.get_std(), xf_t.get_mean() + xf_t.get_std(), alpha=0.5)\n",
    "axs[0].plot(fk_grid, xf_inf.get_mean(), label=r'$\\textrm{Analytical limit } t\\rightarrow \\infty$')\n",
    "axs[0].fill_between(fk_grid, xf_inf.get_mean() - xf_inf.get_std(), xf_inf.get_mean() + xf_inf.get_std(), alpha=0.5)\n",
    "\n",
    "# xf log\n",
    "axs[1].plot(fk_grid, xf_t.get_mean())\n",
    "axs[1].fill_between(fk_grid, xf_t.get_mean() - xf_t.get_std(), xf_t.get_mean() + xf_t.get_std(), alpha=0.5)\n",
    "axs[1].plot(fk_grid, xf_inf.get_mean())\n",
    "axs[1].fill_between(fk_grid, xf_inf.get_mean() - xf_inf.get_std(), xf_inf.get_mean() + xf_inf.get_std(), alpha=0.5)\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].tick_params(axis='y', which='both', left=False, right=True, labelleft=False, labelright=True)\n",
    "\n",
    "axs[1].set_xlim(1.e-3, 1)\n",
    "axs[0].set_ylabel(r'$xT_3$', fontsize=16)\n",
    "axs[0].set_xlabel(r'$x$', fontsize=16)\n",
    "axs[1].set_xlabel(r'$x$', fontsize=16)\n",
    "\n",
    "axs[0].legend(fontsize=20)\n",
    "\n",
    "fig.suptitle(r'$\\textrm{Check at infinity }$', fontsize=16)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fd0cdc",
   "metadata": {},
   "source": [
    "# 1) Analytical solution with random initialisation and ntk from last training epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b297c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_NAME = \"case_1\"\n",
    "SAVEDIR = PLOT_FOLDER / FOLDER_NAME\n",
    "SAVEDIR.mkdir(parents=False, exist_ok=True)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10), sharey=False, gridspec_kw={'hspace': 0., 'wspace': 0.})\n",
    "\n",
    "t = 50000 * 1.e-5\n",
    "U, V = compute_evolution_operator(20000, t)\n",
    "xT3_t = U @ xT3_0 + V @ data_by_replica_original\n",
    "\n",
    "\n",
    "# xf linaer\n",
    "axs[0].plot(fk_grid, xT3_training.get_mean(), label=r'$\\textrm{Trained solution (eot)}$')\n",
    "axs[0].fill_between(fk_grid, xT3_training.get_mean() - xT3_training.get_std(), xT3_training.get_mean() + xT3_training.get_std(), alpha=0.5)\n",
    "axs[0].plot(fk_grid, xT3_t.get_mean(), label=r'$\\textrm{Analytical solution}$')\n",
    "axs[0].fill_between(fk_grid, xT3_t.get_mean() - xT3_t.get_std(), xT3_t.get_mean() + xT3_t.get_std(), alpha=0.5)\n",
    "axs[0].plot(fk_grid, f_bcdms, label=r'$\\textrm{True function}$')\n",
    "\n",
    "# xf log\n",
    "axs[1].plot(fk_grid, xT3_training.get_mean())\n",
    "axs[1].fill_between(fk_grid, xT3_training.get_mean() - xT3_training.get_std(), xT3_training.get_mean() + xT3_training.get_std(), alpha=0.5)\n",
    "axs[1].plot(fk_grid, xT3_t.get_mean())\n",
    "axs[1].fill_between(fk_grid, xT3_t.get_mean() - xT3_t.get_std(), xT3_t.get_mean() + xT3_t.get_std(), alpha=0.5)\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].tick_params(axis='y', which='both', left=False, right=True, labelleft=False, labelright=True)\n",
    "axs[1].set_xlim([1.e-3, 1])\n",
    "\n",
    "\n",
    "axs[0].set_ylabel(r'$xT_3$', fontsize=16)\n",
    "axs[0].set_xlabel(r'$x$', fontsize=16)\n",
    "axs[1].set_xlabel(r'$x$', fontsize=16)\n",
    "axs[0].legend(fontsize=20)\n",
    "\n",
    "fig.suptitle(r'$\\textrm{Distribution at } t =$' + rf'${t}$', fontsize=20)\n",
    "fig.tight_layout()\n",
    "if SAVE_PLOT:\n",
    "  fig.savefig(SAVEDIR / 'xT3_1.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d130e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_mean = U.get_mean()\n",
    "U_std = U.get_std()\n",
    "\n",
    "V_mean = V.get_mean()\n",
    "V_std = V.get_std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d500de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(np.abs(V_std / V_mean))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58edca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(np.abs(U_std / U_mean))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f14c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10), sharey=False, gridspec_kw={'hspace': 0., 'wspace': 0.})\n",
    "T3_t = xT3_t.apply_operator(b=fk_grid, operator=lambda a, b: np.true_divide(a, b), axis=0, name=f'T3 at t={t}')\n",
    "\n",
    "# xf linaer\n",
    "axs[0].plot(fk_grid, T3_training.get_mean(), label=r'$\\textrm{Trained solution (eot)}$')\n",
    "axs[0].fill_between(fk_grid, T3_training.get_mean() - T3_training.get_std(), T3_training.get_mean() + T3_training.get_std(), alpha=0.5)\n",
    "axs[0].plot(fk_grid, T3_t.get_mean(), label=r'$\\textrm{Analytical solution}$')\n",
    "axs[0].fill_between(fk_grid, T3_t.get_mean() - T3_t.get_std(), T3_t.get_mean() + T3_t.get_std(), alpha=0.5)\n",
    "\n",
    "# xf log\n",
    "axs[1].plot(fk_grid, T3_training.get_mean())\n",
    "axs[1].fill_between(fk_grid, T3_training.get_mean() - T3_training.get_std(), T3_training.get_mean() + T3_training.get_std(), alpha=0.5)\n",
    "axs[1].plot(fk_grid, T3_t.get_mean())\n",
    "axs[1].fill_between(fk_grid, T3_t.get_mean() - T3_t.get_std(), T3_t.get_mean() + T3_t.get_std(), alpha=0.5)\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].tick_params(axis='y', which='both', left=False, right=True, labelleft=False, labelright=True)\n",
    "axs[1].set_xlim([1.e-3, 1])\n",
    "\n",
    "axs[0].set_ylabel(r'$T_3$', fontsize=16)\n",
    "axs[0].set_xlabel(r'$x$', fontsize=16)\n",
    "axs[1].set_xlabel(r'$x$', fontsize=16)\n",
    "\n",
    "axs[0].legend(fontsize=20)\n",
    "axs[0].set_ylim(-0.5,3)\n",
    "axs[1].set_ylim(-0.5,3)\n",
    "\n",
    "fig.suptitle(r'$\\textrm{Distribution at } t =$' + rf'${t}$', fontsize=20)\n",
    "fig.tight_layout()\n",
    "if SAVE_PLOT:\n",
    "  fig.savefig(SAVEDIR / 'T3_1.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04e3240",
   "metadata": {},
   "source": [
    "# 2) Analytical solution with initial condition at $t = t_{\\rm ref}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c491f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_NAME = \"case_2\"\n",
    "SAVEDIR = PLOT_FOLDER / FOLDER_NAME\n",
    "SAVEDIR.mkdir(parents=False, exist_ok=True)\n",
    "ref_epoch = 20000\n",
    "xT3_ref = Distribution('xT3 at reference epoch')\n",
    "\n",
    "# Get trained model at the reference epoch\n",
    "for replica_path in replicas_folders:\n",
    "    replica = replica_path.name\n",
    "    last_epoch = replica_epochs_dict[replica][np.argwhere(np.array(common_epochs) == ref_epoch)[0,0]]\n",
    "\n",
    "    model = PDFmodel.load_model(replica_path / 'config.json', last_epoch)\n",
    "    xT3_ref.add(model.predict().numpy().reshape(-1))\n",
    "\n",
    "t = (common_epochs[-1] - ref_epoch) * learning_rate\n",
    "U, V = compute_evolution_operator(ref_epoch, t)\n",
    "xT3_t = U @ xT3_ref + V @ data_by_replica_original\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10), sharey=False, gridspec_kw={'hspace': 0., 'wspace': 0.})\n",
    "\n",
    "# xf linaer\n",
    "axs[0].plot(fk_grid, xT3_training.get_mean(), label=r'$\\textrm{Trained solution}$')\n",
    "axs[0].fill_between(fk_grid, xT3_training.get_mean() - xT3_training.get_std(), xT3_training.get_mean() + xT3_training.get_std(), alpha=0.5)\n",
    "axs[0].plot(fk_grid, xT3_t.get_mean(), label=r'$\\textrm{Analytical solution}$')\n",
    "axs[0].fill_between(fk_grid, xT3_t.get_mean() - xT3_t.get_std(), xT3_t.get_mean() + xT3_t.get_std(), alpha=0.5)\n",
    "axs[0].plot(fk_grid, f_bcdms, label=r'$\\textrm{True function}$')\n",
    "\n",
    "# xf log\n",
    "axs[1].plot(fk_grid, xT3_training.get_mean())\n",
    "axs[1].fill_between(fk_grid, xT3_training.get_mean() - xT3_training.get_std(), xT3_training.get_mean() + xT3_training.get_std(), alpha=0.5)\n",
    "axs[1].plot(fk_grid, xT3_t.get_mean())\n",
    "axs[1].fill_between(fk_grid, xT3_t.get_mean() - xT3_t.get_std(), xT3_t.get_mean() + xT3_t.get_std(), alpha=0.5)\n",
    "axs[1].plot(fk_grid, f_bcdms, label=r'$\\textrm{True function}$')\n",
    "\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].tick_params(axis='y', which='both', left=False, right=True, labelleft=False, labelright=True)\n",
    "axs[1].set_xlim([1.e-3,1])\n",
    "\n",
    "\n",
    "axs[0].set_ylabel(r'$xT_3$', fontsize=16)\n",
    "axs[0].set_xlabel(r'$x$', fontsize=16)\n",
    "axs[1].set_xlabel(r'$x$', fontsize=16)\n",
    "\n",
    "axs[0].legend(fontsize=20)\n",
    "\n",
    "fig.suptitle(r'$\\textrm{Distribution at } t =$' + rf'${t}$', fontsize=20)\n",
    "fig.tight_layout()\n",
    "if SAVE_PLOT:\n",
    "  fig.savefig(SAVEDIR / 'xT3_2.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890043dd",
   "metadata": {},
   "source": [
    "# 3) Contribution of $U$ and $V$ separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c3ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_NAME = \"case_3\"\n",
    "SAVEDIR = PLOT_FOLDER / FOLDER_NAME\n",
    "SAVEDIR.mkdir(parents=False, exist_ok=True)\n",
    "ref_epoch = 30000\n",
    "xT3_ref = Distribution('xT3 at reference epoch')\n",
    "\n",
    "# Get trained model at the reference epoch\n",
    "for replica_path in replicas_folders:\n",
    "    replica = replica_path.name\n",
    "    last_epoch = replica_epochs_dict[replica][np.argwhere(np.array(common_epochs) == ref_epoch)[0,0]]\n",
    "\n",
    "    model = PDFmodel.load_model(replica_path / 'config.json', last_epoch)\n",
    "    xT3_ref.add(model.predict().numpy().reshape(-1))\n",
    "\n",
    "t = 0.001#(common_epochs[-1] - ref_epoch) * learning_rate\n",
    "U, V = compute_evolution_operator(ref_epoch, t)\n",
    "xT3_t_u = U @ xT3_ref\n",
    "xT3_t_v = V @ data_by_replica_original\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10), sharey=False, gridspec_kw={'hspace': 0., 'wspace': 0.})\n",
    "\n",
    "# xf linaer\n",
    "axs[0].plot(fk_grid, xT3_training.get_mean(), label=r'$\\textrm{Trained solution}$')\n",
    "axs[0].fill_between(fk_grid, xT3_training.get_mean() - xT3_training.get_std(), xT3_training.get_mean() + xT3_training.get_std(), alpha=0.5)\n",
    "\n",
    "axs[0].plot(fk_grid, xT3_t_u.get_mean(), label=r'$\\textrm{Contribution from } U$')\n",
    "axs[0].fill_between(fk_grid, xT3_t_u.get_mean() - xT3_t_u.get_std(), xT3_t_u.get_mean() + xT3_t_u.get_std(), alpha=0.5)\n",
    "\n",
    "axs[0].plot(fk_grid, xT3_t_v.get_mean(), label=r'$\\textrm{Contribution from } V$')\n",
    "axs[0].fill_between(fk_grid, xT3_t_v.get_mean() - xT3_t_v.get_std(), xT3_t_v.get_mean() + xT3_t_v.get_std(), alpha=0.5)\n",
    "\n",
    "#axs[0].plot(fk_grid, f_bcdms, label=r'$\\textrm{True function}$')\n",
    "\n",
    "# xf log\n",
    "axs[1].plot(fk_grid, xT3_training.get_mean())\n",
    "axs[1].fill_between(fk_grid, xT3_training.get_mean() - xT3_training.get_std(), xT3_training.get_mean() + xT3_training.get_std(), alpha=0.5)\n",
    "\n",
    "axs[1].plot(fk_grid, xT3_t_u.get_mean())\n",
    "axs[1].fill_between(fk_grid, xT3_t_u.get_mean() - xT3_t_u.get_std(), xT3_t_u.get_mean() + xT3_t_u.get_std(), alpha=0.5)\n",
    "\n",
    "axs[1].plot(fk_grid, xT3_t_v.get_mean())\n",
    "axs[1].fill_between(fk_grid, xT3_t_v.get_mean() - xT3_t_v.get_std(), xT3_t_v.get_mean() + xT3_t_v.get_std(), alpha=0.5)\n",
    "\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].tick_params(axis='y', which='both', left=False, right=True, labelleft=False, labelright=True)\n",
    "axs[1].set_xlim([1.e-3,1])\n",
    "\n",
    "\n",
    "axs[0].set_ylabel(r'$xT_3$', fontsize=16)\n",
    "axs[0].set_xlabel(r'$x$', fontsize=16)\n",
    "axs[1].set_xlabel(r'$x$', fontsize=16)\n",
    "\n",
    "axs[0].legend(fontsize=20)\n",
    "\n",
    "fig.suptitle(r'$\\textrm{Distribution at } t =$' + rf'${t}$', fontsize=20)\n",
    "fig.tight_layout()\n",
    "\n",
    "if SAVE_PLOT:\n",
    "  fig.savefig(SAVEDIR / 'xT3_u_v_contribution_small_t.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9976f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_NAME = \"case_3\"\n",
    "SAVEDIR = PLOT_FOLDER / FOLDER_NAME\n",
    "SAVEDIR.mkdir(parents=False, exist_ok=True)\n",
    "ref_epoch = 30000\n",
    "xT3_ref = Distribution('xT3 at reference epoch')\n",
    "\n",
    "# Get trained model at the reference epoch\n",
    "for replica_path in replicas_folders:\n",
    "    replica = replica_path.name\n",
    "    last_epoch = replica_epochs_dict[replica][np.argwhere(np.array(common_epochs) == ref_epoch)[0,0]]\n",
    "\n",
    "    model = PDFmodel.load_model(replica_path / 'config.json', last_epoch)\n",
    "    xT3_ref.add(model.predict().numpy().reshape(-1))\n",
    "\n",
    "t = (common_epochs[-1] - ref_epoch) * learning_rate\n",
    "U, V = compute_evolution_operator(ref_epoch, t)\n",
    "xT3_t_u = U @ xT3_ref\n",
    "xT3_t_v = V @ data_by_replica_original\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10), sharey=False, gridspec_kw={'hspace': 0., 'wspace': 0.})\n",
    "\n",
    "# xf linaer\n",
    "axs[0].plot(fk_grid, xT3_training.get_mean(), label=r'$\\textrm{Trained solution}$')\n",
    "axs[0].fill_between(fk_grid, xT3_training.get_mean() - xT3_training.get_std(), xT3_training.get_mean() + xT3_training.get_std(), alpha=0.5)\n",
    "\n",
    "axs[0].plot(fk_grid, xT3_t_u.get_mean(), label=r'$\\textrm{Contribution from } U$')\n",
    "axs[0].fill_between(fk_grid, xT3_t_u.get_mean() - xT3_t_u.get_std(), xT3_t_u.get_mean() + xT3_t_u.get_std(), alpha=0.5)\n",
    "\n",
    "axs[0].plot(fk_grid, xT3_t_v.get_mean(), label=r'$\\textrm{Contribution from } V$')\n",
    "axs[0].fill_between(fk_grid, xT3_t_v.get_mean() - xT3_t_v.get_std(), xT3_t_v.get_mean() + xT3_t_v.get_std(), alpha=0.5)\n",
    "\n",
    "#axs[0].plot(fk_grid, f_bcdms, label=r'$\\textrm{True function}$')\n",
    "\n",
    "# xf log\n",
    "axs[1].plot(fk_grid, xT3_training.get_mean())\n",
    "axs[1].fill_between(fk_grid, xT3_training.get_mean() - xT3_training.get_std(), xT3_training.get_mean() + xT3_training.get_std(), alpha=0.5)\n",
    "\n",
    "axs[1].plot(fk_grid, xT3_t_u.get_mean())\n",
    "axs[1].fill_between(fk_grid, xT3_t_u.get_mean() - xT3_t_u.get_std(), xT3_t_u.get_mean() + xT3_t_u.get_std(), alpha=0.5)\n",
    "\n",
    "axs[1].plot(fk_grid, xT3_t_v.get_mean())\n",
    "axs[1].fill_between(fk_grid, xT3_t_v.get_mean() - xT3_t_v.get_std(), xT3_t_v.get_mean() + xT3_t_v.get_std(), alpha=0.5)\n",
    "\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].tick_params(axis='y', which='both', left=False, right=True, labelleft=False, labelright=True)\n",
    "axs[1].set_xlim([1.e-3,1])\n",
    "\n",
    "\n",
    "axs[0].set_ylabel(r'$xT_3$', fontsize=16)\n",
    "axs[0].set_xlabel(r'$x$', fontsize=16)\n",
    "axs[1].set_xlabel(r'$x$', fontsize=16)\n",
    "\n",
    "axs[0].legend(fontsize=20)\n",
    "\n",
    "fig.suptitle(r'$\\textrm{Distribution at } t =$' + rf'${t}$', fontsize=20)\n",
    "fig.tight_layout()\n",
    "\n",
    "if SAVE_PLOT:\n",
    "  fig.savefig(SAVEDIR / 'xT3_u_v_contribution_eot.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f807a118",
   "metadata": {},
   "source": [
    "# 4) Expectation value $\\mathbb{E}\\left[ U(t) f_0 \\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1cd934",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_NAME = \"case_4\"\n",
    "SAVEDIR = PLOT_FOLDER / FOLDER_NAME\n",
    "\n",
    "ref_epoch = 30000\n",
    "\n",
    "t = (common_epochs[-1] - ref_epoch) * learning_rate\n",
    "U, V = compute_evolution_operator(ref_epoch, t)\n",
    "\n",
    "\n",
    "xT3_rhs = U.get_mean() @ xT3_0.get_mean()\n",
    "xT3_lhs = (U @ xT3_0).get_mean()\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10), sharey=False, sharex=False, gridspec_kw={'hspace': 0., 'wspace': 0., 'height_ratios': [3, 1]})\n",
    "\n",
    "# Linear\n",
    "axs[0][0].plot(fk_grid, xT3_lhs, label=r'$E\\left[ U(t) f_0 \\right]$')\n",
    "axs[0][0].plot(fk_grid, xT3_rhs, label=r'$E\\left[ U(t) \\right] E\\left[f_0 \\right]$')\n",
    "axs[1][0].plot(fk_grid, xT3_rhs / xT3_lhs)\n",
    "axs[1][0].axhline(y=1, linestyle='--', color='C0')\n",
    "axs[0][0].set_xscale('linear')\n",
    "axs[1][0].set_xscale('linear')\n",
    "\n",
    "# Log\n",
    "axs[0][1].plot(fk_grid, xT3_lhs, label=r'$E\\left[ U(t) f_0 \\right]$')\n",
    "axs[0][1].plot(fk_grid, xT3_rhs, label=r'$E\\left[ U(t) \\right] E\\left[f_0 \\right]$')\n",
    "axs[1][1].plot(fk_grid, xT3_rhs / xT3_lhs)\n",
    "axs[1][1].axhline(y=1, linestyle='--', color='C0')\n",
    "axs[0][1].set_xscale('log')\n",
    "axs[1][1].set_xscale('log')\n",
    "axs[1][1].tick_params(axis='y', which='both', left=False, right=True, labelleft=False, labelright=True)\n",
    "axs[0][1].set_xlim([1.e-3,1])\n",
    "axs[1][1].set_xlim([1.e-3,1])\n",
    "\n",
    "axs[0][0].set_ylabel(r'$\\textrm{U contribution}$', fontsize=20)\n",
    "axs[1][0].set_xlabel(r'$x$', fontsize=20)\n",
    "axs[1][1].set_xlabel(r'$x$', fontsize=20)\n",
    "\n",
    "axs[0][0].legend(fontsize=20)\n",
    "\n",
    "axs[1][0].set_ylabel(r'$\\frac{E\\left[ U(t) \\right] E\\left[f_0 \\right]}{E\\left[ U(t) f_0 \\right]}$', fontsize=20)\n",
    "fig.suptitle(r'$\\textrm{Distribution at } t =$' + rf'${t}$', fontsize=20)\n",
    "fig.tight_layout()\n",
    "\n",
    "if SAVE_PLOT:\n",
    "  SAVEDIR.mkdir(parents=False, exist_ok=True)\n",
    "  fig.savefig(SAVEDIR / 'xT3_exp_val_eot.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9b7767",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_NAME = \"case_4\"\n",
    "SAVEDIR = PLOT_FOLDER / FOLDER_NAME\n",
    "\n",
    "ref_epoch = 30000\n",
    "\n",
    "t = 0.0005\n",
    "U, V = compute_evolution_operator(ref_epoch, t)\n",
    "\n",
    "xT3_rhs = U.get_mean() @ xT3_0.get_mean()\n",
    "xT3_lhs = (U @ xT3_0).get_mean()\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10), sharey=False, sharex=False, gridspec_kw={'hspace': 0., 'wspace': 0., 'height_ratios': [3, 1]})\n",
    "\n",
    "# Linear\n",
    "axs[0][0].plot(fk_grid, xT3_lhs, label=r'$E\\left[ U(t) f_0 \\right]$')\n",
    "axs[0][0].plot(fk_grid, xT3_rhs, label=r'$E\\left[ U(t) \\right] E\\left[f_0 \\right]$')\n",
    "axs[1][0].plot(fk_grid, xT3_rhs / xT3_lhs)\n",
    "axs[1][0].axhline(y=1, linestyle='--', color='C0')\n",
    "axs[0][0].set_xscale('linear')\n",
    "axs[1][0].set_xscale('linear')\n",
    "\n",
    "# Log\n",
    "axs[0][1].plot(fk_grid, xT3_lhs, label=r'$E\\left[ U(t) f_0 \\right]$')\n",
    "axs[0][1].plot(fk_grid, xT3_rhs, label=r'$E\\left[ U(t) \\right] E\\left[f_0 \\right]$')\n",
    "axs[1][1].plot(fk_grid, xT3_rhs / xT3_lhs)\n",
    "axs[1][1].axhline(y=1, linestyle='--', color='C0')\n",
    "axs[0][1].set_xscale('log')\n",
    "axs[1][1].set_xscale('log')\n",
    "axs[1][1].tick_params(axis='y', which='both', left=False, right=True, labelleft=False, labelright=True)\n",
    "axs[0][1].set_xlim([1.e-3,1])\n",
    "axs[1][1].set_xlim([1.e-3,1])\n",
    "\n",
    "axs[0][0].set_ylabel(r'$\\textrm{U contribution}$', fontsize=20)\n",
    "axs[1][0].set_xlabel(r'$x$', fontsize=20)\n",
    "axs[1][1].set_xlabel(r'$x$', fontsize=20)\n",
    "\n",
    "axs[0][0].legend(fontsize=20)\n",
    "\n",
    "axs[1][0].set_ylabel(r'$\\frac{E\\left[ U(t) \\right] E\\left[f_0 \\right]}{E\\left[ U(t) f_0 \\right]}$', fontsize=20)\n",
    "\n",
    "fig.suptitle(r'$\\textrm{Distribution at } t =$' + rf'${t}$', fontsize=20)\n",
    "fig.tight_layout()\n",
    "\n",
    "if SAVE_PLOT:\n",
    "  fig.savefig(SAVEDIR / 'xT3_exp_val_early.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9103353d",
   "metadata": {},
   "source": [
    "# Interplay between $M$ and NTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5f116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = eigvecs_time[common_epochs.index(ref_epoch)]\n",
    "T_tilde = (Z.transpose() @ FK.T).transpose()\n",
    "T_tilde_mean = T_tilde.get_mean(axis=0)\n",
    "T_tilde_std = T_tilde.get_std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d640e55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_NAME = \"ntk_m_overlap\"\n",
    "SAVEDIR = PLOT_FOLDER / FOLDER_NAME\n",
    "SAVEDIR.mkdir(parents=False, exist_ok=True)\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "# predictions with eigvectors of the ntk\n",
    "ref_epochs = [0, 4000, 30000, 50000]\n",
    "ref_replica = 34 # Random replica\n",
    "\n",
    "# Compute eigvals and eigvecs of M\n",
    "m, W = np.linalg.eigh(M)\n",
    "m = m[::-1]\n",
    "W = W[:, ::-1]\n",
    "\n",
    "for ref_epoch in ref_epochs:\n",
    "  fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "  Z = eigvecs_time[common_epochs.index(ref_epoch)]\n",
    "  cut = cut_by_epoch[common_epochs.index(ref_epoch)]\n",
    "  A = np.power(Z[ref_replica].T @ W, 2)\n",
    "\n",
    "  ms = ax.matshow(A, \n",
    "                  cmap=mpl.colormaps['RdBu_r'],\n",
    "                  vmax=A.max(),\n",
    "                  vmin=0.0\n",
    "                  #vmax=A.max(),\n",
    "                  #vmin=1.e-7,\n",
    "                  #norm=mpl.colors.LogNorm(vmin=1.e-7, vmax=A.max()),\n",
    "                  )\n",
    "  \n",
    "  # Plot horizontal and vertical lines at the cut value\n",
    "  cut_value = cut[ref_replica]\n",
    "  ax.axhline(y=cut_value, color='white', linestyle='--', linewidth=2)\n",
    "  plt.colorbar(ms, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "  ax.set_title(r\"$\\textrm{Overlap at epoch = }\" +  f\"{ref_epoch}\" + r\"$\", fontsize=30)\n",
    "  ax.set_ylabel(r'$\\textrm{Eigenvectors of the NTK}$', fontsize=30)\n",
    "  ax.set_xlabel(r'$\\textrm{Eigenvectors of the M matrix}$', fontsize=30)\n",
    "  ax.xaxis.set_ticks_position('bottom')\n",
    "  ax.xaxis.set_label_position('bottom')\n",
    "\n",
    "  fig.tight_layout()\n",
    "\n",
    "  if SAVE_PLOT:\n",
    "    fig.savefig(SAVEDIR / f'overlap_epoch_{ref_epoch}.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f2745a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8097be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
