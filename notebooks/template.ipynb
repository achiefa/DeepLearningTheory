{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f19032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from  matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "rc('text',usetex=True)\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from yadlt.model import PDFmodel\n",
    "from yadlt.distribution import Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4a2d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extension for the weights file\n",
    "WEIGHTS_TOKEN = 'weights.h5'\n",
    "def select_weight(epoch: int):\n",
    "  return f\"epoch_{int(epoch)}.{WEIGHTS_TOKEN}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d799cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the fit folder\n",
    "FIT_FOLDER = Path('../Results/fits/fit_250417-01-L2-50000')\n",
    "\n",
    "# Folder for the serialization\n",
    "SERIALIZATION_FOLDER = FIT_FOLDER / 'serialization'\n",
    "SERIALIZATION_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Path to plot folder\n",
    "PLOT_FOLDER = FIT_FOLDER / 'plots'\n",
    "PLOT_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SAVE_PLOT = False\n",
    "SAVE_NB = False\n",
    "APPLY_LIM_KIN = False\n",
    "ASSERT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ce35d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract replicas from the fit folder\n",
    "replicas_folders = [f for f in FIT_FOLDER.iterdir() if f.is_dir() and 'replica' in str(f)]\n",
    "replicas_folders.sort()\n",
    "replicas = len(replicas_folders)\n",
    "\n",
    "# For each replicas, load the epochs and data\n",
    "replica_epochs_dict = {}\n",
    "for replica_folder in replicas_folders:\n",
    "  epochs = [f for f in replica_folder.iterdir() if f.is_file() and WEIGHTS_TOKEN in str(f)]\n",
    "  epochs.sort()\n",
    "  replica_epochs_dict[replica_folder.name] = epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12f83cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find common epochs\n",
    "# Different replicas may have different epochs, so we need to find the common ones\n",
    "common_epochs = set()\n",
    "for replica, epochs in replica_epochs_dict.items():\n",
    "  aux = set()\n",
    "  for epoch in epochs:\n",
    "    epoch_num = int(epoch.name.split('.')[0].split('_')[1])\n",
    "    aux.add(epoch_num)\n",
    "  \n",
    "  if len(common_epochs) == 0:\n",
    "    common_epochs = aux\n",
    "  else:\n",
    "    common_epochs.intersection_update(aux)\n",
    "\n",
    "common_epochs = sorted(list(common_epochs))\n",
    "print(f\"Common epochs: {common_epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6823ed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yadlt import data\n",
    "from pathlib import Path\n",
    "import importlib.resources as pkg_resources\n",
    "\n",
    "# Load Tommaso's file\n",
    "data_path = Path(pkg_resources.files(data) / \"BCDMS_data\")\n",
    "fk_grid = np.load(data_path / 'fk_grid.npy')\n",
    "FK_original = np.load(data_path / 'FK.npy')\n",
    "f_bcdms = np.load(data_path / 'f_bcdms.npy')\n",
    "Cy = np.load(data_path / 'Cy.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd3e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the last common epoch from the ensemble of replicas\n",
    "xT3_training = Distribution('xT3_training')\n",
    "print(f'Loading {len(replicas_folders)} replicas...', end='\\t')\n",
    "for replica_path in replicas_folders:\n",
    "    replica = replica_path.name\n",
    "    last_epoch = replica_epochs_dict[replica][-1]\n",
    "\n",
    "    model = PDFmodel.load_model(replica_path / 'config.json', last_epoch)\n",
    "    xT3_training.add(model.predict().numpy().reshape(-1))\n",
    "print('Done!')\n",
    "\n",
    "# Compute T3 from xT3\n",
    "T3_training = xT3_training.apply_operator(b=fk_grid, operator=lambda a, b: np.true_divide(a, b), axis=0, name=f'T3 at the end of the training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec1edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data used to fit the replicas\n",
    "data_by_replica_original = Distribution(\"Original replicas of the data\")\n",
    "\n",
    "for rep in range(replicas):\n",
    "  data = np.load(FIT_FOLDER / f'replica_{rep+1}' / 'data.npy')\n",
    "  data_by_replica_original.add(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3b8540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ensemble of xT3 at the end of the training\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(fk_grid, xT3_training.get_mean(), label='Mean')\n",
    "plt.fill_between(fk_grid, xT3_training.get_mean() - xT3_training.get_std(), xT3_training.get_mean() + xT3_training.get_std(), alpha=0.5)\n",
    "plt.plot(fk_grid, f_bcdms, label='True function')\n",
    "plt.xlabel(r'$x$', fontsize=14)\n",
    "plt.ylabel(r'$xT_3$', fontsize=14)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "if SAVE_PLOT:\n",
    "  plt.savefig(PLOT_FOLDER / 'pdf_mean_std.png', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2235c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect NTK statistics distributions for each replica over the training epochs\n",
    "# This is the boilerplate code to compute the NTK and its statistics\n",
    "if not any(SERIALIZATION_FOLDER.iterdir()):\n",
    "  print('Data have not been serialized yet. Serializing now...')\n",
    "  NTK_time = []\n",
    "  frob_norm_time = []\n",
    "  l2_norm_time = []\n",
    "  linf_norm_time = []\n",
    "  for epoch in common_epochs:\n",
    "    print(f\"Epoch {epoch} / {common_epochs[-1]}\")\n",
    "    NTK_distribution = Distribution(f'NTK epoch {epoch}') # Each epoch contains a distribution of NTKs\n",
    "    frob_norm_dist = Distribution(f'Frobenius norm epoch {epoch}')\n",
    "    l2_norm_dist = Distribution(f'L2 norm epoch {epoch}')\n",
    "    linf_norm_dist = Distribution(f'Linf norm epoch {epoch}')\n",
    "    for replica_path in replicas_folders:\n",
    "      model = PDFmodel.load_model(replica_path / 'config.json', replica_path / select_weight(epoch))\n",
    "      NTK = model.compute_ntk()\n",
    "      _, S, _ = np.linalg.svd(NTK, hermitian=True)\n",
    "      frob_norm_dist.add(np.sqrt(np.sum([s**2 for s in S])))\n",
    "      l2_norm_dist.add(S[0])\n",
    "      linf_norm_dist.add(np.linalg.norm(NTK, ord='inf'))\n",
    "      NTK_distribution.add(NTK)\n",
    "\n",
    "    NTK_time.append(NTK_distribution)\n",
    "    frob_norm_time.append(frob_norm_dist)\n",
    "    l2_norm_time.append(l2_norm_dist)\n",
    "    linf_norm_time.append(linf_norm_dist)\n",
    "    pickle.dump(NTK_time, open(SERIALIZATION_FOLDER / 'NTK_time.pickle', 'wb'))\n",
    "    pickle.dump(frob_norm_time, open(SERIALIZATION_FOLDER / 'frob_norm_time.pickle', 'wb'))\n",
    "    pickle.dump(l2_norm_time, open(SERIALIZATION_FOLDER / 'l2_norm_time.pickle', 'wb'))\n",
    "    pickle.dump(linf_norm_time, open(SERIALIZATION_FOLDER / 'linf_norm_time.pickle', 'wb'))\n",
    "else:\n",
    "  print('Data have already been serialized. Loading from disk...')\n",
    "  NTK_time = pickle.load(open(SERIALIZATION_FOLDER / 'NTK_time.pickle', 'rb'))\n",
    "  frob_norm_time = pickle.load(open(SERIALIZATION_FOLDER / 'frob_norm_time.pickle', 'rb'))\n",
    "  l2_norm_time = pickle.load(open(SERIALIZATION_FOLDER / 'l2_norm_time.pickle', 'rb'))\n",
    "  linf_norm_time = pickle.load(open(SERIALIZATION_FOLDER / 'linf_norm_time.pickle', 'rb'))\n",
    "  print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5085946",
   "metadata": {},
   "source": [
    "# Norm of the NTK over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340644b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "frob_means = np.array([frob.get_mean() for frob in frob_norm_time])\n",
    "frob_stds = np.array([frob.get_std() for frob in frob_norm_time])\n",
    "l2_means = np.array([l2.get_mean() for l2 in l2_norm_time])\n",
    "l2_stds = np.array([l2.get_std() for l2 in l2_norm_time])\n",
    "linf_means = np.array([linf.get_mean() for linf in linf_norm_time])\n",
    "linf_stds = np.array([linf.get_std() for linf in linf_norm_time])\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 10))\n",
    "\n",
    "axs[0].plot(common_epochs, frob_means, label='Frob. norm NTK')\n",
    "axs[0].fill_between(common_epochs, frob_means + frob_stds, frob_means - frob_stds, alpha=0.5)\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Frob. norm NTK')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(common_epochs, l2_means, label='L2 norm NTK')\n",
    "axs[1].fill_between(common_epochs, l2_means + l2_stds, l2_means - l2_stds, alpha=0.5)\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('L2 norm NTK')\n",
    "axs[1].legend()\n",
    "\n",
    "axs[2].plot(common_epochs, linf_means, label=r'$L_{\\infty}$ norm NTK')\n",
    "axs[2].fill_between(common_epochs, linf_means + linf_stds, linf_means - linf_stds, alpha=0.5)\n",
    "axs[2].set_xlabel('Epoch')\n",
    "axs[2].set_ylabel(r'$L_{\\infty}$ norm NTK')\n",
    "axs[2].legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "if SAVE_PLOT:\n",
    "  fig.savefig(PLOT_FOLDER / 'NTK_norms.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce949f47",
   "metadata": {},
   "source": [
    "# Change in the NTK over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e704c8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute  \\Delta\\Theta_t = || \\Theta_{t+1} - \\Theta_t}||\n",
    "Delta_ntk_t = []\n",
    "for i in range(len(NTK_time) - 1):\n",
    "  delta_ntk_dist = Distribution(f'Delta NTK {i}')\n",
    "  for rep in range(replicas):\n",
    "    delta_ntk = np.linalg.norm(NTK_time[i + 1][rep] - NTK_time[i][rep])\n",
    "    delta_ntk_dist.add(delta_ntk)\n",
    "  Delta_ntk_t.append(delta_ntk_dist)\n",
    "\n",
    "delta_ntk_means = np.array([delta.get_mean() for delta in Delta_ntk_t])\n",
    "delta_ntk_stds = np.array([delta.get_std() for delta in Delta_ntk_t])\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10), sharey=False, gridspec_kw={'hspace': 0.1, 'wspace': 0.1})\n",
    "\n",
    "axs[0].plot(common_epochs[1:], delta_ntk_means, label='')\n",
    "axs[0].fill_between(common_epochs[1:], delta_ntk_means + delta_ntk_stds, delta_ntk_means - delta_ntk_stds, alpha=0.5)\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel(r'$\\Delta \\Theta_t$', fontsize=16)\n",
    "axs[0].set_xmargin(0.02)\n",
    "\n",
    "axs[1].plot(common_epochs[1:], delta_ntk_means, label='')\n",
    "axs[1].fill_between(common_epochs[1:], delta_ntk_means + delta_ntk_stds, delta_ntk_means - delta_ntk_stds, alpha=0.5)\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].set_xmargin(0.02)\n",
    "\n",
    "fig.suptitle(r'$\\Delta \\Theta_t = || \\Theta_{t+1} - \\Theta_{t}||$', fontsize=20, y=0.95)\n",
    "fig.tight_layout()\n",
    "if SAVE_PLOT:\n",
    "  fig.savefig(PLOT_FOLDER / 'delta_ntk.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f45f4ef",
   "metadata": {},
   "source": [
    "# Model at initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8570a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating and ensemble of models\n",
    "replicas = len(replicas_folders)\n",
    "seed = 1423413\n",
    "xT3_0 = Distribution('xT3 at initialisation')\n",
    "T3_0 = Distribution('T3 at initialisation')\n",
    "for rep in range(replicas):\n",
    "  model = PDFmodel(\n",
    "          dense_layer='Dense',\n",
    "          input=fk_grid,\n",
    "          outputs=1,\n",
    "          architecture=[28,20],\n",
    "          activations=['tanh', 'tanh'],\n",
    "          kernel_initializer='GlorotNormal',\n",
    "          user_ki_args=None,\n",
    "          seed=seed + rep)\n",
    "\n",
    "  xT3_0.add(model.predict().numpy().reshape(-1))\n",
    "  T3_0.add(model.predict().numpy().reshape(-1) / fk_grid)\n",
    "\n",
    "\n",
    "# Plot the distribution at initialisation\n",
    "fig, axs = plt.subplots(2,1, figsize=(10, 5))\n",
    "axs[0].plot(fk_grid, xT3_0.get_mean(), label='Mean')\n",
    "axs[0].fill_between(fk_grid, xT3_0.get_mean()  - xT3_0.get_std(), xT3_0.get_mean() + xT3_0.get_std(), alpha=0.5)\n",
    "axs[0].set_ylabel(r'$xT_3$')\n",
    "\n",
    "axs[1].plot(fk_grid, T3_0.get_mean(), label='Mean')\n",
    "axs[1].fill_between(fk_grid, T3_0.get_mean()  - T3_0.get_std(), T3_0.get_mean() + T3_0.get_std(), alpha=0.5)\n",
    "axs[1].set_ylabel(r'$T_3$')\n",
    "axs[1].set_xlabel(r'$x$')\n",
    "#_ = plt.title('Distribution at initialisation')\n",
    "\n",
    "fig.tight_layout()\n",
    "if SAVE_PLOT:\n",
    "  fig.savefig(PLOT_FOLDER / 'initialisation_distribution.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnpdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
