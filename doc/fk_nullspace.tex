\section{Null space of FK}
The FK tables can be regarded as a linear map from the space of PDFs to the space of 
data:
\begin{align}
  \FKtab : \mathbb{R}^{\PDF} \rightarrow \mathbb{R}^{\ndat} \,.
\end{align}
Note that the matrix corresponding to this linear map is not square, and hence $\FKtab 
\neq \FKtabT$. We can define the null space of the FK tables
\begin{equation}
  \ker \FKtab \equiv K_{\FKtab} = 
  \left\{
    f \in \mathbb{R}^{\PDF} \; : \; \FKtab \, f = 0
  \right\} \, ,
  \label{eq:ker_FK}
\end{equation}
together with its orthogonal space
\begin{equation}
  R_{\FKtab} \equiv K_{\FKtab}^{\bot} = 
  \left\{
    f \in \mathbb{R}^{\PDF} \; : \; f \cdot f_K = 0,
    \hspace{2mm} \forall f_K \in K_{\FKtab}
  \right\}\,.
\end{equation}
Note that 
\begin{align}
  \label{eq:KerFK->KerM}
  \FKtab f = 0 \Longrightarrow M f = 0\, .
\end{align}
The converse is also true, 
\begin{align}
  M f = 0 &\Longrightarrow (f, Mf) = 0 \\
    &\Longrightarrow (\FKtab f, C_Y^{-1} \FKtab f) = 0 \\
    &\Longrightarrow \FKtab f = 0\, ,
\end{align}
where the last inequality follows from the fact that $C_Y>0$.

For each of these two subspaces we can define a basis
\begin{align}
  & \B_{K} = \left\{ \pmb{u}^{(i)}_{K}\,, \hspace{2mm}  i=1,\dots, \dim K_{\FKtab} \right\} \,,\\
  & \B_{\bot} = \left\{ \pmb{u}^{(i)}_{\bot}\,, \hspace{2mm}  i=1,\dots, \dim R_{\FKtab} \right\} \,.
  \label{eq:FK_basis}
\end{align}
Remember that $K_{\FKtab} \bigoplus R_{\FKtab} = \mathbb{R}^{\PDF}$ and thus the basis $\B = \B_{K}
\bigoplus \B_{\bot}$ is a basis for $\mathbb{R}^{\PDF}$. Henceforth, when decomposing a vector in $\RPDF$, I 
will use the ordering $\left\{ \B_{K}, \B_{\bot} \right\}$. Hence, given $\pmb{f}\in \RPDF$, we can
write
\begin{equation}
  \pmb{f} = \pmb{f}_{K} + \pmb{f}_{\bot} 
          = \bpmat 
              f_K \\[2pt]
              f_{\bot}
            \epmat \,.
\end{equation}
Finally, note that $\FKtab$ is not symmetric (not even square). Thus, the right null space is not the same
as the left null space, in particular
\begin{align}
  \FKtab \pmb{u}_K = 0  \; \nRightarrow \; \pmb{u}_K^T \FKtab = 0 \,.
\end{align}

With the two bases in eqs.~\eqref{eq:FK_basis}, we can decompose the $\FKtab$ as follows
\begin{equation}
  \FKtab =
  \bpmat
    \FKtab_{KK}     & \FKtab_{K\bot} \\[3pt]
    \FKtab_{\bot K} & \FKtab_{\bot\bot}
  \epmat \,,
\end{equation}
where
\begin{align}
  \FKtab_{B_1 B_2} = \sum_{i=1}^{\dim\B_1} \sum_{j=1}^{\dim\B_2}
  \bra{u_{\B_1}^{(i)}} \FKtab \ket{u_{\B_2}^{(j)}} \;
  \ket{u_{\B_1}^{(i)}} \bra{u_{\B_2}^{(j)}}\,,
  \hspace{5mm}
  \B_1, \B_2 = K_{\FKtab}, R_{\FKtab}\,.
  \label{eq:fk->B1B2}
\end{align}
By definition of the kernel, we also have
\begin{align}
  \FKtab_{KK} = \FKtab_{\bot K} = 0 \,,
\end{align}
while $\FKtab_{K\bot}$ would be zero only if $\FKtab$ was diagonal. Thus, in the basis
$\B$, the FK tables can be expressed as
\begin{align}
  \FKtab =
  \bpmat
    0  & \FKtab_{K\bot} \\[3pt]
    0 & \FKtab_{\bot\bot}
  \epmat \,.
\end{align}
The product with a vector $\pmb{f} \in \RPDF$ becomes
\begin{equation}
  \FKtab \pmb{f} =
    \bpmat
      0  & \FKtab_{K\bot} \\[3pt]
      0  & \FKtab_{\bot\bot}
    \epmat
    \bpmat 
      f_K \\[2pt]
      f_{\bot}
    \epmat
    = \biggl(\FKtab_{K\bot} + \FKtab_{\bot\bot}\biggr) f_{\bot} \,.
\end{equation}
The matrix $M$, eq.~\eqref{eq:MmatrixForLoss}, can also be decomposed as in Eq.~\eqref{eq:fk->B1B2}. However, now
$M=M^T$ and thus only one component is non-zero:
\begin{align}
  M =
  \bpmat
    0 & 0 \\[3pt]
    0 & M_{\bot\bot}
  \epmat \,.
  \label{eq:fk_projection_basis}
\end{align}
We can decompose the other elements in eq.~\eqref{eq:ft_b_ThetaMft} in a similar vein:
\begin{align}
  b = \bpmat b_{K} \\[3pt] b_{\bot} \epmat \,,
  \hspace{5mm}
  \Theta = \bpmat
    \Theta_{KK} & \Theta_{K\bot} \\[3pt]
    \Theta_{\bot K} & \Theta_{\bot\bot}
  \epmat \,,
\end{align}
where $\Theta \in \RRPDF$ and can thus be projected in $\mathcal{B}$. Owing to this decomposition,
we can now split eq.~\eqref{eq:ft_b_ThetaMft} into the two components of $f_t$, so that we are
left with two coupled linear differential equations:
\begin{equation}
  \label{eq:SysDiffEqsFt}
  \begin{cases}
    \ddt f_{\bot} = b_{\bot} - \Theta_{\bot\bot} M_{\bot\bot} f_{\bot} \,,\\[5pt]
    \ddt f_{K} = b_{K} - \Theta_{K\bot} M_{\bot\bot} f_{\bot} \,,\\
  \end{cases}
\end{equation}
where the dependence on the training time $t$ is left implicit. From eq.~\eqref{eq:SysDiffEqsFt}
we see that $f_{K}$ does \textit{not} evolve linearly, but depends on the evolution of $f_{\bot}$.
Moreover, the differential equation for $f_{\bot}$ is diagonal, and can be solved as shown in the
main text, namely diagonalising $M_{\bot \bot}$. Note that, in the orthogonal subspace, $M_{\bot \bot}$
is positive-definite as we have projected out the null eigenvalues.