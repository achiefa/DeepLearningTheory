{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validphys.api import API\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from validphys.fkparser import load_fktable\n",
    "from collections import defaultdict\n",
    "\n",
    "from typing import List, Dict\n",
    "from collections import namedtuple\n",
    "\n",
    "from n3fit.layers import DIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed for the initialisation of the neural network\n",
    "seed = 1341351341"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flavour and Evolution info for rotation matrix\n",
    "PID_map = {\n",
    "  'd'    : 1,\n",
    "  'u'    : 2,\n",
    "  's'    : 3,\n",
    "  'c'    : 4,\n",
    "  'b'    : 5,\n",
    "  'dbar' : -1,\n",
    "  'ubar' : -2,\n",
    "  'sbar' : -3,\n",
    "  'cbar' : -4,\n",
    "  'bbar' : -5,\n",
    "  'g'    : 21\n",
    "}\n",
    "\n",
    "# Flavour combination map for FK tables\n",
    "FK_basis = {\n",
    "        0: r\"$g$\",\n",
    "        1: r\"$T_{3}$\",\n",
    "        2: r\"$T_{{8}}$\",\n",
    "        3: r\"$T_{15} (c^-)$\",\n",
    "        4: r\"$\\Sigma$\",\n",
    "        5: r\"$V_3$\",\n",
    "        6: r\"$V_8$\",\n",
    "        7: r\"$V_{15}$\",\n",
    "        8: r\"$V$\"}\n",
    "\n",
    "flavour_map = [\n",
    "        {'fl': 'u'},\n",
    "        {'fl': 'ubar'},\n",
    "        {'fl': 'd'},\n",
    "        {'fl': 'dbar'},\n",
    "        {'fl': 's'},\n",
    "        {'fl': 'sbar'},\n",
    "        {'fl': 'c'},\n",
    "        {'fl': 'g'},\n",
    "    ]\n",
    "\n",
    "NN31IC_ev_basis = {\n",
    "  0: r\"$\\Sigma$\",\n",
    "  1: r\"$g$\",\n",
    "  2: r\"$V$\",\n",
    "  3: r\"$V_3$\",\n",
    "  4: r\"$V_8$\",\n",
    "  5: r\"$T_3$\",\n",
    "  6: r\"$T_8$\",\n",
    "  7: r\"$c^+$\",\n",
    "  8: r\"$V_{15}$\"\n",
    "}\n",
    "\n",
    "from n3fit.layers import FlavourToEvolution, FkRotation\n",
    "from n3fit.backends import operations as op\n",
    "\n",
    "rotmat = FlavourToEvolution(flavour_map, \"FLAVOUR\")\n",
    "layer_evln = FkRotation(output_dim=14, name=\"pdf_FK_basis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flav_info = [{'fl': 'sng',  'trainable': False, 'smallx': [0,0],  'largex': [0,0]}, \n",
    "             {'fl': 'g',    'trainable': False, 'smallx': [0,0],  'largex': [0,0]}, \n",
    "             {'fl': 'v',    'trainable': False, 'smallx': [0,0],  'largex': [0,0]}, \n",
    "             {'fl': 'v3',   'trainable': False, 'smallx': [0,0],  'largex': [0,0]}, \n",
    "             {'fl': 'v8',   'trainable': False, 'smallx': [0,0],  'largex': [0,0]}, \n",
    "             {'fl': 't3',   'trainable': False, 'smallx': [0,0],  'largex': [0,0]}, \n",
    "             {'fl': 't8',   'trainable': False, 'smallx': [0,0],  'largex': [0,0]}, \n",
    "             {'fl': 't15',  'trainable': False, 'smallx': [0,0],  'largex': [0,0]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from n3fit import model_gen\n",
    "\n",
    "# arugments for NNPDF model generation\n",
    "model_parameters = {\n",
    "  'nodes' : [25, 20, 8],\n",
    "  'activations' : ['tanh', 'tanh', 'linear'],\n",
    "  'layer_type' : 'dense',\n",
    "  'flav_info' : flav_info,\n",
    "  'fitbasis' : 'EVOL',\n",
    "  'seed' : seed,\n",
    "  'initializer_name' : 'glorot_normal',\n",
    "  'dropout' : 0.0,\n",
    "  'regularizer' : None,\n",
    "  'regularizer_args' : None,\n",
    "  'impose_sumrule' : True,\n",
    "  'scaler' : None,\n",
    "  'num_replicas' : 1,\n",
    "  'photons' : None\n",
    "}\n",
    "\n",
    "pdf_model = model_gen.pdfNN_layer_generator(**model_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of DIS dataset\n",
    "dataset_inputs = [\n",
    "  #{'dataset': 'NMC_NC_NOTFIXED_DW_EM-F2', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'NMC_NC_NOTFIXED_P_EM-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'SLAC_NC_NOTFIXED_P_DW_EM-F2', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'SLAC_NC_NOTFIXED_D_DW_EM-F2', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'BCDMS_NC_NOTFIXED_P_DW_EM-F2', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'BCDMS_NC_NOTFIXED_D_DW_EM-F2', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'CHORUS_CC_NOTFIXED_PB_DW_NU-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'CHORUS_CC_NOTFIXED_PB_DW_NB-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'NUTEV_CC_NOTFIXED_FE_DW_NU-SIGMARED', 'cfac': ['MAS'], 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'NUTEV_CC_NOTFIXED_FE_DW_NB-SIGMARED', 'cfac': ['MAS'], 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'HERA_NC_318GEV_EM-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'HERA_NC_225GEV_EP-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'HERA_NC_251GEV_EP-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'HERA_NC_300GEV_EP-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'HERA_NC_318GEV_EP-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'HERA_CC_318GEV_EM-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'HERA_CC_318GEV_EP-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'HERA_NC_318GEV_EAVG_CHARM-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'HERA_NC_318GEV_EAVG_BOTTOM-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequential_model(outputs=1, \n",
    "                   input_layer=None, \n",
    "                   nlayers=2, \n",
    "                   units=[100,100],\n",
    "                   seed=seed,\n",
    "                   **kwargs):\n",
    "  \"\"\"\n",
    "  Create a tensorflow sequential model where all intermediate layers have the same size\n",
    "  This function accepts an already constructed layer as the input.\n",
    "\n",
    "  All hidden layers will have the same number of nodes for simplicity\n",
    "\n",
    "  Arguments:\n",
    "      outputs: int (default=1)\n",
    "          number of output nodes (how many flavours are we training)\n",
    "      input_layer: KerasTensor (default=None)\n",
    "          if given, sets the input layer of the sequential model\n",
    "      nlayers: int\n",
    "          number of hidden layers of the network\n",
    "      units: int\n",
    "          number of nodes of every hidden layer in the network\n",
    "      activation: str\n",
    "          activation function to be used by the hidden layers (ex: 'tanh', 'sigmoid', 'linear')\n",
    "  \"\"\"\n",
    "  if len(units) != nlayers:\n",
    "      raise Exception(\"The length of units must match the number of layers.\")\n",
    "  \n",
    "  if kwargs.get('kernel_initializer'):\n",
    "      kernel_initializer = kwargs['kernel_initializer']\n",
    "  else:\n",
    "      kernel_initializer = tf.keras.initializers.HeNormal\n",
    "\n",
    "  if kwargs.get('activation_list'):\n",
    "      activation_list = kwargs['activation_list']\n",
    "      if len(units) != len(activation_list):\n",
    "          raise Exception(\"The length of the activation list must match the number of layers.\")\n",
    "  else:\n",
    "      activation_list = ['tanh' for _ in range(nlayers)]\n",
    "\n",
    "  if kwargs.get('output_func'):\n",
    "      output_func = kwargs['output_func']\n",
    "  else:\n",
    "      output_func = 'linear'\n",
    "  \n",
    "  if kwargs.get('name'):\n",
    "      name = kwargs['name']\n",
    "  else:\n",
    "      name = 'pdf'\n",
    "  \n",
    "  model = tf.keras.models.Sequential(name=name)\n",
    "  if input_layer is not None:\n",
    "      model.add(input_layer)\n",
    "  for layer in range(nlayers):\n",
    "      model.add(tf.keras.layers.Dense(units[layer], \n",
    "                                      activation=activation_list[layer],\n",
    "                                      kernel_initializer=kernel_initializer(seed=seed - layer),\n",
    "                                      ),\n",
    "      )\n",
    "  model.add(tf.keras.layers.Dense(outputs, \n",
    "                                  activation=output_func, \n",
    "                                  kernel_initializer=kernel_initializer(seed=seed - nlayers)\n",
    "                                  ))\n",
    "\n",
    "  return model\n",
    "\n",
    "def compute_ntk(model, input):\n",
    "  # Record operations for gradient computation\n",
    "  batch_size = input.size\n",
    "  n_outputs = model.layers[-1].units\n",
    "  x = tf.convert_to_tensor(input)\n",
    "  x = tf.reshape(x, shape=(-1,1))\n",
    "  with tf.GradientTape(persistent=True) as tape:\n",
    "      tape.watch(x)\n",
    "      # Forward pass\n",
    "      predictions = model(x)\n",
    "\n",
    "  jacobian = tape.jacobian(predictions, model.trainable_variables)  \n",
    "\n",
    "  ntk = tf.zeros((n_outputs, batch_size, n_outputs, batch_size))\n",
    "  for jac in jacobian:\n",
    "      jac_concat = tf.reshape(jac, (jac.shape[1], jac.shape[0], np.prod(jac.shape[2:]))) \n",
    "      ntk += tf.einsum('iap,jbp->iajb', jac_concat, jac_concat)  \n",
    "  return ntk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for validphys API\n",
    "common_dict = dict(\n",
    "    dataset_inputs=dataset_inputs,\n",
    "    metadata_group=\"nnpdf31_process\",\n",
    "    use_cuts='internal',\n",
    "    datacuts={'t0pdfset': '240701-02-rs-nnpdf40-baseline', 'q2min': 3.49, 'w2min': 12.5},\n",
    "    theoryid=40000000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_data = API.procs_data(**common_dict)\n",
    "groups_index = API.groups_index(**common_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below loops over the selected dataset and collects FK tables, $x$-grids, and central data $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the dictionaries\n",
    "fk_table_list = defaultdict(list)\n",
    "x_grid_list = defaultdict(list)\n",
    "Y = defaultdict(list)\n",
    "\n",
    "# Useful information for indexing the datasets\n",
    "total_ndata_wc = 0\n",
    "total_grid_size = 0\n",
    "start_grid_by_exp = defaultdict(list)\n",
    "grid_size_by_exp = defaultdict(list)\n",
    "start_proc_by_exp = defaultdict(list)\n",
    "exp_size = defaultdict(list)\n",
    "\n",
    "for idx_proc, group_proc in enumerate(groups_data):\n",
    "  for idx_exp, exp_set in enumerate(group_proc.datasets):\n",
    "\n",
    "    fkspecs = exp_set.fkspecs\n",
    "    cuts = exp_set.cuts\n",
    "    ndata = exp_set.load_commondata().ndata\n",
    "    fk_table = load_fktable(fkspecs[0])\n",
    "    fk_table_wc = fk_table.with_cuts(cuts)\n",
    "    x_grid = fk_table_wc.xgrid\n",
    "    fk_table_wc_np = fk_table_wc.get_np_fktable()\n",
    "\n",
    "    Y[exp_set.name] = exp_set.load_commondata().with_cuts(cuts).central_values.to_numpy()\n",
    "    fk_table_list[exp_set.name] = fk_table_wc_np\n",
    "    x_grid_list[exp_set.name] = x_grid\n",
    "    start_proc_by_exp[exp_set.name] = total_ndata_wc\n",
    "    start_grid_by_exp[exp_set.name] = total_grid_size\n",
    "    grid_size_by_exp[exp_set.name] = x_grid.shape[0]\n",
    "    total_grid_size += x_grid.shape[0]\n",
    "    total_ndata_wc += ndata\n",
    "    exp_size[exp_set.name] = ndata\n",
    "\n",
    "# Flatten x-grids\n",
    "x_grid_flat = np.concatenate([grid for grid in x_grid_list.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to generate the model. It can be one single replica, or many replicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate NNPDF model\n",
    "replicas = 1\n",
    "\n",
    "if replicas == 1:\n",
    "  nnpdf = generate_sequential_model(outputs=9, nlayers=2, units=[28, 20],seed=seed, name='NNPDF', kernel_initializer=tf.keras.initializers.GlorotNormal)\n",
    "else:\n",
    "  raise ValueError('Ensemble generation not yet implemented.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the experimental covariance matrix and compute its inverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = API.groups_covmat_no_table(**common_dict)\n",
    "Cinv = np.linalg.inv(C)\n",
    "Cinv = pd.DataFrame(Cinv, index=C.index, columns=C.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then compute the NTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NTK = compute_ntk(nnpdf, x_grid_flat).numpy()\n",
    "NTK = NTK.reshape((NTK.shape[0] * NTK.shape[1], NTK.shape[2] * NTK.shape[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the matrix $M$ defined as $M = (FK)^T C^{-1}_Y (FK)$.\n",
    "\n",
    "**Implementation details**\n",
    "\n",
    "Each data set is provided with an FK table whose dimensions are $(N_{\\textrm{dat}},\\; N_f, \\; N_{\\textrm{grid}})$. I do the following steps\n",
    "1. Flatten the last two dimensions of the FK tables, such that $(N_{\\textrm{dat}},\\; N_f, \\; N_{\\textrm{grid}}) \\rightarrow (N_{\\textrm{dat}},\\; N_f, \\times N_{\\textrm{grid}})$.\n",
    "2. Build the FK table of the entire dataset defined as the block diagonal matrix made of the flattened FK tables\n",
    "    $$\n",
    "      FK_{\\mathcal{D}} = \\left(\\begin{matrix}\n",
    "      (FK)_{I_1} && 0 && \\cdots && 0 \\\\[5pt]\n",
    "      0 && (FK)_{I_2} && \\cdots && 0 \\\\[5pt]\n",
    "      \\vdots && \\vdots && \\ddots && \\vdots \\\\[5pt]\n",
    "      0 && 0 && \\cdots && (FK)_{I_D}\n",
    "      \\end{matrix} \\right) \\,,\n",
    "    $$\n",
    "    where $I_i$, $i=1,\\dots, D$ specifies the $i$-th dataset of the FK table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import block_diag\n",
    "ndat = sum([fk.shape[0] for fk in fk_table_list.values()])\n",
    "FK = np.zeros(shape=(ndat, 9, x_grid_flat.size))\n",
    "\n",
    "flatten_fks = []\n",
    "exp_start_proc = defaultdict(list)\n",
    "grid_fl_start_proc = defaultdict(list)\n",
    "grid_fl_size_by_exp = defaultdict(list)\n",
    "total_grid_fl_size = 0\n",
    "total_data_size = 0\n",
    "exp_ordering = []\n",
    "for exp, fk in fk_table_list.items():\n",
    "  fk_flatten = fk.reshape((fk.shape[0], fk.shape[1] * fk.shape[2]))\n",
    "  flatten_fks.append(fk_flatten)\n",
    "  exp_ordering.append(exp)\n",
    "  exp_start_proc[exp] = total_data_size\n",
    "  grid_fl_start_proc[exp] = total_grid_fl_size\n",
    "  grid_fl_size_by_exp[exp] = fk_flatten.shape[1]\n",
    "  total_data_size += fk_flatten.shape[0]\n",
    "  total_grid_fl_size += fk_flatten.shape[1]\n",
    "\n",
    "FK = block_diag(*flatten_fks)\n",
    "\n",
    "# Check that the ordering of the block diagonal matrix is the same as the inverse covariance matrix.\n",
    "for val1, val2 in zip(Cinv.index.get_level_values(level='dataset').unique().to_list(), exp_ordering):\n",
    "  try:\n",
    "    assert(val1 == val2)\n",
    "  except:\n",
    "    AssertionError(\"The ordering is not the same\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now construct the matrix M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = FK.T @ Cinv @ FK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularise the matrix through the identity and invert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_id = 0.0001\n",
    "Mr = M + eta_id * np.identity(M.shape[0])\n",
    "Mr_inv = np.linalg.inv(Mr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the matrix that governs the evolution $H = \\Theta M_R$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = NTK @ Mr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I compute the normalisation $K = M_R^{-1} A^T C_Y^{-1} y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for exp in exp_ordering:\n",
    "  y.append(Y[exp])\n",
    "\n",
    "y = np.concatenate(y)\n",
    "K = Mr_inv @ FK.T @ Cinv @ y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the network predictions at initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = nnpdf(x_grid_flat).numpy()\n",
    "flav_grid_shape = f0.shape\n",
    "f0 = f0.reshape(-1)\n",
    "\n",
    "input = np.logspace(-7,1,633).reshape(1,-1)\n",
    "pdf_output = pdf_model.predict( {\"pdf_input\": x_grid_flat.reshape(1,-1)}, verbose=False)\n",
    "test_output = pdf_model.predict( {\"pdf_input\": input}, verbose=False)\n",
    "# transform to 8 flavor basis: sigma, g, v, v3, v8, v15, t3, t8, t15\n",
    "pdf_output = pdf_output[0,0,:,[1,2,3,4,5,6,9,10,11]]\n",
    "test_output = test_output[0,0,:,[1,2,3,4,5,6,9,10,11]]\n",
    "#out = out.reshape((out.shape[2], out.shape[3]))\n",
    "f0 = pdf_output.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating the gradient flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing the integrated solution\n",
    "$$\n",
    "f(t) = e^{-Ht} f_0 + \\left( I -  e^{-Ht} \\right) K \\,.\n",
    "$$\n",
    "We can introduce the eigenspace of the operator $H$\n",
    "$$\n",
    "H v^{(k)} = \\lambda_k v^{(k)} \\,, \\hspace{5mm} k = 1, \\dots, \\textrm{eig}(H)\\,.\n",
    "$$\n",
    "The vector $v^{(k)} \\in \\mathbb{R}^{N_{grid} \\times N_f}$ is the eigenvector relative to the $k$-th eigenvalue $\\lambda_k$ for the matrix $H$. We can project the integrated equation in the eigenspace of $H$\n",
    "$$\n",
    "\\begin{split}\n",
    "f^{\\alpha}(t) & = \\sum_{k = 1}^{\\textrm{eig}(H)} \\left[  e^{- t \\lambda_k} \\; \\widetilde{f}_0^{(k)} + \\left( 1 - e^{- t\\lambda_k} \\right) \\widetilde{K}^{(k)} \\right] \\; v^{(k)} \\\\\n",
    "& = \\sum_{k = 1}^{\\textrm{eig}(H)} \\left[  C_1^{(k)} + C_2^{(k)} \\right] \\; v^{(k)} \\,,\n",
    "\\end{split}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "C_1^{(k)} = e^{- t \\lambda_k} \\; \\widetilde{f}_0^{(k)} \\\\\n",
    "C_2^{(k)} = \\left( 1 - e^{- t\\lambda_k} \\right) \\widetilde{K}^{(k)}\n",
    "$$\n",
    "and $\\widetilde{f}_0$, $\\widetilde{K}$ are the components of the respective vectors in the eigenspace of $H$\n",
    "$$\n",
    "\\widetilde{f}_0^{(k)} = \\left< f_0, v^{(k)} \\right> \\,,\\\\\n",
    "\\widetilde{K}^{(k)} = \\left< K, v^{(k)} \\right> \\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "eigvals, eigvecs = np.linalg.eig(H)\n",
    "eigvals = eigvals.real\n",
    "eigvecs = eigvecs.real\n",
    "\n",
    "def integrate_flow_t(t, eigvals=eigvals, eigvecs=eigvecs):\n",
    "\n",
    "  f0_tilde = [np.dot(f0, eigvecs[:, k]) for k in range(eigvals.size)]\n",
    "  K_tilde = [np.dot(K, eigvecs[:, k]) for k in range(eigvals.size)]\n",
    "\n",
    "  output = np.zeros(shape=K.shape[0])\n",
    "  for k in range(35):\n",
    "      C1_k = f0_tilde[k] * np.exp(- eigvals[k] * t)\n",
    "      C2_k = (1 - np.exp(- eigvals[k] * t) ) * K_tilde[k]\n",
    "      output = np.add(output, (C1_k + C2_k) * eigvecs[:,k])\n",
    "\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and rotate NNPDF PDF\n",
    "pdf = API.pdf(pdf=\"240203-02-ak-ht-tcm-disonly\")\n",
    "pdf_loaded = pdf.load()\n",
    "pdf_central = pdf_loaded.central_member\n",
    "\n",
    "xgrid_unique_values, indices = np.unique(x_grid_flat, return_index=True)\n",
    "\n",
    "pdf_outs = []\n",
    "for x in xgrid_unique_values:\n",
    "  aux = pdf_central.xfxQ2(x, 1.65**2)\n",
    "  pdf_outs.append([ aux[PID_map[i['fl']]] for i in flavour_map])\n",
    "\n",
    "pdf_outs = np.array(pdf_outs)\n",
    "pdf_outs =np.expand_dims(pdf_outs, axis=[0, 1]) # Add batch, replica, x dimensions\n",
    "pdf_outs = op.numpy_to_tensor(pdf_outs)\n",
    "\n",
    "out_rotated = rotmat(pdf_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_grid_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate as scint\n",
    "fig, axes = plt.subplots(3, 3, figsize=(25, 25))  # Adjust figsize for desired plot size\n",
    "\n",
    "\n",
    "t = 100000\n",
    "out = integrate_flow_t(t)\n",
    "g = FK @ out\n",
    "out = out.reshape(flav_grid_shape)\n",
    "k = K.to_numpy().reshape(flav_grid_shape)\n",
    "\n",
    "x_plot = np.logspace(-5, -4, 100)\n",
    "# Example data for each subplot\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    y = out[:,i]\n",
    "    y = y - y[-1]\n",
    "    ax.scatter(x_grid_flat, y)\n",
    "    ax.scatter(x_grid_flat, k[:,i], color='red')\n",
    "    #ax.scatter(input, test_output[i,:], color='red')\n",
    "    #ax.plot(xgrid_unique_values, out_rotated[0,0,:,i], color='red')\n",
    "    ax.set_xlabel(r'$x$')\n",
    "    ax.set_ylabel(NN31IC_ev_basis[i], fontsize=15)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim(1e-5,1.)\n",
    "\n",
    "# Adjust layout to prevent overlapping titles and labels\n",
    "plt.tight_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnpdf_doc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
