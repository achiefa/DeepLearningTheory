{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validphys.api import API\n",
    "import sys\n",
    "\n",
    "# Add the path to the library folder\n",
    "sys.path.append('./lib')\n",
    "\n",
    "from utils import XGRID, build_fk_matrix, regularize_matrix\n",
    "from model import PDFmodel, generate_mse_loss\n",
    "from gen_dicts import generate_dicts\n",
    "from validphys.api import API\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 14132124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of DIS dataset\n",
    "dataset_inputs = [\n",
    "  #{'dataset': 'NMC_NC_NOTFIXED_DW_EM-F2', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'NMC_NC_NOTFIXED_P_EM-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'SLAC_NC_NOTFIXED_P_DW_EM-F2', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'SLAC_NC_NOTFIXED_D_DW_EM-F2', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'BCDMS_NC_NOTFIXED_P_DW_EM-F2', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'BCDMS_NC_NOTFIXED_D_DW_EM-F2', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'CHORUS_CC_NOTFIXED_PB_DW_NU-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'CHORUS_CC_NOTFIXED_PB_DW_NB-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'NUTEV_CC_NOTFIXED_FE_DW_NU-SIGMARED', 'cfac': ['MAS'], 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'NUTEV_CC_NOTFIXED_FE_DW_NB-SIGMARED', 'cfac': ['MAS'], 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'HERA_NC_318GEV_EM-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'HERA_NC_225GEV_EP-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'HERA_NC_251GEV_EP-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'HERA_NC_300GEV_EP-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'HERA_NC_318GEV_EP-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'HERA_CC_318GEV_EM-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'HERA_CC_318GEV_EP-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'HERA_NC_318GEV_EAVG_CHARM-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'HERA_NC_318GEV_EAVG_BOTTOM-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "]\n",
    "\n",
    "# Dictionary for validphys API\n",
    "common_dict = dict(\n",
    "    dataset_inputs=dataset_inputs,\n",
    "    metadata_group=\"nnpdf31_process\",\n",
    "    use_cuts='internal',\n",
    "    datacuts={'q2min': 3.49, 'w2min': 12.5},\n",
    "    theoryid=40000000,\n",
    "    t0pdfset='NNPDF40_nnlo_as_01180',\n",
    "    use_t0=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve data from NNPDF\n",
    "groups_data = API.procs_data(**common_dict)\n",
    "tuple_of_dicts = generate_dicts(groups_data)\n",
    "fk_table_dict = tuple_of_dicts.fk_tables\n",
    "central_data_dict = tuple_of_dicts.central_data\n",
    "FK = build_fk_matrix(fk_table_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHAPDF 6.5.4 loading /opt/homebrew/Caskroom/miniconda/base/envs/nnpdf/share/LHAPDF/NNPDF40_nnlo_as_01180/NNPDF40_nnlo_as_01180_0000.dat\n",
      "NNPDF40_nnlo_as_01180 PDF set, member #0, version 1; LHAPDF ID = 331100\n"
     ]
    }
   ],
   "source": [
    "C = API.groups_covmat_no_table(**common_dict)\n",
    "\n",
    "# Serialize covmat\n",
    "C_index = C.index\n",
    "C_col = C.columns\n",
    "Cinv = np.linalg.inv(C)\n",
    "Cinv = pd.DataFrame(Cinv, index=C_index, columns=C_col)\n",
    "\n",
    "# Diagonalize covariance matric\n",
    "eigvals_Cinv, R_Y = np.linalg.eigh(Cinv)\n",
    "if eigvals_Cinv[-1] > eigvals_Cinv[0]:\n",
    "    eigvals_Cinv = eigvals_Cinv[::-1]\n",
    "    R_Y = R_Y[:,::-1]\n",
    "D_Y = np.zeros_like(R_Y)\n",
    "np.fill_diagonal(D_Y, eigvals_Cinv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dataframe for predictions\n",
    "Y = pd.DataFrame(np.zeros(Cinv.shape[0]), index=Cinv.index)\n",
    "for exp_name, data in central_data_dict.items():\n",
    "  if data.size == Y.loc[(slice(None), [exp_name], slice(None)), :].size:\n",
    "    Y.loc[(slice(None), [exp_name], slice(None)), :] = data\n",
    "  else:\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnpdf_model = PDFmodel(input=XGRID,\n",
    "                       outputs=9,\n",
    "                       architecture=[28,20],\n",
    "                       activations=['tanh', 'tanh'],\n",
    "                       kernel_initializer='RandomNormal',\n",
    "                       user_ki_args={'mean': 0.0, 'stddev': 1.0},\n",
    "                       seed=seed,\n",
    "                       dtype='float64')\n",
    "NTK = nnpdf_model.compute_ntk()\n",
    "\n",
    "# Flatten NTK\n",
    "prod = 1\n",
    "oldshape = NTK.shape\n",
    "for k in oldshape[2:]:\n",
    "    prod *= k\n",
    "NTK_flat = np.array(NTK).reshape(prod,-1)\n",
    "\n",
    "eigvals_NTK, eigvecs_NTK = np.linalg.eigh(NTK_flat)\n",
    "if eigvals_NTK[-1] > eigvals_NTK[0]:\n",
    "  eigvals_NTK = eigvals_NTK[::-1]\n",
    "  eigvecs_NTK = eigvecs_NTK[:,::-1]\n",
    "\n",
    "\n",
    "# Compute predictions at initialization\n",
    "f0 = nnpdf_model.predict(squeeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from GD training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('training.pkl', 'rb') as file:\n",
    "    results = pickle.load(file)\n",
    "\n",
    "pred_in_time = results[1]\n",
    "pdfs_in_time = results[2]\n",
    "learning_rate_gd = 0.00000001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing matrices from notes\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below computes the following matrices\n",
    "$$\n",
    "M = (FK)^T C_Y^{-1} (FK) = RDR^T\\\\[10pt]\n",
    "\\tilde{H} = D^{1/2} R^T \\Theta_t R  D^{1/2}   \\\\[10pt]\n",
    "\\tilde{H}_{\\epsilon} = D^{1/2}_Y R^T_Y (FK) \\Theta (FK)^T R_Y D^{1/2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $M = (FK)^T C_Y^{-1} (FK) = RDR^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = FK.T @ Cinv.to_numpy() @ FK\n",
    "M, (eigvals_M, R) = regularize_matrix(M)\n",
    "\n",
    "# Construct diagonal matrix\n",
    "D = np.zeros_like(R)\n",
    "np.fill_diagonal(D, eigvals_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntk, (eigvals_ntk, R_ntk) = regularize_matrix(NTK_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\tilde{H} = D^{1/2} R^T \\Theta R D^{1/2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is symmetric: True\n"
     ]
    }
   ],
   "source": [
    "H_tilde = np.sqrt(D) @ R.T @ ntk @ R @ np.sqrt(D)\n",
    "\n",
    "# Check if symmetric\n",
    "print(f'Is symmetric: {np.allclose(H_tilde, H_tilde.T)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\tilde{H_{\\epsilon}} = D^{1/2} R^T \\Theta R D^{1/2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_eps = np.sqrt(D_Y) @ R_Y.T @ FK @ NTK_flat @ FK.T @ R_Y @ np.sqrt(D_Y)\n",
    "M = FK.T @ Cinv @ FK\n",
    "b = NTK_flat @ FK.T @ Cinv @ Y\n",
    "\n",
    "# Check that matrix H_eps is symmetric\n",
    "try:\n",
    "    assert(np.allclose(H_eps, H_eps.T, rtol = 5*1e-4, atol = 1e-8))\n",
    "except AssertionError:\n",
    "    print(f'Matrix H_eps is not symmetric due to numerical error...')\n",
    "    H_eps = 0.5 * (H_eps + H_eps.T)\n",
    "\n",
    "eigvals_H_eps, eigvecs_H_eps = np.linalg.eigh(H_eps)\n",
    "if eigvals_H_eps[-1] > eigvals_H_eps[0]:\n",
    "  eigvals_H_eps = eigvals_H_eps[::-1]\n",
    "  eigvecs_H_eps = eigvecs_H_eps[:,::-1]\n",
    "\n",
    "# Check that matrix M is symmetric\n",
    "try:\n",
    "    assert(np.allclose(M, M.T))\n",
    "except AssertionError:\n",
    "    print(f'Matrix M is not symmetric')\n",
    "else:\n",
    "    eigvals_M, R = np.linalg.eigh(M)\n",
    "    if eigvals_M[-1] > eigvals_M[0]:\n",
    "      eigvals_M = eigvals_M[::-1]\n",
    "      R = R[:,::-1]\n",
    "\n",
    "    # Round eigenvalues to zero\n",
    "    for i in range(eigvals_M.size):\n",
    "      eigvals_M[i] = round_float32(eigvals_M[i], eigvals_M[0], tol_magnitude=1.e-8)\n",
    "\n",
    "    # Build diagonal matrix D\n",
    "    D = np.diag(eigvals_M)\n",
    "\n",
    "# Compute matrix H_tilde\n",
    "H_tilde = np.sqrt(D) @ R.T @ NTK_flat @ R @ np.sqrt(D)\n",
    "\n",
    "# Check that matrix H_tilde is symmetric\n",
    "try:\n",
    "    assert(np.allclose(H_tilde, H_tilde.T, rtol = 5*1e-4, atol = 1e-8))\n",
    "except AssertionError:\n",
    "    print(f'Matrix H_tilde is not symmetric')\n",
    "    H_tilde = 0.5 * (H_tilde + H_tilde.T)\n",
    "\n",
    "eigvals_H_tilde, eigvecs_H_tilde = np.linalg.eigh(H_tilde)\n",
    "if eigvals_H_tilde[-1] > eigvals_H_tilde[0]:\n",
    "  eigvals_H_tilde = eigvals_H_tilde[::-1]\n",
    "  eigvecs_H_tilde = eigvecs_H_tilde[:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_tilde = np.sqrt(D) @ R.T @ b.to_numpy()[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_utils import plot_eigvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_eigvals(eigvals_M, figsize=(10,8), title='')\n",
    "axs.text(0.1, 0.60, r'$M = (FK)^T C^{-1}_Y (FK)$', fontsize=20, transform=axs.transAxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_eigvals(eigvals_H_eps, figsize=(10,8), title=r'$H_{\\epsilon} = D^{1/2}_Y R^T_Y (FK) \\Theta (FK)^T R_Y D^{1/2}_Y$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_eigvals(eigvals_H_tilde, \n",
    "                        figsize=(10,8), \n",
    "                        title=r'$\\tilde{H}= D^{1/2} R^T \\Theta R D^{1/2}$,  $M = RDR^T$')\n",
    "fig.savefig('/Users/s2569857/Codes/DeepLearningTheory/doc/figs/Htilde_eigvals.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_eigvals(eigvals_NTK, figsize=(10,8), title='')\n",
    "axs.set_title(r'Eigenvalues of $\\Theta$', fontsize=20)\n",
    "fig.savefig('/Users/s2569857/Codes/DeepLearningTheory/doc/figs/ntk_eigvals.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_eigvals(eigvals_M, figsize=(10,8), title=r'Eigenvalues of $M = (FK)^T C_Y^{-1} (FK)$')\n",
    "#axs.set_title(r'Eigenvalues of $\\Theta$', fontsize=20)\n",
    "fig.savefig('/Users/s2569857/Codes/DeepLearningTheory/doc/figs/m_eigvals.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions for the null space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "def nullspace(matrix, orth_space=False, rcond=1.e-8):\n",
    "  ker = sp.linalg.null_space(matrix, rcond=rcond)\n",
    "\n",
    "  if orth_space:\n",
    "    # Compute SVD of the null space\n",
    "    _, _, Vh = np.linalg.svd(ker.T, full_matrices=True)\n",
    "    orthogonal_space = Vh[len(ker.T):].T\n",
    "    return ker, orthogonal_space\n",
    "  \n",
    "  else:\n",
    "    return ker\n",
    "  \n",
    "def project_matrix(matrix, basis):\n",
    "  basis_dim = basis.shape[1]\n",
    "  space_dim = basis.shape[0]\n",
    "  if space_dim != matrix.shape[1]:\n",
    "    raise ValueError ('The matrix cannot be projected into the basis')\n",
    "  \n",
    "  M_orth = np.zeros((basis_dim, basis_dim))\n",
    "  for i in range(basis_dim):\n",
    "    for j in range(basis_dim):\n",
    "      M_orth[i,j] = basis[:,i].T @ matrix @ basis[:,j]\n",
    "\n",
    "  return M_orth\n",
    "\n",
    "def project_vector(vector, basis):\n",
    "  basis_dim = basis.shape[1]\n",
    "  space_dim = basis.shape[0]\n",
    "  if space_dim != vector.shape[0]:\n",
    "    raise ValueError ('The matrix cannot be projected into the basis')\n",
    "  \n",
    "  res = [np.dot(vector, basis[:,i]) for i in range(basis_dim)]\n",
    "  return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null space of (FK)\n",
    "--------------------\n",
    "**This part is still WIP and it is not meant to be used.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FK tables and the matrix M should share the same null space. However, when the two null spaces are computed separately, they are different..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the null space of the matrix M and its orthogonal space\n",
    "m, n = FK.shape[0], FK.shape[1]\n",
    "rcond_FK = 1.e-8\n",
    "ker_M, ker_orth_M = nullspace(M, orth_space=True, rcond=rcond_FK)\n",
    "\n",
    "u_M, s_M, vh_M = np.linalg.svd(M, full_matrices=True)\n",
    "tol_M = np.amax(s_M, initial=0.) * rcond_FK\n",
    "\n",
    "# Regularise singular values\n",
    "# This is necessary as the process of finding the null space\n",
    "# introduces a tolerance for zero singular values. Effectively,\n",
    "# this is equivalent to the regularization of the matrix.\n",
    "for i in range(s_M.size):\n",
    "  if s_M[i] < tol_M:\n",
    "    s_M[i] = 0.0\n",
    "\n",
    "# Reconstruct M  after regularization\n",
    "smat_M = np.zeros((u_M.shape[0], vh_M.shape[0]), dtype=np.float32)\n",
    "smat_M[:vh_M.shape[0], :vh_M.shape[0]] = np.diag(s_M)\n",
    "M_reg = u_M @ smat_M @ vh_M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project M into the space orthogonal to ker(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_botbot = project_matrix(M_reg, ker_orth_M)\n",
    "NTK_botbot = project_matrix(NTK_flat, ker_orth_M)\n",
    "b_bot = project_vector(b.to_numpy()[:,0], ker_orth_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_botbot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null-space of $\\tilde{H}$\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the null space of the matrix $\\tilde{H}$ and its orthogonal space\n",
    "ker_Htilde, ker_orth_Htilde = nullspace(H_tilde, orth_space=True, rcond=1.e-8)\n",
    "\n",
    "# Project $\\tilde{H}$ in the orthogonal space\n",
    "H_tilde_proj = project_matrix(H_tilde, ker_orth_Htilde)\n",
    "\n",
    "# Invert matrix\n",
    "H_tilde_proj_inv = np.linalg.inv(H_tilde_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_tilde_proj = np.array(project_vector(b_tilde, ker_orth_Htilde))\n",
    "f0_flatten = f0.flat\n",
    "f0_tilde = np.sqrt(D) @ R.T @ f0_flatten\n",
    "f0_tilde_proj = np.array(project_vector(f0_tilde, ker_orth_Htilde))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eH = sp.linalg.expm(-learning_rate_gd * H_tilde_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Id = np.eye(eH.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_tilde_t = eH @ f0_tilde_proj + (Id - eH) @ H_tilde_proj_inv @ b_tilde_proj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(D).diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.linalg.inv(np.sqrt(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_utils import plot_PDFs\n",
    "fig, axs = plot_PDFs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolution of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "# Construct dataframe for predictions\n",
    "Y = pd.DataFrame(np.zeros(Cinv.shape[0]), index=Cinv.index)\n",
    "for exp_name, data in central_data_dict.items():\n",
    "  if data.size == Y.loc[(slice(None), [exp_name], slice(None)), :].size:\n",
    "    Y.loc[(slice(None), [exp_name], slice(None)), :] = data\n",
    "  else:\n",
    "    raise ValueError\n",
    "  \n",
    "eps_0 = Y.to_numpy()[:,0] - FK @ f0.flatten()\n",
    "Ly = (L @ Y).to_numpy()[:,0]\n",
    "L_eps0 = L @ eps_0\n",
    "\n",
    "L_eps0_tilde = [np.dot(L_eps0, eigvecs[:,k]) for k in range(eigvecs.shape[1])]\n",
    "pre_computed_coefficients = [Linv @ eigvecs[:,k] * L_eps0_tilde[k] for k in range(eigvals_reg.size)] \n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def preds_t(t, learning_rate = 0.00001, eig_range=None):\n",
    "  if eig_range is None:\n",
    "    eig_range = eigvals_reg.size\n",
    "  predictions = [pre_computed_coefficients[k] * np.exp(-eigvals_reg[k] * learning_rate* t) for k in range(eig_range)] \n",
    "  predictions = np.sum(predictions, axis=0)\n",
    "\n",
    "  predictions = pd.DataFrame(predictions, index=Y.index)\n",
    "  predictions = Y - predictions\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = ['NMC_NC_NOTFIXED_P_EM-SIGMARED', 'SLAC_NC_NOTFIXED_P_EM-F2', 'BCDMS_NC_NOTFIXED_D_EM-F2', 'HERA_NC_318GEV_EM-SIGMARED']\n",
    "exp_titles = ['NMC', 'SLAC NC P', 'BCDMS NC D', 'HERA NC 318GEV']\n",
    "y_labels = [r'$\\sigma$', r'$F_2$', r'$F_2$', r'$\\sigma$']\n",
    "t = 0.\n",
    "fig_pred, axes_pred = plt.subplots(2, 2, figsize=(25, 25))  # Adjust figsize for desired plot size\n",
    "preds = preds_t(t, learning_rate=learning_rate_gd)\n",
    "\n",
    "scat_gf = []\n",
    "scat_gd = []\n",
    "text = []\n",
    "for i, ax in enumerate(axes_pred.flat):\n",
    "    y = Y.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "    p = preds.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "    trained_pred = pred_in_time[0][experiments[i]]\n",
    "    ax.scatter(np.arange(y.size), y, color='green', label='Central data', marker='o', s=100, alpha=0.4)\n",
    "    gf = ax.scatter(np.arange(y.size), p, color='orange', label='Analytical solution', marker='^', s=100)\n",
    "    gd = ax.scatter(np.arange(y.size), trained_pred, color='red', label='Gradient descent', marker='v', s=100)\n",
    "    scat_gf.append(gf)\n",
    "    scat_gd.append(gd)\n",
    "    #ax.set_xlabel(r'$x$')\n",
    "    ax.set_ylabel(y_labels[i], fontsize=20)\n",
    "    #ax.set_xscale('log')\n",
    "    ax.set_title(exp_titles[i], x=0.8,fontsize=20, fontweight='bold')\n",
    "    ax.legend(fontsize=20)\n",
    "    text_t = ax.text(0.05, 1.01, f't = {t}, learning rate = {learning_rate_gd}', fontsize=20, transform=ax.transAxes)\n",
    "    text.append(text_t)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "#fig.savefig('data_evolution.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = ['NMC_NC_NOTFIXED_P_EM-SIGMARED', 'SLAC_NC_NOTFIXED_P_EM-F2', 'BCDMS_NC_NOTFIXED_D_EM-F2', 'HERA_NC_318GEV_EM-SIGMARED']\n",
    "exp_titles = ['NMC', 'SLAC NC P', 'BCDMS NC D', 'HERA NC 318GEV']\n",
    "y_labels = [r'$\\sigma$', r'$F_2$', r'$F_2$', r'$\\sigma$']\n",
    "t = 0.\n",
    "fig_eps, axes_eps = plt.subplots(2, 2, figsize=(25, 25))  # Adjust figsize for desired plot size\n",
    "preds = preds_t(t, learning_rate=learning_rate_gd)\n",
    "\n",
    "scat_gf_eps = []\n",
    "scat_gd_eps = []\n",
    "text_eps = []\n",
    "for i, ax in enumerate(axes_eps.flat):\n",
    "    y = Y.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "    p = y - preds.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "    trained_pred = y[:,0] - pred_in_time[int(t)][experiments[i]].numpy()\n",
    "    ax.scatter(np.arange(y.size), y, color='green', label='Central data', marker='o', s=100, alpha=0.4)\n",
    "    gf = ax.scatter(np.arange(y.size), p, color='orange', label='Analytical solution', marker='^', s=100)\n",
    "    gd = ax.scatter(np.arange(y.size), trained_pred, color='red', label='Gradient descent', marker='v', s=100)\n",
    "    scat_gf_eps.append(gf)\n",
    "    scat_gd_eps.append(gd)\n",
    "    #ax.set_xlabel(r'$x$')\n",
    "    ax.set_ylabel(r'$\\epsilon$', fontsize=20)\n",
    "    #ax.set_xscale('log')\n",
    "    ax.set_title(exp_titles[i], x=0.8,fontsize=20, fontweight='bold')\n",
    "    ax.legend(fontsize=20)\n",
    "    text_t = ax.text(0.05, 1.01, f't = {t}, learning rate = {learning_rate_gd}', fontsize=20, transform=ax.transAxes)\n",
    "    text_eps.append(text_t)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "#fig.savefig('data_evolution.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_analytical(t, eig_range=None):\n",
    "  preds = preds_t(t, learning_rate=learning_rate_gd, eig_range=eig_range)\n",
    "  loss = 0\n",
    "  ndata = 0\n",
    "  for exp in Y.index.get_level_values('dataset').unique():\n",
    "    y = Y.xs(level='dataset', key=exp).to_numpy()\n",
    "    Cinv_exp = Cinv.xs(level=\"dataset\", key=exp).T.xs(level=\"dataset\", key=exp).to_numpy()\n",
    "    p = preds.xs(level='dataset', key=exp).to_numpy()\n",
    "    R = y[:,0] - p[:,0]\n",
    "    loss += 0.5 * R.T @ Cinv_exp @ R\n",
    "    ndata += Cinv_exp.shape[0]\n",
    "  return float(loss) / ndata\n",
    "\n",
    "def compute_loss_gd(t):\n",
    "  preds = pred_in_time[int(t)]\n",
    "  loss = 0\n",
    "  ndata = 0\n",
    "  for exp, pred in preds.items():\n",
    "    y = Y.xs(level='dataset', key=exp).to_numpy()\n",
    "    Cinv_exp = tf.convert_to_tensor(Cinv.xs(level=\"dataset\", key=exp).T.xs(level=\"dataset\", key=exp).to_numpy(), name=f'Cinv_{exp}', dtype='float32')\n",
    "    R = tf.convert_to_tensor(y[:,0] - pred, name=f'residue_{exp}', dtype='float32')\n",
    "    Cinv_R = tf.linalg.matvec(Cinv_exp, R)\n",
    "    loss += 0.5 * tf.reduce_sum(tf.multiply(R, Cinv_R))\n",
    "    ndata += Cinv_exp.shape[0]\n",
    "  return float(loss) / ndata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps_high = np.arange(1000,len(pred_in_time),1000)\n",
    "time_steps_low = np.arange(0,1000,2)\n",
    "time_steps = np.concatenate([time_steps_low, time_steps_high])\n",
    "aloss = [compute_loss_analytical(t, eig_range=100) for t in time_steps]\n",
    "gd_loss = [compute_loss_gd(t) for t in time_steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_loss, ax_loss = plt.subplots(figsize=(10, 7))  # Adjust figsize for desired plot size\n",
    "\n",
    "ax_loss.scatter(time_steps, aloss, label='Analytical solution')\n",
    "ax_loss.scatter(time_steps, gd_loss, label='Gradient descent')\n",
    "ax_loss.set_xlabel(r'$t$')\n",
    "ax_loss.set_ylabel(r'Loss function', fontsize=20)\n",
    "ax_loss.set_xscale('symlog')\n",
    "ax_loss.set_title('MSE in function of training time', x=0.5, fontsize=20, fontweight='bold')\n",
    "ax_loss.legend(fontsize=20)\n",
    "#text_t = ax.text(0.05, 1.01, f't = {t}, learning rate = {learning_rate_gd}', fontsize=20, transform=ax.transAxes)\n",
    "#text.append(text_t)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "fig_loss.savefig('Loss_function_time.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "import matplotlib\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "\n",
    "# Animation function\n",
    "# Update function for predicitons\n",
    "def update_preds(t):\n",
    "    preds = preds_t(t, learning_rate=learning_rate_gd)\n",
    "    for i, (gf, gd, text_t) in enumerate(zip(scat_gf, scat_gd, text)):\n",
    "        # Update the y-data for each subplot's line\n",
    "        y = Y.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "        p = preds.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "        trained_pred = pred_in_time[int(t)][experiments[i]]\n",
    "        data_gf = np.hstack(( np.arange(y.size)[:, np.newaxis] , p))\n",
    "        data_gd = np.hstack(( np.arange(y.size)[:, np.newaxis] , trained_pred[:,np.newaxis]))\n",
    "        gf.set_offsets(data_gf)  # Example: Add phase shift based on t and subplot index\n",
    "        gd.set_offsets(data_gd)  # Example: Add phase shift based on t and subplot index\n",
    "        text_t.set_text(f't = {t}, learning rate = {learning_rate_gd}')\n",
    "    return scat_gf + scat_gd + text\n",
    "\n",
    "# Update function for epsilon\n",
    "def update_eps(t):\n",
    "    preds = preds_t(t, learning_rate=learning_rate_gd)\n",
    "    for i, (gf, gd, text_t) in enumerate(zip(scat_gf_eps, scat_gd_eps, text_eps)):\n",
    "        # Update the y-data for each subplot's line\n",
    "        y = Y.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "        p = preds.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "        trained_pred = pred_in_time[int(t)][experiments[i]]\n",
    "        data_gf = np.hstack(( np.arange(y.size)[:, np.newaxis] , p))\n",
    "        data_gd = np.hstack(( np.arange(y.size)[:, np.newaxis] , trained_pred[:,np.newaxis]))\n",
    "        gf.set_offsets(data_gf)  # Example: Add phase shift based on t and subplot index\n",
    "        gd.set_offsets(data_gd)  # Example: Add phase shift based on t and subplot index\n",
    "        text_t.set_text(f't = {t}, learning rate = {learning_rate_gd}')\n",
    "    return scat_gf + scat_gd + text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani_pred = FuncAnimation(fig_pred, update_preds, frames=np.arange(0, len(pred_in_time), 1000), interval=10, blit=True, cache_frame_data=False)\n",
    "ani_eps = FuncAnimation(fig_eps, update_eps, frames=np.arange(0, len(pred_in_time), 1000), interval=10, blit=True, cache_frame_data=False)\n",
    "\n",
    "# Save the animation in the background\n",
    "ani_pred.save('prediction_evolution.mp4', writer='ffmpeg', fps=20)\n",
    "ani_eps.save('epsilon_evolution.mp4', writer='ffmpeg', fps=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnpdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
