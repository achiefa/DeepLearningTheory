{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Keras backend\n"
     ]
    }
   ],
   "source": [
    "from validphys.api import API\n",
    "import sys\n",
    "\n",
    "# Add the path to the library folder\n",
    "sys.path.append('./lib')\n",
    "\n",
    "from utils import XGRID, build_fk_matrix, regularize_matrix\n",
    "from model import PDFmodel, generate_mse_loss\n",
    "from gen_dicts import generate_dicts\n",
    "from plot_utils import plot_eigvals\n",
    "from validphys.api import API\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 14132124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of DIS dataset\n",
    "dataset_inputs = [\n",
    "  #{'dataset': 'NMC_NC_NOTFIXED_DW_EM-F2', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'NMC_NC_NOTFIXED_P_EM-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'SLAC_NC_NOTFIXED_P_DW_EM-F2', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'SLAC_NC_NOTFIXED_D_DW_EM-F2', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'BCDMS_NC_NOTFIXED_P_DW_EM-F2', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'BCDMS_NC_NOTFIXED_D_DW_EM-F2', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'CHORUS_CC_NOTFIXED_PB_DW_NU-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'CHORUS_CC_NOTFIXED_PB_DW_NB-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'NUTEV_CC_NOTFIXED_FE_DW_NU-SIGMARED', 'cfac': ['MAS'], 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'NUTEV_CC_NOTFIXED_FE_DW_NB-SIGMARED', 'cfac': ['MAS'], 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'HERA_NC_318GEV_EM-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'HERA_NC_225GEV_EP-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'HERA_NC_251GEV_EP-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'HERA_NC_300GEV_EP-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'HERA_NC_318GEV_EP-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'HERA_CC_318GEV_EM-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'HERA_CC_318GEV_EP-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'HERA_NC_318GEV_EAVG_CHARM-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'HERA_NC_318GEV_EAVG_BOTTOM-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "]\n",
    "\n",
    "# Dictionary for validphys API\n",
    "common_dict = dict(\n",
    "    dataset_inputs=dataset_inputs,\n",
    "    metadata_group=\"nnpdf31_process\",\n",
    "    use_cuts='internal',\n",
    "    datacuts={'q2min': 3.49, 'w2min': 12.5},\n",
    "    theoryid=40000000,\n",
    "    t0pdfset='NNPDF40_nnlo_as_01180',\n",
    "    use_t0=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve data from NNPDF\n",
    "groups_data = API.procs_data(**common_dict)\n",
    "tuple_of_dicts = generate_dicts(groups_data)\n",
    "fk_table_dict = tuple_of_dicts.fk_tables\n",
    "central_data_dict = tuple_of_dicts.central_data\n",
    "FK = build_fk_matrix(fk_table_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHAPDF 6.5.4 loading /opt/homebrew/Caskroom/miniconda/base/envs/nnpdf/share/LHAPDF/NNPDF40_nnlo_as_01180/NNPDF40_nnlo_as_01180_0000.dat\n",
      "NNPDF40_nnlo_as_01180 PDF set, member #0, version 1; LHAPDF ID = 331100\n"
     ]
    }
   ],
   "source": [
    "C = API.groups_covmat_no_table(**common_dict)\n",
    "\n",
    "# Serialize covmat\n",
    "C_index = C.index\n",
    "C_col = C.columns\n",
    "Cinv = np.linalg.inv(C)\n",
    "Cinv = pd.DataFrame(Cinv, index=C_index, columns=C_col)\n",
    "\n",
    "# Diagonalize covariance matric\n",
    "eigvals_Cinv, R_Y = np.linalg.eigh(Cinv)\n",
    "if eigvals_Cinv[-1] > eigvals_Cinv[0]:\n",
    "    eigvals_Cinv = eigvals_Cinv[::-1]\n",
    "    R_Y = R_Y[:,::-1]\n",
    "D_Y = np.zeros_like(R_Y)\n",
    "np.fill_diagonal(D_Y, eigvals_Cinv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dataframe for predictions\n",
    "Y = pd.DataFrame(np.zeros(Cinv.shape[0]), index=Cinv.index)\n",
    "for exp_name, data in central_data_dict.items():\n",
    "  if data.size == Y.loc[(slice(None), [exp_name], slice(None)), :].size:\n",
    "    Y.loc[(slice(None), [exp_name], slice(None)), :] = data\n",
    "  else:\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnpdf_model = PDFmodel(input=XGRID,\n",
    "                       outputs=9,\n",
    "                       architecture=[28,20],\n",
    "                       activations=['tanh', 'tanh'],\n",
    "                       kernel_initializer='RandomNormal',\n",
    "                       user_ki_args={'mean': 0.0, 'stddev': 1.0},\n",
    "                       seed=seed,\n",
    "                       dtype='float64')\n",
    "NTK = nnpdf_model.compute_ntk()\n",
    "\n",
    "# Flatten NTK\n",
    "prod = 1\n",
    "oldshape = NTK.shape\n",
    "for k in oldshape[2:]:\n",
    "    prod *= k\n",
    "NTK_flat = np.array(NTK).reshape(prod,-1)\n",
    "\n",
    "# Compute predictions at initialization\n",
    "f0 = nnpdf_model.predict(squeeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from GD training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('training.pkl', 'rb') as file:\n",
    "    results = pickle.load(file)\n",
    "\n",
    "pred_in_time = results[1]\n",
    "pdfs_in_time = results[2]\n",
    "learning_rate_gd = 0.00000001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing matrices from notes\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol = 1.e-3#np.finfo(np.float64).eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $M = (FK)^T C_Y^{-1} (FK) = RDR^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = FK.T @ Cinv.to_numpy() @ FK\n",
    "M, (eigvals_M, R) = regularize_matrix(M, tol=tol)\n",
    "\n",
    "# Construct diagonal matrix\n",
    "D = np.zeros_like(R)\n",
    "np.fill_diagonal(D, eigvals_M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\tilde{H} = D^{1/2} R^T \\Theta R D^{1/2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is symmetric: True\n"
     ]
    }
   ],
   "source": [
    "ntk, (eigvals_ntk, R_ntk) = regularize_matrix(NTK_flat)\n",
    "H_tilde = np.sqrt(D) @ R.T @ ntk @ R @ np.sqrt(D)\n",
    "H_tilde, (eigvals_H_tilde, eigvecs_H_tilde) = regularize_matrix(H_tilde, tol=tol)\n",
    "\n",
    "# Check if symmetric\n",
    "print(f'Is symmetric: {np.allclose(H_tilde, H_tilde.T)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\tilde{H_{\\epsilon}} = D^{1/2} R^T \\Theta R D^{1/2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is symmetric: True\n"
     ]
    }
   ],
   "source": [
    "H_eps_tilde = np.sqrt(D_Y) @ R_Y.T @ FK @ ntk @ FK.T @ R_Y @ np.sqrt(D_Y)\n",
    "H_eps_tilde, (eigvals_H_eps_tilde, eigvecs_H_eps_tilde) = regularize_matrix(H_eps_tilde, tol=tol)\n",
    "\n",
    "# Check if symmetric\n",
    "print(f'Is symmetric: {np.allclose(H_eps_tilde, H_eps_tilde.T)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $b = \\Theta (FK)^T C_Y^{-1} y \\hspace{5mm} \\textrm{and} \\hspace{5mm} \\tilde{b} = D^{1/2} R^T b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = ntk @ FK.T @ Cinv.to_numpy(dtype='float64') @ Y.to_numpy('float64')\n",
    "b_tilde = np.sqrt(D) @ R.T @ b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots of the eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_eigvals(eigvals_H_eps_tilde, figsize=(10,8), title=r'$H_{\\epsilon} = D^{1/2}_Y R^T_Y (FK) \\Theta (FK)^T R_Y D^{1/2}_Y$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_eigvals(eigvals_H_tilde, \n",
    "                        figsize=(10,8), \n",
    "                        title=r'$\\tilde{H}= D^{1/2} R^T \\Theta R D^{1/2}$,  $M = RDR^T$')\n",
    "fig.savefig('../../../doc/figs/Htilde_eigvals.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_eigvals(eigvals_ntk, figsize=(10,8), title='')\n",
    "axs.set_title(r'Eigenvalues of $\\Theta$', fontsize=20)\n",
    "fig.savefig('../../../doc/figs/ntk_eigvals.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_eigvals(eigvals_M, figsize=(10,8), title=r'Eigenvalues of $M = (FK)^T C_Y^{-1} (FK)$')\n",
    "#axs.set_title(r'Eigenvalues of $\\Theta$', fontsize=20)\n",
    "#fig.savefig('../../../doc/figs/m_eigvals.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions for the null space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "def null_space_eig(eigvals, eigvecs, tol=None):\n",
    "  if tol is None:\n",
    "    tol = np.amax(eigvals, initial=0.) * np.finfo(eigvecs.dtype).eps\n",
    "  num = np.sum(eigvals > tol, dtype=int) # Number of non-zero eigenvalues\n",
    "  ker = eigvecs[:,num:]\n",
    "  orth = eigvecs[:,:num]\n",
    "  return ker, orth\n",
    "  \n",
    "def project_matrix(matrix, basis1, basis2):\n",
    "  dimB1 = basis1.shape[1]\n",
    "  dimB2 = basis2.shape[1]\n",
    "  emb_space1 = basis1.shape[0]\n",
    "  emb_space2 = basis2.shape[0]\n",
    "\n",
    "  # Check if the bases are compatible with the matrix\n",
    "  if matrix.shape[0] != emb_space1 or matrix.shape[1] != emb_space2:\n",
    "    raise ValueError ('The matrix cannot be projected into the two bases.')\n",
    "  \n",
    "  #M_orth = np.zeros((dimB1, dimB2))\n",
    "  #for i in range(dimB1):\n",
    "  #  for j in range(dimB2):\n",
    "  M_orth = basis1.T @ matrix @ basis2\n",
    "\n",
    "  return M_orth\n",
    "\n",
    "def project_vector(vector, basis):\n",
    "  basis_dim = basis.shape[1]\n",
    "  space_dim = basis.shape[0]\n",
    "  if space_dim != vector.shape[0]:\n",
    "    raise ValueError ('The matrix cannot be projected into the basis')\n",
    "  \n",
    "  res = [np.dot(vector, basis[:,i]) for i in range(basis_dim)]\n",
    "  return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the $ker(M)$ and its orthogonal space. Then project the matrix M into the four components as explained in the notes.\n",
    "\n",
    "We must be careful in this part. Indeed, we must decide the threshold for the smallest distinguishable eigenvalue. Looking at the eigenvalues of the matrix $M$ may help choose this value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 3124227.6108772354\n",
      "2 : 1403346.4123894328\n",
      "3 : 456262.382786244\n",
      "4 : 340401.94392178574\n",
      "5 : 102319.29860667067\n",
      "6 : 93976.81790458383\n",
      "7 : 74554.88176256222\n",
      "8 : 69484.39975297164\n",
      "9 : 51622.76207117809\n",
      "10 : 44115.20273963305\n",
      "11 : 26964.98519148161\n",
      "12 : 24523.92813802907\n",
      "13 : 21406.35767285671\n",
      "14 : 18843.31711000429\n",
      "15 : 15105.818770701035\n",
      "16 : 14233.550076906415\n",
      "17 : 9802.403011957407\n",
      "18 : 7818.862748033741\n",
      "19 : 6874.863591158355\n",
      "20 : 6321.435594768886\n",
      "21 : 4579.068123341692\n",
      "22 : 3992.435884194028\n",
      "23 : 3685.986052988151\n",
      "24 : 3261.3024196549604\n",
      "25 : 3032.1264836599976\n",
      "26 : 2546.6484429102384\n",
      "27 : 2466.190584104022\n",
      "28 : 2352.9819779930367\n",
      "29 : 2050.66766920035\n",
      "30 : 1793.3076905141436\n",
      "31 : 1779.1202599261612\n",
      "32 : 1469.258396587751\n",
      "33 : 1316.0734418302266\n",
      "34 : 1241.37745256911\n",
      "35 : 1154.7936746725159\n",
      "36 : 998.018869304499\n",
      "37 : 872.984787007436\n",
      "38 : 742.4398080891076\n",
      "39 : 650.6481224644775\n",
      "40 : 638.3808183791555\n",
      "41 : 608.9775263694085\n",
      "42 : 490.8503281376732\n",
      "43 : 463.29925988519204\n",
      "44 : 409.85245901598506\n",
      "45 : 331.8656251455118\n",
      "46 : 321.0942262069132\n",
      "47 : 214.36020763145157\n",
      "48 : 201.52125350109165\n",
      "49 : 144.36130458181583\n",
      "50 : 131.9457164877788\n",
      "51 : 98.8096481538077\n",
      "52 : 77.63139715584916\n",
      "53 : 67.66381459166122\n",
      "54 : 38.26648783367592\n",
      "55 : 36.35788669536866\n",
      "56 : 32.695840438543414\n",
      "57 : 28.46932458577962\n",
      "58 : 22.6390750959586\n",
      "59 : 20.456610209007113\n",
      "60 : 16.26198040027598\n",
      "61 : 16.099146027717282\n",
      "62 : 14.009522133482129\n",
      "63 : 13.18219549797385\n",
      "64 : 11.16130337250623\n",
      "65 : 10.22292756873335\n",
      "66 : 9.992231955241637\n",
      "67 : 8.809943701947931\n",
      "68 : 8.384086791262288\n",
      "69 : 7.818630433606573\n",
      "70 : 7.390781429258739\n",
      "71 : 6.725638304126847\n",
      "72 : 6.2433321858430295\n",
      "73 : 5.251515497328729\n",
      "74 : 5.151466154103134\n",
      "75 : 4.750585766890649\n",
      "76 : 4.298154899229822\n",
      "77 : 3.873562359309434\n",
      "78 : 3.7735360181819053\n",
      "79 : 2.7453377955431724\n",
      "80 : 2.484408093265314\n",
      "81 : 2.425102664616694\n",
      "82 : 1.8393389530550883\n",
      "83 : 1.7375861715078234\n",
      "84 : 1.6742885762658204\n",
      "85 : 1.6235916205008396\n",
      "86 : 1.2894725981622919\n",
      "87 : 1.1668736276477223\n",
      "88 : 0.9286087458422537\n",
      "89 : 0.9168259424889559\n",
      "90 : 0.8215105930193528\n",
      "91 : 0.811440505281115\n",
      "92 : 0.6674676910804291\n",
      "93 : 0.599476953356217\n",
      "94 : 0.5645988814989609\n",
      "95 : 0.49751860081951277\n",
      "96 : 0.4762280075913317\n",
      "97 : 0.3292241169530617\n",
      "98 : 0.30602041747407915\n",
      "99 : 0.2828391213698792\n",
      "100 : 0.2530287102803205\n",
      "101 : 0.2447164271062449\n",
      "102 : 0.2148049719849523\n",
      "103 : 0.19920222938518936\n",
      "104 : 0.17108771259227049\n",
      "105 : 0.16634112521040836\n",
      "106 : 0.12925819534411276\n",
      "107 : 0.11368809909755835\n",
      "108 : 0.10872296186185804\n",
      "109 : 0.10443217467881524\n",
      "110 : 0.08884717438362488\n",
      "111 : 0.08616987438264424\n",
      "112 : 0.07364541532823783\n",
      "113 : 0.07057638574062623\n",
      "114 : 0.06056687983248586\n",
      "115 : 0.05589595143320305\n",
      "116 : 0.04780689829147414\n",
      "117 : 0.045219245641640204\n",
      "118 : 0.038783094868369256\n",
      "119 : 0.03639904952642436\n",
      "120 : 0.033174057449551694\n",
      "121 : 0.02726989432666709\n",
      "122 : 0.024641824404785084\n",
      "123 : 0.019191134408779467\n",
      "124 : 0.01736807034070396\n",
      "125 : 0.01686554882900275\n",
      "126 : 0.01636590481662972\n",
      "127 : 0.015012647987973816\n",
      "128 : 0.014623024165012183\n",
      "129 : 0.012976539921977951\n",
      "130 : 0.01269851263881056\n",
      "131 : 0.009318918127570621\n",
      "132 : 0.008725336748718364\n",
      "133 : 0.007105631631747494\n",
      "134 : 0.005795205792691885\n",
      "135 : 0.005480124013540606\n",
      "136 : 0.005052905736938623\n",
      "137 : 0.004669943067016956\n",
      "138 : 0.004068783803028435\n",
      "139 : 0.0037999060769783556\n",
      "140 : 0.0034693017215091087\n",
      "141 : 0.0033352092377278947\n",
      "142 : 0.0025002070530476365\n",
      "143 : 0.00237978600491607\n",
      "144 : 0.002261191882655168\n",
      "145 : 0.0019913663585146265\n",
      "146 : 0.0018586927079898175\n",
      "147 : 0.0016813287401566644\n",
      "148 : 0.001528366171974799\n",
      "149 : 0.0011005224528585359\n",
      "150 : 0.0\n",
      "151 : 0.0\n",
      "152 : 0.0\n",
      "153 : 0.0\n",
      "154 : 0.0\n",
      "155 : 0.0\n",
      "156 : 0.0\n",
      "157 : 0.0\n",
      "158 : 0.0\n",
      "159 : 0.0\n",
      "160 : 0.0\n",
      "161 : 0.0\n",
      "162 : 0.0\n",
      "163 : 0.0\n",
      "164 : 0.0\n",
      "165 : 0.0\n",
      "166 : 0.0\n",
      "167 : 0.0\n",
      "168 : 0.0\n",
      "169 : 0.0\n",
      "170 : 0.0\n",
      "171 : 0.0\n",
      "172 : 0.0\n",
      "173 : 0.0\n",
      "174 : 0.0\n",
      "175 : 0.0\n",
      "176 : 0.0\n",
      "177 : 0.0\n",
      "178 : 0.0\n",
      "179 : 0.0\n",
      "180 : 0.0\n",
      "181 : 0.0\n",
      "182 : 0.0\n",
      "183 : 0.0\n",
      "184 : 0.0\n",
      "185 : 0.0\n",
      "186 : 0.0\n",
      "187 : 0.0\n",
      "188 : 0.0\n",
      "189 : 0.0\n",
      "190 : 0.0\n",
      "191 : 0.0\n",
      "192 : 0.0\n",
      "193 : 0.0\n",
      "194 : 0.0\n",
      "195 : 0.0\n",
      "196 : 0.0\n",
      "197 : 0.0\n",
      "198 : 0.0\n",
      "199 : 0.0\n",
      "200 : 0.0\n",
      "201 : 0.0\n",
      "202 : 0.0\n",
      "203 : 0.0\n",
      "204 : 0.0\n",
      "205 : 0.0\n",
      "206 : 0.0\n",
      "207 : 0.0\n",
      "208 : 0.0\n",
      "209 : 0.0\n",
      "210 : 0.0\n",
      "211 : 0.0\n",
      "212 : 0.0\n",
      "213 : 0.0\n",
      "214 : 0.0\n",
      "215 : 0.0\n",
      "216 : 0.0\n",
      "217 : 0.0\n",
      "218 : 0.0\n",
      "219 : 0.0\n",
      "220 : 0.0\n",
      "221 : 0.0\n",
      "222 : 0.0\n",
      "223 : 0.0\n",
      "224 : 0.0\n",
      "225 : 0.0\n",
      "226 : 0.0\n",
      "227 : 0.0\n",
      "228 : 0.0\n",
      "229 : 0.0\n",
      "230 : 0.0\n",
      "231 : 0.0\n",
      "232 : 0.0\n",
      "233 : 0.0\n",
      "234 : 0.0\n",
      "235 : 0.0\n",
      "236 : 0.0\n",
      "237 : 0.0\n",
      "238 : 0.0\n",
      "239 : 0.0\n",
      "240 : 0.0\n",
      "241 : 0.0\n",
      "242 : 0.0\n",
      "243 : 0.0\n",
      "244 : 0.0\n",
      "245 : 0.0\n",
      "246 : 0.0\n",
      "247 : 0.0\n",
      "248 : 0.0\n",
      "249 : 0.0\n",
      "250 : 0.0\n",
      "251 : 0.0\n",
      "252 : 0.0\n",
      "253 : 0.0\n",
      "254 : 0.0\n",
      "255 : 0.0\n",
      "256 : 0.0\n",
      "257 : 0.0\n",
      "258 : 0.0\n",
      "259 : 0.0\n",
      "260 : 0.0\n",
      "261 : 0.0\n",
      "262 : 0.0\n",
      "263 : 0.0\n",
      "264 : 0.0\n",
      "265 : 0.0\n",
      "266 : 0.0\n",
      "267 : 0.0\n",
      "268 : 0.0\n",
      "269 : 0.0\n",
      "270 : 0.0\n",
      "271 : 0.0\n",
      "272 : 0.0\n",
      "273 : 0.0\n",
      "274 : 0.0\n",
      "275 : 0.0\n",
      "276 : 0.0\n",
      "277 : 0.0\n",
      "278 : 0.0\n",
      "279 : 0.0\n",
      "280 : 0.0\n",
      "281 : 0.0\n",
      "282 : 0.0\n",
      "283 : 0.0\n",
      "284 : 0.0\n",
      "285 : 0.0\n",
      "286 : 0.0\n",
      "287 : 0.0\n",
      "288 : 0.0\n",
      "289 : 0.0\n",
      "290 : 0.0\n",
      "291 : 0.0\n",
      "292 : 0.0\n",
      "293 : 0.0\n",
      "294 : 0.0\n",
      "295 : 0.0\n",
      "296 : 0.0\n",
      "297 : 0.0\n",
      "298 : 0.0\n",
      "299 : 0.0\n",
      "300 : 0.0\n",
      "301 : 0.0\n",
      "302 : 0.0\n",
      "303 : 0.0\n",
      "304 : 0.0\n",
      "305 : 0.0\n",
      "306 : 0.0\n",
      "307 : 0.0\n",
      "308 : 0.0\n",
      "309 : 0.0\n",
      "310 : 0.0\n",
      "311 : 0.0\n",
      "312 : 0.0\n",
      "313 : 0.0\n",
      "314 : 0.0\n",
      "315 : 0.0\n",
      "316 : 0.0\n",
      "317 : 0.0\n",
      "318 : 0.0\n",
      "319 : 0.0\n",
      "320 : 0.0\n",
      "321 : 0.0\n",
      "322 : 0.0\n",
      "323 : 0.0\n",
      "324 : 0.0\n",
      "325 : 0.0\n",
      "326 : 0.0\n",
      "327 : 0.0\n",
      "328 : 0.0\n",
      "329 : 0.0\n",
      "330 : 0.0\n",
      "331 : 0.0\n",
      "332 : 0.0\n",
      "333 : 0.0\n",
      "334 : 0.0\n",
      "335 : 0.0\n",
      "336 : 0.0\n",
      "337 : 0.0\n",
      "338 : 0.0\n",
      "339 : 0.0\n",
      "340 : 0.0\n",
      "341 : 0.0\n",
      "342 : 0.0\n",
      "343 : 0.0\n",
      "344 : 0.0\n",
      "345 : 0.0\n",
      "346 : 0.0\n",
      "347 : 0.0\n",
      "348 : 0.0\n",
      "349 : 0.0\n",
      "350 : 0.0\n",
      "351 : 0.0\n",
      "352 : 0.0\n",
      "353 : 0.0\n",
      "354 : 0.0\n",
      "355 : 0.0\n",
      "356 : 0.0\n",
      "357 : 0.0\n",
      "358 : 0.0\n",
      "359 : 0.0\n",
      "360 : 0.0\n",
      "361 : 0.0\n",
      "362 : 0.0\n",
      "363 : 0.0\n",
      "364 : 0.0\n",
      "365 : 0.0\n",
      "366 : 0.0\n",
      "367 : 0.0\n",
      "368 : 0.0\n",
      "369 : 0.0\n",
      "370 : 0.0\n",
      "371 : 0.0\n",
      "372 : 0.0\n",
      "373 : 0.0\n",
      "374 : 0.0\n",
      "375 : 0.0\n",
      "376 : 0.0\n",
      "377 : 0.0\n",
      "378 : 0.0\n",
      "379 : 0.0\n",
      "380 : 0.0\n",
      "381 : 0.0\n",
      "382 : 0.0\n",
      "383 : 0.0\n",
      "384 : 0.0\n",
      "385 : 0.0\n",
      "386 : 0.0\n",
      "387 : 0.0\n",
      "388 : 0.0\n",
      "389 : 0.0\n",
      "390 : 0.0\n",
      "391 : 0.0\n",
      "392 : 0.0\n",
      "393 : 0.0\n",
      "394 : 0.0\n",
      "395 : 0.0\n",
      "396 : 0.0\n",
      "397 : 0.0\n",
      "398 : 0.0\n",
      "399 : 0.0\n",
      "400 : 0.0\n",
      "401 : 0.0\n",
      "402 : 0.0\n",
      "403 : 0.0\n",
      "404 : 0.0\n",
      "405 : 0.0\n",
      "406 : 0.0\n",
      "407 : 0.0\n",
      "408 : 0.0\n",
      "409 : 0.0\n",
      "410 : 0.0\n",
      "411 : 0.0\n",
      "412 : 0.0\n",
      "413 : 0.0\n",
      "414 : 0.0\n",
      "415 : 0.0\n",
      "416 : 0.0\n",
      "417 : 0.0\n",
      "418 : 0.0\n",
      "419 : 0.0\n",
      "420 : 0.0\n",
      "421 : 0.0\n",
      "422 : 0.0\n",
      "423 : 0.0\n",
      "424 : 0.0\n",
      "425 : 0.0\n",
      "426 : 0.0\n",
      "427 : 0.0\n",
      "428 : 0.0\n",
      "429 : 0.0\n",
      "430 : 0.0\n",
      "431 : 0.0\n",
      "432 : 0.0\n",
      "433 : 0.0\n",
      "434 : 0.0\n",
      "435 : 0.0\n",
      "436 : 0.0\n",
      "437 : 0.0\n",
      "438 : 0.0\n",
      "439 : 0.0\n",
      "440 : 0.0\n",
      "441 : 0.0\n",
      "442 : 0.0\n",
      "443 : 0.0\n",
      "444 : 0.0\n",
      "445 : 0.0\n",
      "446 : 0.0\n",
      "447 : 0.0\n",
      "448 : 0.0\n",
      "449 : 0.0\n",
      "450 : 0.0\n"
     ]
    }
   ],
   "source": [
    "for i, val in enumerate(eigvals_M):\n",
    "  print(f'{i+1} : {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ker_M, orth_M = null_space_eig(eigvals_M, R, tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 149)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orth_M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_pp = project_matrix(M, orth_M, orth_M)\n",
    "M_kk = project_matrix(M, ker_M, ker_M)\n",
    "M_pk = project_matrix(M, orth_M, ker_M)\n",
    "M_kp = project_matrix(M, ker_M, orth_M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the matrix $M$ is symmetric, only $M_{\\bot\\bot} \\neq 0$, while the other three components should be zero. Also here, we need to be careful with what we consider a null value. I'll use the effective tolerance used in the extraction of the null-space (@TODO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pp ?= 0 : False\n",
      "M_kk ?= 0 : True\n",
      "M_kp ?= 0 : True\n",
      "M_pk ?= 0 : True\n"
     ]
    }
   ],
   "source": [
    "print(f'M_pp ?= 0 : {np.allclose(np.zeros_like(M_pp), M_pp, atol=tol)}')\n",
    "print(f'M_kk ?= 0 : {np.allclose(np.zeros_like(M_kk), M_kk, atol=tol)}')\n",
    "print(f'M_kp ?= 0 : {np.allclose(np.zeros_like(M_kp), M_kp, atol=tol)}')\n",
    "print(f'M_pk ?= 0 : {np.allclose(np.zeros_like(M_pk), M_pk, atol=tol)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the orthogonal space, the matrix $M$ should be invertible..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pp_inv @ M_pp ?= Id: True\n",
      "M_pp @ M_pp_inv ?= Id: True\n"
     ]
    }
   ],
   "source": [
    "M_pp_inv = np.linalg.inv(M_pp)\n",
    "print(f'M_pp_inv @ M_pp ?= Id: {np.allclose(M_pp_inv @ M_pp, np.eye(M_pp.shape[0]))}')\n",
    "print(f'M_pp @ M_pp_inv ?= Id: {np.allclose(M_pp @ M_pp_inv, np.eye(M_pp.shape[0]))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "## Projection for FK - WIP\n",
    "The same projection should be applied to the FK tables. Note the $ker(FK) = ker(M)$ (see notes), and hence we don't need to compute the null-space of the FK tables. However, it is interesting to see that despite the two null-spaces should be the same, when we compute $ker(FK)$ numerically we obtain something different..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FK, (s_FK, vh_FK) = regularize_matrix(FK, tol=np.finfo(FK.dtype).eps * np.amax(eigvals_M, initial=0.))\n",
    "#ker_FK, orth_FK = nullspace(FK, orth_space=True, rcond=np.finfo('float64').eps * np.amax(eigvals_M, initial=0.) / np.amax(s_FK, initial=0.))\n",
    "#print(f'ker(FK): {ker_FK.shape} != ker(M): {ker_M.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two spaces are different even if we set the same relative condition number. The reason is that the function `scipy.linalg.null_space` defines the tolerance as `tol = rcond * max(s)`, where `s` are the singular values of the matrix. The order of magnitude of the highest singular value of $(FK)$ is different from the one of $M$, and this should be enough to explain the difference we observe. We should see the same answer provided we use the same tolerance for both extraction.\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also $(FK)$ must be projected in the two bases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FK, (s_FK, vh_FK) = regularize_matrix(FK, tol=np.finfo(FK.dtype).eps * np.amax(eigvals_M, initial=0.)/ np.amax(s_FK, initial=0.))\n",
    "FK_p = project_matrix(FK, np.eye(FK.shape[0]), orth_M)\n",
    "FK_k = project_matrix(FK, np.eye(FK.shape[0]), ker_M)\n",
    "ntk_pp = project_matrix(ntk, orth_M, orth_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FK_k ?= 0 : True\n",
      "FK_p ?= 0 : False\n"
     ]
    }
   ],
   "source": [
    "print(f'FK_k ?= 0 : {np.allclose(np.zeros_like(FK_k), FK_k, atol=tol)}')\n",
    "print(f'FK_p ?= 0 : {np.allclose(np.zeros_like(FK_p), FK_p, atol=tol)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that $(FK) \\Theta (FK)^T = (FK_{\\bot}) \\Theta_{\\bot\\bot} (FK_{\\bot})^T$ because $(FK_K) = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = FK_p @ ntk_pp @ FK_p.T @ Cinv.to_numpy()\n",
    "test2 = FK @ ntk @ FK.T @ Cinv.to_numpy()\n",
    "eigvals = np.linalg.eigvals(Cinv.to_numpy())\n",
    "np.allclose(test1,test2, atol=tol*eigvals.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5420.607087270766"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tol*eigvals.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01063744,  0.04715807,  0.01105861, ...,  0.02134893,\n",
       "         0.04356189, -0.01356432],\n",
       "       [ 0.0095173 ,  0.03769981,  0.00960757, ...,  0.01288368,\n",
       "         0.03984187, -0.01822565],\n",
       "       [ 0.01095587,  0.04454752,  0.0110293 , ...,  0.0165962 ,\n",
       "         0.04152658, -0.01633752],\n",
       "       ...,\n",
       "       [ 0.00809976,  0.03346447,  0.006441  , ...,  0.046501  ,\n",
       "         0.10311208, -0.04812069],\n",
       "       [ 0.0285553 ,  0.11427956,  0.02739389, ...,  0.08098131,\n",
       "         0.12962646, -0.01893501],\n",
       "       [-0.04895807, -0.21657117, -0.05359029, ..., -0.13770991,\n",
       "        -0.06761168, -0.10561507]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 - test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = FK @ ntk @ FK.T @ Cinv.to_numpy() @ FK_p @ M_pp_inv @ FK_p.T @ Cinv.to_numpy()\n",
    "test2 = FK_p @ ntk_pp @ FK_p.T @ Cinv.to_numpy() @ FK_p @ M_pp_inv @ FK_p.T @ Cinv.to_numpy()\n",
    "np.allclose(test1,test2, atol=tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pp ?= M_pp_recons: True\n",
      "M_kp ?= M_kp_recons: True\n",
      "M_pk ?= M_pk_recons: True\n",
      "M_kk ?= M_kk_recons: True\n"
     ]
    }
   ],
   "source": [
    "M_pp_recons = FK_p.T @ Cinv.to_numpy(dtype='float64') @ FK_p\n",
    "M_kp_recons = FK_k.T @ Cinv.to_numpy(dtype='float64') @ FK_p\n",
    "M_pk_recons = FK_p.T @ Cinv.to_numpy(dtype='float64') @ FK_k\n",
    "M_kk_recons = FK_k.T @ Cinv.to_numpy(dtype='float64') @ FK_k\n",
    "print(f'M_pp ?= M_pp_recons: {np.allclose(M_pp, M_pp_recons, atol=tol)}')\n",
    "print(f'M_kp ?= M_kp_recons: {np.allclose(M_kp, M_kp_recons, atol=tol)}')\n",
    "print(f'M_pk ?= M_pk_recons: {np.allclose(M_pk, M_pk_recons, atol=tol)}')\n",
    "print(f'M_kk ?= M_kk_recons: {np.allclose(M_kk, M_kk_recons, atol=tol)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the limiting solution $f_{\\infty} = (M_{\\bot\\bot})^{-1} (FK_{\\bot})^{T} C_Y^{-1} y$ and $\\tilde{\\epsilon}_{\\infty}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_inf = M_pp_inv @ FK_p.T @ Cinv.to_numpy(dtype='float64') @ Y.to_numpy(dtype='float64')[:,0]\n",
    "eps_inf = Y.to_numpy(dtype='float64')[:,0] - FK_p @ f_inf\n",
    "eps_tilde_inf = np.sqrt(D_Y) @ R_Y.T @ eps_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is symmetric: True\n"
     ]
    }
   ],
   "source": [
    "H_eps_tilde_p = np.sqrt(D_Y) @ R_Y.T @ FK_p @ ntk_pp @ FK_p.T @ R_Y @ np.sqrt(D_Y)\n",
    "#H_eps_tilde_p, (eigvals_H_eps_tilde_p, eigvecs_H_eps_tilde_p) = regularize_matrix(H_eps_tilde_p)\n",
    "\n",
    "# Check if symmetric\n",
    "print(f'Is symmetric: {np.allclose(H_eps_tilde_p, H_eps_tilde_p.T)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = H_eps_tilde @ eps_tilde_inf\n",
    "res_p = H_eps_tilde_p @ eps_tilde_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2058259581892878e-05"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(res_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolution of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "# Construct dataframe for predictions\n",
    "Y = pd.DataFrame(np.zeros(Cinv.shape[0]), index=Cinv.index)\n",
    "for exp_name, data in central_data_dict.items():\n",
    "  if data.size == Y.loc[(slice(None), [exp_name], slice(None)), :].size:\n",
    "    Y.loc[(slice(None), [exp_name], slice(None)), :] = data\n",
    "  else:\n",
    "    raise ValueError\n",
    "  \n",
    "eps_0 = Y.to_numpy()[:,0] - FK @ f0.flatten()\n",
    "Ly = (L @ Y).to_numpy()[:,0]\n",
    "L_eps0 = L @ eps_0\n",
    "\n",
    "L_eps0_tilde = [np.dot(L_eps0, eigvecs[:,k]) for k in range(eigvecs.shape[1])]\n",
    "pre_computed_coefficients = [Linv @ eigvecs[:,k] * L_eps0_tilde[k] for k in range(eigvals_reg.size)] \n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def preds_t(t, learning_rate = 0.00001, eig_range=None):\n",
    "  if eig_range is None:\n",
    "    eig_range = eigvals_reg.size\n",
    "  predictions = [pre_computed_coefficients[k] * np.exp(-eigvals_reg[k] * learning_rate* t) for k in range(eig_range)] \n",
    "  predictions = np.sum(predictions, axis=0)\n",
    "\n",
    "  predictions = pd.DataFrame(predictions, index=Y.index)\n",
    "  predictions = Y - predictions\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = ['NMC_NC_NOTFIXED_P_EM-SIGMARED', 'SLAC_NC_NOTFIXED_P_EM-F2', 'BCDMS_NC_NOTFIXED_D_EM-F2', 'HERA_NC_318GEV_EM-SIGMARED']\n",
    "exp_titles = ['NMC', 'SLAC NC P', 'BCDMS NC D', 'HERA NC 318GEV']\n",
    "y_labels = [r'$\\sigma$', r'$F_2$', r'$F_2$', r'$\\sigma$']\n",
    "t = 0.\n",
    "fig_pred, axes_pred = plt.subplots(2, 2, figsize=(25, 25))  # Adjust figsize for desired plot size\n",
    "preds = preds_t(t, learning_rate=learning_rate_gd)\n",
    "\n",
    "scat_gf = []\n",
    "scat_gd = []\n",
    "text = []\n",
    "for i, ax in enumerate(axes_pred.flat):\n",
    "    y = Y.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "    p = preds.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "    trained_pred = pred_in_time[0][experiments[i]]\n",
    "    ax.scatter(np.arange(y.size), y, color='green', label='Central data', marker='o', s=100, alpha=0.4)\n",
    "    gf = ax.scatter(np.arange(y.size), p, color='orange', label='Analytical solution', marker='^', s=100)\n",
    "    gd = ax.scatter(np.arange(y.size), trained_pred, color='red', label='Gradient descent', marker='v', s=100)\n",
    "    scat_gf.append(gf)\n",
    "    scat_gd.append(gd)\n",
    "    #ax.set_xlabel(r'$x$')\n",
    "    ax.set_ylabel(y_labels[i], fontsize=20)\n",
    "    #ax.set_xscale('log')\n",
    "    ax.set_title(exp_titles[i], x=0.8,fontsize=20, fontweight='bold')\n",
    "    ax.legend(fontsize=20)\n",
    "    text_t = ax.text(0.05, 1.01, f't = {t}, learning rate = {learning_rate_gd}', fontsize=20, transform=ax.transAxes)\n",
    "    text.append(text_t)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "#fig.savefig('data_evolution.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = ['NMC_NC_NOTFIXED_P_EM-SIGMARED', 'SLAC_NC_NOTFIXED_P_EM-F2', 'BCDMS_NC_NOTFIXED_D_EM-F2', 'HERA_NC_318GEV_EM-SIGMARED']\n",
    "exp_titles = ['NMC', 'SLAC NC P', 'BCDMS NC D', 'HERA NC 318GEV']\n",
    "y_labels = [r'$\\sigma$', r'$F_2$', r'$F_2$', r'$\\sigma$']\n",
    "t = 0.\n",
    "fig_eps, axes_eps = plt.subplots(2, 2, figsize=(25, 25))  # Adjust figsize for desired plot size\n",
    "preds = preds_t(t, learning_rate=learning_rate_gd)\n",
    "\n",
    "scat_gf_eps = []\n",
    "scat_gd_eps = []\n",
    "text_eps = []\n",
    "for i, ax in enumerate(axes_eps.flat):\n",
    "    y = Y.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "    p = y - preds.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "    trained_pred = y[:,0] - pred_in_time[int(t)][experiments[i]].numpy()\n",
    "    ax.scatter(np.arange(y.size), y, color='green', label='Central data', marker='o', s=100, alpha=0.4)\n",
    "    gf = ax.scatter(np.arange(y.size), p, color='orange', label='Analytical solution', marker='^', s=100)\n",
    "    gd = ax.scatter(np.arange(y.size), trained_pred, color='red', label='Gradient descent', marker='v', s=100)\n",
    "    scat_gf_eps.append(gf)\n",
    "    scat_gd_eps.append(gd)\n",
    "    #ax.set_xlabel(r'$x$')\n",
    "    ax.set_ylabel(r'$\\epsilon$', fontsize=20)\n",
    "    #ax.set_xscale('log')\n",
    "    ax.set_title(exp_titles[i], x=0.8,fontsize=20, fontweight='bold')\n",
    "    ax.legend(fontsize=20)\n",
    "    text_t = ax.text(0.05, 1.01, f't = {t}, learning rate = {learning_rate_gd}', fontsize=20, transform=ax.transAxes)\n",
    "    text_eps.append(text_t)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "#fig.savefig('data_evolution.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_analytical(t, eig_range=None):\n",
    "  preds = preds_t(t, learning_rate=learning_rate_gd, eig_range=eig_range)\n",
    "  loss = 0\n",
    "  ndata = 0\n",
    "  for exp in Y.index.get_level_values('dataset').unique():\n",
    "    y = Y.xs(level='dataset', key=exp).to_numpy()\n",
    "    Cinv_exp = Cinv.xs(level=\"dataset\", key=exp).T.xs(level=\"dataset\", key=exp).to_numpy()\n",
    "    p = preds.xs(level='dataset', key=exp).to_numpy()\n",
    "    R = y[:,0] - p[:,0]\n",
    "    loss += 0.5 * R.T @ Cinv_exp @ R\n",
    "    ndata += Cinv_exp.shape[0]\n",
    "  return float(loss) / ndata\n",
    "\n",
    "def compute_loss_gd(t):\n",
    "  preds = pred_in_time[int(t)]\n",
    "  loss = 0\n",
    "  ndata = 0\n",
    "  for exp, pred in preds.items():\n",
    "    y = Y.xs(level='dataset', key=exp).to_numpy()\n",
    "    Cinv_exp = tf.convert_to_tensor(Cinv.xs(level=\"dataset\", key=exp).T.xs(level=\"dataset\", key=exp).to_numpy(), name=f'Cinv_{exp}', dtype='float32')\n",
    "    R = tf.convert_to_tensor(y[:,0] - pred, name=f'residue_{exp}', dtype='float32')\n",
    "    Cinv_R = tf.linalg.matvec(Cinv_exp, R)\n",
    "    loss += 0.5 * tf.reduce_sum(tf.multiply(R, Cinv_R))\n",
    "    ndata += Cinv_exp.shape[0]\n",
    "  return float(loss) / ndata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps_high = np.arange(1000,len(pred_in_time),1000)\n",
    "time_steps_low = np.arange(0,1000,2)\n",
    "time_steps = np.concatenate([time_steps_low, time_steps_high])\n",
    "aloss = [compute_loss_analytical(t, eig_range=100) for t in time_steps]\n",
    "gd_loss = [compute_loss_gd(t) for t in time_steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_loss, ax_loss = plt.subplots(figsize=(10, 7))  # Adjust figsize for desired plot size\n",
    "\n",
    "ax_loss.scatter(time_steps, aloss, label='Analytical solution')\n",
    "ax_loss.scatter(time_steps, gd_loss, label='Gradient descent')\n",
    "ax_loss.set_xlabel(r'$t$')\n",
    "ax_loss.set_ylabel(r'Loss function', fontsize=20)\n",
    "ax_loss.set_xscale('symlog')\n",
    "ax_loss.set_title('MSE in function of training time', x=0.5, fontsize=20, fontweight='bold')\n",
    "ax_loss.legend(fontsize=20)\n",
    "#text_t = ax.text(0.05, 1.01, f't = {t}, learning rate = {learning_rate_gd}', fontsize=20, transform=ax.transAxes)\n",
    "#text.append(text_t)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "fig_loss.savefig('Loss_function_time.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "import matplotlib\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "\n",
    "# Animation function\n",
    "# Update function for predicitons\n",
    "def update_preds(t):\n",
    "    preds = preds_t(t, learning_rate=learning_rate_gd)\n",
    "    for i, (gf, gd, text_t) in enumerate(zip(scat_gf, scat_gd, text)):\n",
    "        # Update the y-data for each subplot's line\n",
    "        y = Y.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "        p = preds.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "        trained_pred = pred_in_time[int(t)][experiments[i]]\n",
    "        data_gf = np.hstack(( np.arange(y.size)[:, np.newaxis] , p))\n",
    "        data_gd = np.hstack(( np.arange(y.size)[:, np.newaxis] , trained_pred[:,np.newaxis]))\n",
    "        gf.set_offsets(data_gf)  # Example: Add phase shift based on t and subplot index\n",
    "        gd.set_offsets(data_gd)  # Example: Add phase shift based on t and subplot index\n",
    "        text_t.set_text(f't = {t}, learning rate = {learning_rate_gd}')\n",
    "    return scat_gf + scat_gd + text\n",
    "\n",
    "# Update function for epsilon\n",
    "def update_eps(t):\n",
    "    preds = preds_t(t, learning_rate=learning_rate_gd)\n",
    "    for i, (gf, gd, text_t) in enumerate(zip(scat_gf_eps, scat_gd_eps, text_eps)):\n",
    "        # Update the y-data for each subplot's line\n",
    "        y = Y.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "        p = preds.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "        trained_pred = pred_in_time[int(t)][experiments[i]]\n",
    "        data_gf = np.hstack(( np.arange(y.size)[:, np.newaxis] , p))\n",
    "        data_gd = np.hstack(( np.arange(y.size)[:, np.newaxis] , trained_pred[:,np.newaxis]))\n",
    "        gf.set_offsets(data_gf)  # Example: Add phase shift based on t and subplot index\n",
    "        gd.set_offsets(data_gd)  # Example: Add phase shift based on t and subplot index\n",
    "        text_t.set_text(f't = {t}, learning rate = {learning_rate_gd}')\n",
    "    return scat_gf + scat_gd + text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani_pred = FuncAnimation(fig_pred, update_preds, frames=np.arange(0, len(pred_in_time), 1000), interval=10, blit=True, cache_frame_data=False)\n",
    "ani_eps = FuncAnimation(fig_eps, update_eps, frames=np.arange(0, len(pred_in_time), 1000), interval=10, blit=True, cache_frame_data=False)\n",
    "\n",
    "# Save the animation in the background\n",
    "ani_pred.save('prediction_evolution.mp4', writer='ffmpeg', fps=20)\n",
    "ani_eps.save('epsilon_evolution.mp4', writer='ffmpeg', fps=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnpdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
