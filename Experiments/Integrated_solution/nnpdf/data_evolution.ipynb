{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Keras backend\n"
     ]
    }
   ],
   "source": [
    "from validphys.api import API\n",
    "import sys\n",
    "\n",
    "# Add the path to the library folder\n",
    "sys.path.append('./lib')\n",
    "\n",
    "from utils import XGRID, build_fk_matrix, regularize_matrix\n",
    "from model import PDFmodel, generate_mse_loss\n",
    "from gen_dicts import generate_dicts\n",
    "from plot_utils import plot_eigvals\n",
    "from validphys.api import API\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions for the null space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "from typing import Any, Tuple\n",
    "import numpy.typing as npt\n",
    "def null_space_eig(eigvals: npt.ArrayLike, eigvecs: npt.NDArray[np.float64], tol: float = None) -> Tuple[npt.NDArray[np.float64],npt.NDArray[np.float64]]:\n",
    "  \"\"\"\n",
    "  Compute the kernel and its orthogonal space given as set\n",
    "  of eigenvalues and eigenvectors.\n",
    "\n",
    "  The kernel space is constructed out of the eigenvectors whose eigenvalue\n",
    "  is zero. The eigenvalues are compared to tolerance. If the value is greater\n",
    "  than the tolerance, then it is considered non-zero.\n",
    "\n",
    "  The tolerance is a parameter of this function. If `tol` is not provided,\n",
    "  then it is defined as the product of the largest eigenvalue with the\n",
    "  smallest precision number given the type the of the eigenvalues.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  eigvals: array\n",
    "    List of eigenvalues that are compared to the tolerance.\n",
    "  eigvecs: NDArray\n",
    "    Matrix where the second index select the i-th eigenvector relative\n",
    "    to the i-th eigenvalue, and the first index runs over the components\n",
    "    of each eigenvector.\n",
    "  tol: float\n",
    "    The tolerance for the zero-value veto.\n",
    "\n",
    "  Return\n",
    "  ------\n",
    "  The two sets of basis vectors for the kernel and its orthogonal space. These\n",
    "  are subspaces of the original eigenspace provided as an argument. The indexing\n",
    "  follows the same as `eigvecs`.\n",
    "  \"\"\"\n",
    "  if tol is None:\n",
    "    tol = np.amax(eigvals, initial=0.) * np.finfo(eigvecs.dtype).eps\n",
    "  num = np.sum(eigvals > tol, dtype=int) # Number of non-zero eigenvalues\n",
    "  ker = eigvecs[:,num:]\n",
    "  orth = eigvecs[:,:num]\n",
    "  return ker, orth\n",
    "  \n",
    "def project_matrix(matrix, basis1, basis2=None):\n",
    "  \"\"\"\n",
    "  Project the matrix into a given basis. If two bases are given,\n",
    "  then the first basis specifies the projection of the matrix on\n",
    "  the right space, while the second basis for the left space.\n",
    "\n",
    "  In particular, the projection is computed as follows $\\delta$\n",
    "\n",
    "  ..math::\n",
    "\n",
    "    M_{i_{B_1} j_{B_2}} = \\sum_{i=1}^{dim(B_1)} \\sum_{j=1}^{dim(B_2)}\n",
    "    \\mathbf{v}_{B_2}^{(j)T} \\cdot M \\cdot \\mathbf{v}_{B_1}^{(i)}\n",
    "\n",
    "  where :math:`\\mathbf{v}_{B}^{(i)}` is the i-th vector of the basis B.\n",
    "\n",
    "  If `basis2` is not provided, then basis2 is taken to be standard basis\n",
    "  (i.e. the one specified by the identity matrix).\n",
    "\n",
    "  Note that the matrix is not required to be squared.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  matrix: NDArray\n",
    "    The matrix that is projected.\n",
    "  basis1: NDArray\n",
    "    The (right) basis on which the matrix is projected.\n",
    "  basis2: NDArray\n",
    "    The (left) basis on which the matrix is projected.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  The projection of the matrix into the bases `basis1` and, if \n",
    "  given `basis2`.\n",
    "  \"\"\"\n",
    "  if basis2 is None:\n",
    "    basis2 = np.eye(matrix.shape[0])\n",
    "\n",
    "  emb_space1 = basis1.shape[0] # Embedding space base 1\n",
    "  emb_space2 = basis2.shape[0] # Embedding space base 2\n",
    "\n",
    "  # Check if the bases are compatible with the matrix\n",
    "  if matrix.shape[0] != emb_space2 or matrix.shape[1] != emb_space1:\n",
    "    raise ValueError ('The matrix cannot be projected into the two bases.')\n",
    "\n",
    "  M_orth = basis2.T @ matrix @ basis1\n",
    "\n",
    "  return M_orth\n",
    "\n",
    "def project_vector(vector, basis):\n",
    "  \"\"\"\n",
    "  Project a vector into a given basis.\n",
    "  \"\"\"\n",
    "  basis_dim = basis.shape[1]\n",
    "  space_dim = basis.shape[0]\n",
    "  if space_dim != vector.shape[0]:\n",
    "    raise ValueError ('The matrix cannot be projected into the basis')\n",
    "  \n",
    "  res = [np.dot(vector, basis[:,i]) for i in range(basis_dim)]\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 14132124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of DIS dataset\n",
    "dataset_inputs = [\n",
    "  #{'dataset': 'NMC_NC_NOTFIXED_DW_EM-F2', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'NMC_NC_NOTFIXED_P_EM-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'SLAC_NC_NOTFIXED_P_DW_EM-F2', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'SLAC_NC_NOTFIXED_D_DW_EM-F2', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'BCDMS_NC_NOTFIXED_P_DW_EM-F2', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'BCDMS_NC_NOTFIXED_D_DW_EM-F2', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'CHORUS_CC_NOTFIXED_PB_DW_NU-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'CHORUS_CC_NOTFIXED_PB_DW_NB-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'NUTEV_CC_NOTFIXED_FE_DW_NU-SIGMARED', 'cfac': ['MAS'], 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'NUTEV_CC_NOTFIXED_FE_DW_NB-SIGMARED', 'cfac': ['MAS'], 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'HERA_NC_318GEV_EM-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'HERA_NC_225GEV_EP-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'HERA_NC_251GEV_EP-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'HERA_NC_300GEV_EP-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'HERA_NC_318GEV_EP-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'HERA_CC_318GEV_EM-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'HERA_CC_318GEV_EP-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'HERA_NC_318GEV_EAVG_CHARM-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'HERA_NC_318GEV_EAVG_BOTTOM-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "]\n",
    "\n",
    "# Dictionary for validphys API\n",
    "common_dict = dict(\n",
    "    dataset_inputs=dataset_inputs,\n",
    "    metadata_group=\"nnpdf31_process\",\n",
    "    use_cuts='internal',\n",
    "    datacuts={'q2min': 3.49, 'w2min': 12.5},\n",
    "    theoryid=708,\n",
    "    t0pdfset='NNPDF40_nnlo_as_01180',\n",
    "    use_t0=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve data from NNPDF\n",
    "groups_data = API.procs_data(**common_dict)\n",
    "tuple_of_dicts = generate_dicts(groups_data)\n",
    "fk_table_dict = tuple_of_dicts.fk_tables\n",
    "central_data_dict = tuple_of_dicts.central_data\n",
    "FK = build_fk_matrix(fk_table_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHAPDF 6.5.4 loading /opt/homebrew/Caskroom/miniconda/base/envs/nnpdf/share/LHAPDF/NNPDF40_nnlo_as_01180/NNPDF40_nnlo_as_01180_0000.dat\n",
      "NNPDF40_nnlo_as_01180 PDF set, member #0, version 1; LHAPDF ID = 331100\n"
     ]
    }
   ],
   "source": [
    "C = API.groups_covmat_no_table(**common_dict)\n",
    "\n",
    "# Serialize covmat\n",
    "C_index = C.index\n",
    "C_col = C.columns\n",
    "Cinv = np.linalg.inv(C)\n",
    "Cinv = pd.DataFrame(Cinv, index=C_index, columns=C_col)\n",
    "\n",
    "# Diagonalize covariance matric\n",
    "eigvals_Cinv, R_Y = np.linalg.eigh(Cinv)\n",
    "if eigvals_Cinv[-1] > eigvals_Cinv[0]:\n",
    "    eigvals_Cinv = eigvals_Cinv[::-1]\n",
    "    R_Y = R_Y[:,::-1]\n",
    "D_Y = np.zeros_like(R_Y)\n",
    "np.fill_diagonal(D_Y, eigvals_Cinv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dataframe for predictions\n",
    "Y = pd.DataFrame(np.zeros(Cinv.shape[0]), index=Cinv.index)\n",
    "for exp_name, data in central_data_dict.items():\n",
    "  if data.size == Y.loc[(slice(None), [exp_name], slice(None)), :].size:\n",
    "    Y.loc[(slice(None), [exp_name], slice(None)), :] = data\n",
    "  else:\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnpdf_model = PDFmodel(input=XGRID,\n",
    "                       outputs=9,\n",
    "                       architecture=[28,20],\n",
    "                       activations=['tanh', 'tanh'],\n",
    "                       kernel_initializer='RandomNormal',\n",
    "                       user_ki_args={'mean': 0.0, 'stddev': 1.0},\n",
    "                       seed=seed,\n",
    "                       dtype='float64')\n",
    "NTK = nnpdf_model.compute_ntk()\n",
    "\n",
    "# Flatten NTK\n",
    "prod = 1\n",
    "oldshape = NTK.shape\n",
    "for k in oldshape[2:]:\n",
    "    prod *= k\n",
    "NTK_flat = np.array(NTK).reshape(prod,-1)\n",
    "\n",
    "# Compute predictions at initialization\n",
    "f0 = nnpdf_model.predict(squeeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from GD training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('training.pkl', 'rb') as file:\n",
    "    results = pickle.load(file)\n",
    "\n",
    "pred_in_time = results[1]\n",
    "pdfs_in_time = results[2]\n",
    "learning_rate_gd = 0.00000001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing matrices from notes\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $M = (FK)^T C_Y^{-1} (FK) = RDR^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = FK.T @ Cinv.to_numpy() @ FK\n",
    "M, (eigvals_M, R) = regularize_matrix(M, tol=None)\n",
    "\n",
    "# Construct diagonal matrix\n",
    "D = np.zeros_like(R)\n",
    "np.fill_diagonal(D, eigvals_M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\tilde{H} = D^{1/2} R^T \\Theta R D^{1/2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntk, (eigvals_ntk, R_ntk) = regularize_matrix(NTK_flat)\n",
    "H_tilde = np.sqrt(D) @ R.T @ ntk @ R @ np.sqrt(D)\n",
    "H_tilde, (eigvals_H_tilde, eigvecs_H_tilde) = regularize_matrix(H_tilde, tol=None)\n",
    "\n",
    "# Check if symmetric\n",
    "print(f'Is symmetric: {np.allclose(H_tilde, H_tilde.T)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null space of $M$ and $\\tilde{H}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we compute the $\\textrm{ker}(M)$ and its orthogonal space $R(M)$. We then project the matrix $M$ into the these two bases. In particular, we apply\n",
    "$$\n",
    "M_{i j} = (\\mathbf{v^{(i)}_{B_2}})^T \\cdot \\mathbf{M} \\cdot \\mathbf{v^{(j)}_{B_1}} \\,,\n",
    "$$\n",
    "where $\\mathbf{v^{i}_{B_1}}$ and $\\mathbf{v^{j}_{B_2}}$ are the i-th and j-th vectors of the respective bases.\n",
    "\n",
    "When we compute the null space, we need to choose the threshold for the smallest distinguishable eigenvalue. If no tolerance is provided to the `null_space_eig` function, the default option is used (see above). Otherwise, we can specify a custom tolerance. We could choose such value by looking at the eigenvalues of the matrix $M$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 4501962.482500519\n",
      "2 : 1611794.2231508063\n",
      "3 : 656336.8239098041\n",
      "4 : 529986.6542886588\n",
      "5 : 160906.35937601666\n",
      "6 : 152653.25231474565\n",
      "7 : 137431.8778275906\n",
      "8 : 111497.0201272436\n",
      "9 : 103530.19569058708\n",
      "10 : 77534.6677476217\n",
      "11 : 74051.62283799764\n",
      "12 : 51334.52972635849\n",
      "13 : 46276.75356787624\n",
      "14 : 40624.587537446314\n",
      "15 : 36797.59404387643\n",
      "16 : 34856.831448954945\n",
      "17 : 31118.33117213023\n",
      "18 : 24162.090154794583\n",
      "19 : 23009.658665213006\n",
      "20 : 21393.045643644942\n",
      "21 : 20771.815897040124\n",
      "22 : 18579.258785449296\n",
      "23 : 16966.64697764954\n",
      "24 : 16151.38296418803\n",
      "25 : 15709.19291735395\n",
      "26 : 15452.571087635839\n",
      "27 : 14805.017362400145\n",
      "28 : 14424.193238841144\n",
      "29 : 13299.732276637764\n",
      "30 : 13045.068878934711\n",
      "31 : 12391.612302926651\n",
      "32 : 11969.216349270544\n",
      "33 : 10837.493680749745\n",
      "34 : 10399.045437910148\n",
      "35 : 9984.69135816926\n",
      "36 : 9619.885504185886\n",
      "37 : 9023.136069034628\n",
      "38 : 8732.156929857694\n",
      "39 : 8471.1654950175\n",
      "40 : 8042.005406821709\n",
      "41 : 7794.2930522539145\n",
      "42 : 7151.795793641496\n",
      "43 : 6854.480170365759\n",
      "44 : 6610.6221543693355\n",
      "45 : 6515.051951289397\n",
      "46 : 6127.671104007538\n",
      "47 : 5766.920206829896\n",
      "48 : 5681.720499880346\n",
      "49 : 5093.798069381098\n",
      "50 : 5059.5347791311715\n",
      "51 : 4870.535978441841\n",
      "52 : 4630.148628931684\n",
      "53 : 4336.1614727866745\n",
      "54 : 4212.306846061568\n",
      "55 : 3805.6108483148128\n",
      "56 : 3575.8615311142034\n",
      "57 : 3417.148852163342\n",
      "58 : 3312.0447047963216\n",
      "59 : 3150.3877888222623\n",
      "60 : 3052.950536932681\n",
      "61 : 2804.4626378470434\n",
      "62 : 2695.9216173685027\n",
      "63 : 2607.1449543224758\n",
      "64 : 2461.2693638159076\n",
      "65 : 2385.5477822207617\n",
      "66 : 2298.6260104046537\n",
      "67 : 2159.8851936620076\n",
      "68 : 2063.357031925727\n",
      "69 : 2056.6814402730724\n",
      "70 : 1980.2448374390617\n",
      "71 : 1814.50186518526\n",
      "72 : 1742.6450419734285\n",
      "73 : 1697.8571969824638\n",
      "74 : 1595.274721078389\n",
      "75 : 1537.1927322244544\n",
      "76 : 1335.9694585384868\n",
      "77 : 1290.0659676496723\n",
      "78 : 1274.2827176847027\n",
      "79 : 1210.9652906146048\n",
      "80 : 1148.634280052148\n",
      "81 : 1141.0381192286507\n",
      "82 : 1100.8943715772778\n",
      "83 : 1049.7508169850955\n",
      "84 : 1024.124848913045\n",
      "85 : 1009.0601097281154\n",
      "86 : 936.0659667512035\n",
      "87 : 916.573332446418\n",
      "88 : 836.9589915003132\n",
      "89 : 826.7438419941946\n",
      "90 : 804.9323021230327\n",
      "91 : 736.2551841495388\n",
      "92 : 729.8373704870664\n",
      "93 : 711.3580796583432\n",
      "94 : 696.8658438354937\n",
      "95 : 678.6532170890307\n",
      "96 : 637.0040647313898\n",
      "97 : 612.9206856196059\n",
      "98 : 604.8640837504314\n",
      "99 : 550.135597870357\n",
      "100 : 496.19014732541007\n",
      "101 : 467.77634281225073\n",
      "102 : 458.1908840719801\n",
      "103 : 438.9970079854209\n",
      "104 : 417.16346193493274\n",
      "105 : 401.8371144144307\n",
      "106 : 385.6663896021959\n",
      "107 : 378.7465499844278\n",
      "108 : 364.1050671327063\n",
      "109 : 351.33858694301773\n",
      "110 : 345.28108677769427\n",
      "111 : 323.58279561393937\n",
      "112 : 306.7223886242917\n",
      "113 : 283.56343789204755\n",
      "114 : 276.5741002592983\n",
      "115 : 259.58126222583155\n",
      "116 : 247.49589678835878\n",
      "117 : 237.69302424802913\n",
      "118 : 231.3388059898069\n",
      "119 : 203.29726072423966\n",
      "120 : 200.99884638172932\n",
      "121 : 184.4812459550726\n",
      "122 : 182.7104077654433\n",
      "123 : 178.98722371818\n",
      "124 : 171.88994199761362\n",
      "125 : 152.0435259811124\n",
      "126 : 147.65216480035662\n",
      "127 : 132.93973961615558\n",
      "128 : 127.16084733006662\n",
      "129 : 124.54092884826478\n",
      "130 : 112.2920351163457\n",
      "131 : 105.84904793451528\n",
      "132 : 99.73639876609998\n",
      "133 : 82.29721922898504\n",
      "134 : 81.86103167497865\n",
      "135 : 75.86957513421494\n",
      "136 : 66.67286598222236\n",
      "137 : 64.94422737242074\n",
      "138 : 61.032700729346764\n",
      "139 : 57.69689862822728\n",
      "140 : 56.40364224608013\n",
      "141 : 55.03349233646244\n",
      "142 : 51.76206542854188\n",
      "143 : 45.702352558977175\n",
      "144 : 40.36652203344993\n",
      "145 : 38.332430153529614\n",
      "146 : 36.892159886821354\n",
      "147 : 34.752650434699305\n",
      "148 : 29.903666950766706\n",
      "149 : 28.56436060083335\n",
      "150 : 25.626227403792495\n",
      "151 : 23.522791179069173\n",
      "152 : 22.23976408742001\n",
      "153 : 21.86568242868401\n",
      "154 : 20.256511821867935\n",
      "155 : 19.48343671956338\n",
      "156 : 17.661519537069918\n",
      "157 : 17.244751767673822\n",
      "158 : 16.537955578406383\n",
      "159 : 14.94997671513885\n",
      "160 : 13.67330478961744\n",
      "161 : 13.08122153967553\n",
      "162 : 12.846365563703056\n",
      "163 : 11.847199408018488\n",
      "164 : 11.275287966140993\n",
      "165 : 10.58889944792314\n",
      "166 : 10.089965092329653\n",
      "167 : 8.998021526388387\n",
      "168 : 8.02157737734962\n",
      "169 : 7.924874075946855\n",
      "170 : 7.228524516553569\n",
      "171 : 6.335794192754895\n",
      "172 : 6.040504910752283\n",
      "173 : 5.75290606740802\n",
      "174 : 5.620246720643449\n",
      "175 : 4.987806779430643\n",
      "176 : 4.382145348324953\n",
      "177 : 4.213385948001963\n",
      "178 : 4.00141188741025\n",
      "179 : 3.922354300077363\n",
      "180 : 3.676875281772373\n",
      "181 : 3.152770800607062\n",
      "182 : 3.0572146481713833\n",
      "183 : 3.0098396800173775\n",
      "184 : 2.8862579523099066\n",
      "185 : 2.66334823951271\n",
      "186 : 2.498609328419211\n",
      "187 : 2.454253358576072\n",
      "188 : 2.239013625121936\n",
      "189 : 2.097448736781927\n",
      "190 : 1.9851147282353105\n",
      "191 : 1.846295506156837\n",
      "192 : 1.810633124123095\n",
      "193 : 1.6005288007346394\n",
      "194 : 1.5980188294097761\n",
      "195 : 1.475484303471608\n",
      "196 : 1.3782377709073443\n",
      "197 : 1.2285129338659833\n",
      "198 : 1.138562806393486\n",
      "199 : 1.0639254345972968\n",
      "200 : 0.9849953297348668\n",
      "201 : 0.9353082896063178\n",
      "202 : 0.8786645537636427\n",
      "203 : 0.8440294502397666\n",
      "204 : 0.8162142844477609\n",
      "205 : 0.6461944298852076\n",
      "206 : 0.621304075854333\n",
      "207 : 0.5758331092081719\n",
      "208 : 0.5442181641651092\n",
      "209 : 0.5067302479656115\n",
      "210 : 0.47023862221803714\n",
      "211 : 0.4286857748657395\n",
      "212 : 0.3517328984213115\n",
      "213 : 0.35026858481446127\n",
      "214 : 0.33196525862595494\n",
      "215 : 0.30031078008267087\n",
      "216 : 0.2730834367388514\n",
      "217 : 0.25960182647492513\n",
      "218 : 0.24913028042587515\n",
      "219 : 0.21896201108394184\n",
      "220 : 0.20519272624636128\n",
      "221 : 0.1939361011457887\n",
      "222 : 0.15526527353849826\n",
      "223 : 0.1513318345787172\n",
      "224 : 0.12549790188091536\n",
      "225 : 0.0970405620985589\n",
      "226 : 0.09599438648060747\n",
      "227 : 0.09255095996986495\n",
      "228 : 0.07677405283432692\n",
      "229 : 0.07203987704144653\n",
      "230 : 0.0645002503580101\n",
      "231 : 0.057870311800498835\n",
      "232 : 0.05193314969459988\n",
      "233 : 0.04739343955897493\n",
      "234 : 0.04571207856832509\n",
      "235 : 0.04373078202002591\n",
      "236 : 0.03352470446575863\n",
      "237 : 0.031137208284091215\n",
      "238 : 0.030046339103695554\n",
      "239 : 0.02585905256484362\n",
      "240 : 0.024964088604611752\n",
      "241 : 0.0174938482595709\n",
      "242 : 0.01674487769183905\n",
      "243 : 0.012293979338440819\n",
      "244 : 0.011982368055813219\n",
      "245 : 0.010857330906888818\n",
      "246 : 0.01070902948387389\n",
      "247 : 0.00904029225838713\n",
      "248 : 0.008118263153798894\n",
      "249 : 0.007851166614679246\n",
      "250 : 0.007618606428317587\n",
      "251 : 0.004779292141417281\n",
      "252 : 0.004301411336876613\n",
      "253 : 0.0036765308696712256\n",
      "254 : 0.0025213541482171095\n",
      "255 : 0.002215118114193955\n",
      "256 : 0.0019291894248434382\n",
      "257 : 0.0016220999219090473\n",
      "258 : 0.001565575090923983\n",
      "259 : 0.0013394395809549708\n",
      "260 : 0.0011339573016078527\n",
      "261 : 0.0009341790920040864\n",
      "262 : 0.0008016529293389539\n",
      "263 : 0.0005473409955940694\n",
      "264 : 0.0005083272122616793\n",
      "265 : 0.0004910106452207758\n",
      "266 : 0.00029364163691340486\n",
      "267 : 0.0002743921992619414\n",
      "268 : 0.0002460213775865931\n",
      "269 : 0.00024184922775384606\n",
      "270 : 0.0002189473401207217\n",
      "271 : 0.000176878518899144\n",
      "272 : 0.00011880155120657748\n",
      "273 : 9.259931933289063e-05\n",
      "274 : 8.666703895761571e-05\n",
      "275 : 7.424298738016133e-05\n",
      "276 : 7.113595034166409e-05\n",
      "277 : 6.963866190459611e-05\n",
      "278 : 5.171611281399182e-05\n",
      "279 : 3.9507938258463836e-05\n",
      "280 : 3.664708789618877e-05\n",
      "281 : 3.3525692673905906e-05\n",
      "282 : 2.5626991286941612e-05\n",
      "283 : 1.6359622254137886e-05\n",
      "284 : 1.4151540313879984e-05\n",
      "285 : 1.03673568715549e-05\n",
      "286 : 9.626865707718406e-06\n",
      "287 : 8.561889100413559e-06\n",
      "288 : 8.241121156453454e-06\n",
      "289 : 6.605173699013379e-06\n",
      "290 : 5.438849496823223e-06\n",
      "291 : 3.9882431030251064e-06\n",
      "292 : 3.427045066349335e-06\n",
      "293 : 3.2503056171269944e-06\n",
      "294 : 2.5094709573864896e-06\n",
      "295 : 2.2453658099937218e-06\n",
      "296 : 1.7410356888147873e-06\n",
      "297 : 1.2045757863400347e-06\n",
      "298 : 1.0982093095331097e-06\n",
      "299 : 9.470391684842621e-07\n",
      "300 : 7.131362818532897e-07\n",
      "301 : 5.256407388667862e-07\n",
      "302 : 4.293392022465944e-07\n",
      "303 : 3.9454096927646087e-07\n",
      "304 : 2.5442469874276776e-07\n",
      "305 : 2.1353950593169296e-07\n",
      "306 : 1.8353966392907262e-07\n",
      "307 : 1.6625820633696528e-07\n",
      "308 : 8.17398958889326e-08\n",
      "309 : 6.754983088900357e-08\n",
      "310 : 5.6481780821115855e-08\n",
      "311 : 2.4437744344352878e-08\n",
      "312 : 2.2704905075022638e-08\n",
      "313 : 1.8345600586063234e-08\n",
      "314 : 8.922357607626701e-09\n",
      "315 : 4.601098117843566e-09\n",
      "316 : 4.285378608666737e-09\n",
      "317 : 3.773486976934341e-09\n",
      "318 : 2.8198234062633753e-09\n",
      "319 : 1.5979712731772591e-09\n",
      "320 : 1.3264923158026798e-09\n",
      "321 : 0.0\n",
      "322 : 0.0\n",
      "323 : 0.0\n",
      "324 : 0.0\n",
      "325 : 0.0\n",
      "326 : 0.0\n",
      "327 : 0.0\n",
      "328 : 0.0\n",
      "329 : 0.0\n",
      "330 : 0.0\n",
      "331 : 0.0\n",
      "332 : 0.0\n",
      "333 : 0.0\n",
      "334 : 0.0\n",
      "335 : 0.0\n",
      "336 : 0.0\n",
      "337 : 0.0\n",
      "338 : 0.0\n",
      "339 : 0.0\n",
      "340 : 0.0\n",
      "341 : 0.0\n",
      "342 : 0.0\n",
      "343 : 0.0\n",
      "344 : 0.0\n",
      "345 : 0.0\n",
      "346 : 0.0\n",
      "347 : 0.0\n",
      "348 : 0.0\n",
      "349 : 0.0\n",
      "350 : 0.0\n",
      "351 : 0.0\n",
      "352 : 0.0\n",
      "353 : 0.0\n",
      "354 : 0.0\n",
      "355 : 0.0\n",
      "356 : 0.0\n",
      "357 : 0.0\n",
      "358 : 0.0\n",
      "359 : 0.0\n",
      "360 : 0.0\n",
      "361 : 0.0\n",
      "362 : 0.0\n",
      "363 : 0.0\n",
      "364 : 0.0\n",
      "365 : 0.0\n",
      "366 : 0.0\n",
      "367 : 0.0\n",
      "368 : 0.0\n",
      "369 : 0.0\n",
      "370 : 0.0\n",
      "371 : 0.0\n",
      "372 : 0.0\n",
      "373 : 0.0\n",
      "374 : 0.0\n",
      "375 : 0.0\n",
      "376 : 0.0\n",
      "377 : 0.0\n",
      "378 : 0.0\n",
      "379 : 0.0\n",
      "380 : 0.0\n",
      "381 : 0.0\n",
      "382 : 0.0\n",
      "383 : 0.0\n",
      "384 : 0.0\n",
      "385 : 0.0\n",
      "386 : 0.0\n",
      "387 : 0.0\n",
      "388 : 0.0\n",
      "389 : 0.0\n",
      "390 : 0.0\n",
      "391 : 0.0\n",
      "392 : 0.0\n",
      "393 : 0.0\n",
      "394 : 0.0\n",
      "395 : 0.0\n",
      "396 : 0.0\n",
      "397 : 0.0\n",
      "398 : 0.0\n",
      "399 : 0.0\n",
      "400 : 0.0\n",
      "401 : 0.0\n",
      "402 : 0.0\n",
      "403 : 0.0\n",
      "404 : 0.0\n",
      "405 : 0.0\n",
      "406 : 0.0\n",
      "407 : 0.0\n",
      "408 : 0.0\n",
      "409 : 0.0\n",
      "410 : 0.0\n",
      "411 : 0.0\n",
      "412 : 0.0\n",
      "413 : 0.0\n",
      "414 : 0.0\n",
      "415 : 0.0\n",
      "416 : 0.0\n",
      "417 : 0.0\n",
      "418 : 0.0\n",
      "419 : 0.0\n",
      "420 : 0.0\n",
      "421 : 0.0\n",
      "422 : 0.0\n",
      "423 : 0.0\n",
      "424 : 0.0\n",
      "425 : 0.0\n",
      "426 : 0.0\n",
      "427 : 0.0\n",
      "428 : 0.0\n",
      "429 : 0.0\n",
      "430 : 0.0\n",
      "431 : 0.0\n",
      "432 : 0.0\n",
      "433 : 0.0\n",
      "434 : 0.0\n",
      "435 : 0.0\n",
      "436 : 0.0\n",
      "437 : 0.0\n",
      "438 : 0.0\n",
      "439 : 0.0\n",
      "440 : 0.0\n",
      "441 : 0.0\n",
      "442 : 0.0\n",
      "443 : 0.0\n",
      "444 : 0.0\n",
      "445 : 0.0\n",
      "446 : 0.0\n",
      "447 : 0.0\n",
      "448 : 0.0\n",
      "449 : 0.0\n",
      "450 : 0.0\n"
     ]
    }
   ],
   "source": [
    "for i, val in enumerate(eigvals_M):\n",
    "  print(f'{i+1} : {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ker_M, orth_M = null_space_eig(eigvals_M, R, tol=1.e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_pp = project_matrix(M, orth_M, orth_M)\n",
    "M_kk = project_matrix(M, ker_M, ker_M)\n",
    "M_pk = project_matrix(M, ker_M, orth_M)\n",
    "M_kp = project_matrix(M, orth_M, ker_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"det(M_pp) = {np.linalg.det(M_pp)}\")\n",
    "print(f\"cond(M_pp) = {np.linalg.cond(M_pp)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the matrix $M$ is decomposed as follows\n",
    "$$\n",
    "\\mathbf{M} = \\left(\\begin{matrix}\n",
    "\\mathbf{M}_{KK} & \\mathbf{M}_{K \\bot}\\\\\n",
    "\\mathbf{M}_{\\bot K} & \\mathbf{M}_{\\bot \\bot}\\\\\n",
    "\\end{matrix} \\right) \\,.\n",
    "$$\n",
    "Note that, by definition of null space, only $M_{\\bot\\bot} \\neq 0$. The next cell checks if that is effectively true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'M_pp ?= 0 : {np.allclose(np.zeros_like(M_pp), M_pp)}')\n",
    "print(f'M_kk ?= 0 : {np.allclose(np.zeros_like(M_kk), M_kk)}')\n",
    "print(f'M_kp ?= 0 : {np.allclose(np.zeros_like(M_kp), M_kp)}')\n",
    "print(f'M_pk ?= 0 : {np.allclose(np.zeros_like(M_pk), M_pk)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By constructing the matrix $M_{\\bot\\bot}$, we have projected out the null modes. Hence, this matrix must be invertible. We check that in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_pp_inv = np.linalg.inv(M_pp)\n",
    "print(f'M_pp_inv @ M_pp ?= Id: {np.allclose(M_pp_inv @ M_pp, np.eye(M_pp.shape[0]))}')\n",
    "print(f'M_pp @ M_pp_inv ?= Id: {np.allclose(M_pp @ M_pp_inv, np.eye(M_pp.shape[0]))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to compute the null space and its orthogonal space of the evolution matrix $\\tilde{H}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ker_H_tilde, orth_H_tilde = null_space_eig(eigvals_H_tilde, eigvecs_H_tilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_tilde_pp = project_matrix(H_tilde, orth_H_tilde, orth_H_tilde)\n",
    "H_tilde_kk = project_matrix(H_tilde, ker_H_tilde, ker_H_tilde)\n",
    "H_tilde_pk = project_matrix(H_tilde, ker_H_tilde, orth_H_tilde)\n",
    "H_tilde_kp = project_matrix(H_tilde, orth_H_tilde, ker_H_tilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'H_tilde_pp ?= 0 : {np.allclose(np.zeros_like(H_tilde_pp), H_tilde_pp)}')\n",
    "print(f'H_tilde_kk ?= 0 : {np.allclose(np.zeros_like(H_tilde_kk), H_tilde_kk)}')\n",
    "print(f'H_tilde_kp ?= 0 : {np.allclose(np.zeros_like(H_tilde_kp), H_tilde_kp)}')\n",
    "print(f'H_tilde_pk ?= 0 : {np.allclose(np.zeros_like(H_tilde_pk), H_tilde_pk)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the null space of $\\tilde{H}$ and that of $M$ are not the same in general:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{ker_H_tilde.shape} != {ker_M.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, the null space of the evolution matrix $\\tilde{H}$ is larger that that of $M$. This is kind of expected, as the evolution matrix accounts for the contribution of the NTK which is known to provide many small eigenvalues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When is $\\tilde{H}$ invertible?\n",
    "The matrix $\\tilde{H}$ is not invertible on its own. We can check that directly in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  np.linalg.inv(H_tilde)\n",
    "except np.linalg.LinAlgError:\n",
    "  print('Error detected. The matrix is not ivertible.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was expected, as $\\tilde{H}$ is constructed from the full matrix $M$. We can try to construct $\\tilde{H}$ using $M_{\\bot\\bot}$, which should be equivalent to projecting $\\tilde{H}$ in $M_{\\bot\\bot}$. Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_tilde_p = project_matrix(H_tilde, orth_M, orth_M)\n",
    "try:\n",
    "  H_tilde_p_inv = np.linalg.inv(H_tilde_p)\n",
    "except np.linalg.LinAlgError:\n",
    "  print('Error detected. The matrix is not ivertible.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to work. However, if we try to compute $\\tilde{H}_{\\bot} \\cdot \\tilde{H}_{\\bot}^{-1}$ we obtain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = np.linalg.inv(H_tilde_p)\n",
    "print(f'Printing the first 10 diagonal entries: \\n{(inv @ H_tilde_p).diagonal()[:10]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this is not what we thought we computed, namely the inverse matrix of $\\tilde{H}_{\\bot}$. The reason is the high condition number of the matrix, which makes it highly unstable.\n",
    "\n",
    "We then resort to $\\tilde{H}_{\\bot\\bot}$ computed before. This takes in account the null modes of the NTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  H_tilde_pp_inv = np.linalg.inv(H_tilde_pp)\n",
    "except np.linalg.LinAlgError:\n",
    "  print('Error detected. The matrix is not ivertible.')\n",
    "\n",
    "print(f'Printing the first 10 diagonal entries: \\n{(H_tilde_pp_inv @ H_tilde_pp).diagonal()[:10]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection of $(FK)$: $(FK)_{\\bot}$ and $(FK)_{K}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to project $(FK)$ into these two spaces. Remember that $(FK)$ is a linear map from the space of PDF to the space of the data\n",
    "$$\n",
    "(FK) : \\mathbb{R}^{\\textrm{PDF}} \\longrightarrow \\mathbb{R}^{\\textrm{Data}} \\,.\n",
    "$$\n",
    "The projection is then applied to the right-space only, which is the PDF space. Hence, after projection, the $(FK)$ table can be written as\n",
    "$$\n",
    "(FK) = \\left( \\, (FK)_{K} \\hspace{5mm}  (FK)_{\\bot} \\,\\right) \\,,\n",
    "$$\n",
    "where each $(FK)_{B}$ is a linear map from PDF to data space. Note that $\\textrm{ker}(M) = \\textrm{ker}(FK)$. Thus, also in this case $(FK)_{K}$. We can check that in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FK, (s_FK, vh_FK) = regularize_matrix(FK, tol=np.finfo(FK.dtype).eps * np.amax(eigvals_M, initial=0.)/ np.amax(s_FK, initial=0.))\n",
    "FK_p = project_matrix(FK, orth_M, np.eye(FK.shape[0]))\n",
    "FK_k = project_matrix(FK, ker_M, np.eye(FK.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A naive comparison of the two components $(FK)_K$ and $(FK)_{\\bot}$ would not lead to the desired result, as shown in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'FK_k ?= 0 : {np.allclose(np.zeros_like(FK_k), FK_k)}')\n",
    "print(f'FK_p ?= 0 : {np.allclose(np.zeros_like(FK_p), FK_p)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason being that the tolerance used to construct $\\textrm{Ker}(M)$ and $R(M)$ was defined using the largest eigenvalue of the the matrix $M$. When we move to $(FK)$, we then need to scale the tolerance appropriately so that we have consistent results. In that case, we have $M \\sim (FK)^2$, and we could expect that $\\textrm{tol}_{FK} = \\sqrt{\\textrm{tol}_M}$. Let's try and see if we get the expected result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol =  np.sqrt(np.amax(eigvals_M, initial=0.) * np.finfo(eigvals_M.dtype).eps)\n",
    "print(f'Comparing with tolerance = {tol}.')\n",
    "print(f'FK_k ?= 0 : {np.allclose(np.zeros_like(FK_k), FK_k, atol=tol)}')\n",
    "print(f'FK_p ?= 0 : {np.allclose(np.zeros_like(FK_p), FK_p, atol=tol)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then set to zeros all those entries that are lower that `tol`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @TODO\n",
    "# Should I do the same FK_p\n",
    "FK_k[FK_k <= tol] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reconstruct the full $(FK)$ using these `regularized` components. In particular, we can write\n",
    "$$\n",
    "  (FK) = \\biggl( (FK)_{\\bot} \\;, (FK)_K \\biggr)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "FK_proj = np.hstack((FK_p, FK_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a consistency check, we can verify that $(FK) \\Theta (FK)^T = (FK_{\\bot}) \\Theta_{\\bot\\bot} (FK_{\\bot})^T$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntk_pp = project_matrix(ntk, orth_M, orth_M)\n",
    "ntk_kp = project_matrix(ntk, orth_M, ker_M)\n",
    "ntk_pk = project_matrix(ntk, ker_M, orth_M)\n",
    "ntk_kk = project_matrix(ntk, ker_M, ker_M)\n",
    "ntk_proj = np.block([[ntk_pp, ntk_pk],\n",
    "                     [ntk_kp, ntk_kk]])\n",
    "test1 = FK_p @ ntk_pp @ FK_p.T\n",
    "test2 = FK_proj @ ntk_proj @ FK_proj.T\n",
    "np.allclose(test1, test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another consistency check is the following\n",
    "$$\n",
    "M_{\\bot \\bot} = (FK)_{\\bot}^T C_Y^{-1} (FK)_{\\bot}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_pp_reconstructed = FK_p.T @ Cinv.to_numpy(dtype='float64') @ FK_p\n",
    "M_pp_recon_inv = np.linalg.inv(M_pp_reconstructed)\n",
    "#M_pp_reconstructed, _ = regularize_matrix(M_pp_reconstructed, tol=tol)\n",
    "print(f\"M_pp == M_pp_recon: {np.allclose(M_pp, M_pp_reconstructed)}\")\n",
    "print(f\"M_pp_recon_inv @ M_pp_recon == Id: {np.allclose(M_pp_reconstructed @ M_pp_recon_inv, np.eye(M_pp.shape[0]))}\")\n",
    "print(f\"M_pp_recon_inv == M_pp_inv: {np.allclose(M_pp_recon_inv, M_pp_inv)}\")\n",
    "print(f\"M_pp_inv @ M_pp_recon == Id: {np.allclose(M_pp_inv @ M_pp_reconstructed, np.eye(M_pp.shape[0]))}\")\n",
    "print(f\"M_pp_recon @ M_pp_inv == Id: {np.allclose(M_pp_reconstructed @ M_pp_inv, np.eye(M_pp.shape[0]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.cond(M_pp_reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.cond(M_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.matshow((M_pp_inv - M_pp_recon_inv)) \n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we try to invert the reconstructed matrix, and compare the inversion against $M_{\\bot\\bot}$ previously computed, we get different results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm not completely sure about that given that we get ~1.36 in\n",
    "# the diagonal.\n",
    "M_pp_recon_inv = np.linalg.inv(M_pp_reconstructed)\n",
    "test = M_pp_recon_inv @ M_pp\n",
    "print(test.diagonal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can to the same with all the other combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_kp_reconstructed = FK_k.T @ Cinv.to_numpy(dtype='float64') @ FK_p\n",
    "np.allclose(M_kp, M_kp_reconstructed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\tilde{H_{\\epsilon}} = D_Y^{1/2} R_Y^T (FK) \\Theta (FK)^T R_Y D_Y^{1/2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_eps_tilde = np.sqrt(D_Y) @ R_Y.T @ FK_proj @ ntk_proj @ FK_proj.T @ R_Y @ np.sqrt(D_Y)\n",
    "H_eps_tilde, (eigvals_H_eps_tilde, eigvecs_H_eps_tilde) = regularize_matrix(H_eps_tilde, tol=tol)\n",
    "\n",
    "# Check if symmetric\n",
    "print(f'Is symmetric: {np.allclose(H_eps_tilde, H_eps_tilde.T)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $b = \\Theta (FK)^T C_Y^{-1} y \\hspace{5mm} \\textrm{and} \\hspace{5mm} \\tilde{b} = D^{1/2} R^T b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = ntk @ FK.T @ Cinv.to_numpy(dtype='float64') @ Y.to_numpy('float64')\n",
    "b_tilde = np.sqrt(D) @ R.T @ b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots of the eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_eigvals(eigvals_H_eps_tilde, figsize=(10,8), title=r'$H_{\\epsilon} = D^{1/2}_Y R^T_Y (FK) \\Theta (FK)^T R_Y D^{1/2}_Y$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_eigvals(eigvals_H_tilde, \n",
    "                        figsize=(10,8), \n",
    "                        title=r'$\\tilde{H}= D^{1/2} R^T \\Theta R D^{1/2}$,  $M = RDR^T$')\n",
    "fig.savefig('../../../doc/figs/Htilde_eigvals.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_eigvals(eigvals_ntk, figsize=(10,8), title='')\n",
    "axs.set_title(r'Eigenvalues of $\\Theta$', fontsize=20)\n",
    "fig.savefig('../../../doc/figs/ntk_eigvals.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_eigvals(eigvals_M, figsize=(10,8), title=r'Eigenvalues of $M = (FK)^T C_Y^{-1} (FK)$')\n",
    "#axs.set_title(r'Eigenvalues of $\\Theta$', fontsize=20)\n",
    "#fig.savefig('../../../doc/figs/m_eigvals.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation of $f_{\\infty}$, $\\varepsilon_{\\infty}$ and evolution\n",
    "We now compute the limiting solution $f_{\\infty}$, which is the value that minimizes the loss function.\n",
    "$$\n",
    "f_{\\infty} = \\mathbf{M}_{\\bot\\bot}^{-1} (FK)_{\\bot}^T C_Y^{-1} y \\,.\n",
    "$$\n",
    "We also compute\n",
    "$$\n",
    "\\varepsilon_{\\infty} = y - (FK)_{\\bot}f_{\\infty} = \\biggl(1 - (FK)_{\\bot} \\mathbf{M}_{\\bot\\bot}^{-1} (FK)_{\\bot}^T C_Y^{-1}\\biggr) y\\,,\n",
    "$$\n",
    "together with the minimum of the loss-function\n",
    "$$\n",
    "\\mathcal{L}^{*} = \\frac{1}{2} y^T C_Y^{-1} \\varepsilon_{\\infty}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_inf = M_pp_inv @ FK_p.T @ Cinv.to_numpy(dtype='float64') @ Y.to_numpy(dtype='float64')[:,0]\n",
    "eps_inf = Y.to_numpy(dtype='float64')[:,0] - FK_p @ f_inf\n",
    "L_inf = 0.5 * Y.to_numpy(dtype='float64')[:,0].T @ Cinv.to_numpy(dtype='float64') @ eps_inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also compute the following quantity, which will be useful the description of the evolution\n",
    "$$\n",
    "\\begin{align}\n",
    "& \\tilde{\\varepsilon}_{\\infty} = D_{Y}^{1/2} \\, R_Y^T \\varepsilon_{\\infty} \\hspace{5mm} \\textrm{where} \\hspace{5mm} C_Y^{-1} = R_Y D_Y R_Y^T \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_inf_tilde = np.sqrt(D_Y) @ R_Y.T @ eps_inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check eq.(67)\n",
    "First we verify that\n",
    "$$\n",
    "   (FK)^T C_Y^{-1} (FK)_{\\bot} M_{\\bot\\bot}^{-1} = 1 \\,.\n",
    "$$\n",
    "Note that the right-most $(FK)$ is the full matrix, while $(FK)_{\\bot}$ is the one projected into the orthogonal space. To make things compatible, we need to use the same set of bases for both. If we don't do the same, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_prod = FK_p.T @ Cinv.to_numpy(dtype='float64') @ FK_p @ M_pp_inv\n",
    "wrong_prod[:wrong_prod.shape[1], :].diagonal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where we show only the square part of the product. If we instead project the $(FK)$ first, we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prod = FK_proj.T @ Cinv.to_numpy(dtype='float64') @ FK_p @ M_pp_inv\n",
    "np.allclose(np.eye(correct_prod.shape[1]), correct_prod[:correct_prod.shape[1], :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prod[:correct_prod.shape[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prod.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prod.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then check\n",
    "$$\n",
    "(FK)^T C_Y^{-1} - (FK)^T C_Y^{-1} (FK)_{\\bot} M_{\\bot\\bot}^{-1} (FK)_{\\bot}^T C_Y^{-1} = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_bit = FK_proj.T @ Cinv.to_numpy(dtype='float64')\n",
    "second_bit = FK_proj.T @ Cinv.to_numpy(dtype='float64') @ FK_p @ M_pp_inv @ FK_p.T @ Cinv.to_numpy(dtype='float64')\n",
    "test67 = second_bit - first_bit\n",
    "np.allclose(np.zeros_like(test67), test67)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check eq.(67) of the paper, that is\n",
    "$$\n",
    "\\tilde{H}_{\\varepsilon} \\, \\tilde{\\varepsilon}_{\\infty} = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = H_eps_tilde @ eps_inf_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEPRECATED\n",
    "-------------\n",
    "This part needs to be updated..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolution of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "# Construct dataframe for predictions\n",
    "Y = pd.DataFrame(np.zeros(Cinv.shape[0]), index=Cinv.index)\n",
    "for exp_name, data in central_data_dict.items():\n",
    "  if data.size == Y.loc[(slice(None), [exp_name], slice(None)), :].size:\n",
    "    Y.loc[(slice(None), [exp_name], slice(None)), :] = data\n",
    "  else:\n",
    "    raise ValueError\n",
    "  \n",
    "eps_0 = Y.to_numpy()[:,0] - FK @ f0.flatten()\n",
    "Ly = (L @ Y).to_numpy()[:,0]\n",
    "L_eps0 = L @ eps_0\n",
    "\n",
    "L_eps0_tilde = [np.dot(L_eps0, eigvecs[:,k]) for k in range(eigvecs.shape[1])]\n",
    "pre_computed_coefficients = [Linv @ eigvecs[:,k] * L_eps0_tilde[k] for k in range(eigvals_reg.size)] \n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def preds_t(t, learning_rate = 0.00001, eig_range=None):\n",
    "  if eig_range is None:\n",
    "    eig_range = eigvals_reg.size\n",
    "  predictions = [pre_computed_coefficients[k] * np.exp(-eigvals_reg[k] * learning_rate* t) for k in range(eig_range)] \n",
    "  predictions = np.sum(predictions, axis=0)\n",
    "\n",
    "  predictions = pd.DataFrame(predictions, index=Y.index)\n",
    "  predictions = Y - predictions\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = ['NMC_NC_NOTFIXED_P_EM-SIGMARED', 'SLAC_NC_NOTFIXED_P_EM-F2', 'BCDMS_NC_NOTFIXED_D_EM-F2', 'HERA_NC_318GEV_EM-SIGMARED']\n",
    "exp_titles = ['NMC', 'SLAC NC P', 'BCDMS NC D', 'HERA NC 318GEV']\n",
    "y_labels = [r'$\\sigma$', r'$F_2$', r'$F_2$', r'$\\sigma$']\n",
    "t = 0.\n",
    "fig_pred, axes_pred = plt.subplots(2, 2, figsize=(25, 25))  # Adjust figsize for desired plot size\n",
    "preds = preds_t(t, learning_rate=learning_rate_gd)\n",
    "\n",
    "scat_gf = []\n",
    "scat_gd = []\n",
    "text = []\n",
    "for i, ax in enumerate(axes_pred.flat):\n",
    "    y = Y.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "    p = preds.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "    trained_pred = pred_in_time[0][experiments[i]]\n",
    "    ax.scatter(np.arange(y.size), y, color='green', label='Central data', marker='o', s=100, alpha=0.4)\n",
    "    gf = ax.scatter(np.arange(y.size), p, color='orange', label='Analytical solution', marker='^', s=100)\n",
    "    gd = ax.scatter(np.arange(y.size), trained_pred, color='red', label='Gradient descent', marker='v', s=100)\n",
    "    scat_gf.append(gf)\n",
    "    scat_gd.append(gd)\n",
    "    #ax.set_xlabel(r'$x$')\n",
    "    ax.set_ylabel(y_labels[i], fontsize=20)\n",
    "    #ax.set_xscale('log')\n",
    "    ax.set_title(exp_titles[i], x=0.8,fontsize=20, fontweight='bold')\n",
    "    ax.legend(fontsize=20)\n",
    "    text_t = ax.text(0.05, 1.01, f't = {t}, learning rate = {learning_rate_gd}', fontsize=20, transform=ax.transAxes)\n",
    "    text.append(text_t)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "#fig.savefig('data_evolution.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = ['NMC_NC_NOTFIXED_P_EM-SIGMARED', 'SLAC_NC_NOTFIXED_P_EM-F2', 'BCDMS_NC_NOTFIXED_D_EM-F2', 'HERA_NC_318GEV_EM-SIGMARED']\n",
    "exp_titles = ['NMC', 'SLAC NC P', 'BCDMS NC D', 'HERA NC 318GEV']\n",
    "y_labels = [r'$\\sigma$', r'$F_2$', r'$F_2$', r'$\\sigma$']\n",
    "t = 0.\n",
    "fig_eps, axes_eps = plt.subplots(2, 2, figsize=(25, 25))  # Adjust figsize for desired plot size\n",
    "preds = preds_t(t, learning_rate=learning_rate_gd)\n",
    "\n",
    "scat_gf_eps = []\n",
    "scat_gd_eps = []\n",
    "text_eps = []\n",
    "for i, ax in enumerate(axes_eps.flat):\n",
    "    y = Y.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "    p = y - preds.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "    trained_pred = y[:,0] - pred_in_time[int(t)][experiments[i]].numpy()\n",
    "    ax.scatter(np.arange(y.size), y, color='green', label='Central data', marker='o', s=100, alpha=0.4)\n",
    "    gf = ax.scatter(np.arange(y.size), p, color='orange', label='Analytical solution', marker='^', s=100)\n",
    "    gd = ax.scatter(np.arange(y.size), trained_pred, color='red', label='Gradient descent', marker='v', s=100)\n",
    "    scat_gf_eps.append(gf)\n",
    "    scat_gd_eps.append(gd)\n",
    "    #ax.set_xlabel(r'$x$')\n",
    "    ax.set_ylabel(r'$\\epsilon$', fontsize=20)\n",
    "    #ax.set_xscale('log')\n",
    "    ax.set_title(exp_titles[i], x=0.8,fontsize=20, fontweight='bold')\n",
    "    ax.legend(fontsize=20)\n",
    "    text_t = ax.text(0.05, 1.01, f't = {t}, learning rate = {learning_rate_gd}', fontsize=20, transform=ax.transAxes)\n",
    "    text_eps.append(text_t)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "#fig.savefig('data_evolution.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_analytical(t, eig_range=None):\n",
    "  preds = preds_t(t, learning_rate=learning_rate_gd, eig_range=eig_range)\n",
    "  loss = 0\n",
    "  ndata = 0\n",
    "  for exp in Y.index.get_level_values('dataset').unique():\n",
    "    y = Y.xs(level='dataset', key=exp).to_numpy()\n",
    "    Cinv_exp = Cinv.xs(level=\"dataset\", key=exp).T.xs(level=\"dataset\", key=exp).to_numpy()\n",
    "    p = preds.xs(level='dataset', key=exp).to_numpy()\n",
    "    R = y[:,0] - p[:,0]\n",
    "    loss += 0.5 * R.T @ Cinv_exp @ R\n",
    "    ndata += Cinv_exp.shape[0]\n",
    "  return float(loss) / ndata\n",
    "\n",
    "def compute_loss_gd(t):\n",
    "  preds = pred_in_time[int(t)]\n",
    "  loss = 0\n",
    "  ndata = 0\n",
    "  for exp, pred in preds.items():\n",
    "    y = Y.xs(level='dataset', key=exp).to_numpy()\n",
    "    Cinv_exp = tf.convert_to_tensor(Cinv.xs(level=\"dataset\", key=exp).T.xs(level=\"dataset\", key=exp).to_numpy(), name=f'Cinv_{exp}', dtype='float32')\n",
    "    R = tf.convert_to_tensor(y[:,0] - pred, name=f'residue_{exp}', dtype='float32')\n",
    "    Cinv_R = tf.linalg.matvec(Cinv_exp, R)\n",
    "    loss += 0.5 * tf.reduce_sum(tf.multiply(R, Cinv_R))\n",
    "    ndata += Cinv_exp.shape[0]\n",
    "  return float(loss) / ndata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps_high = np.arange(1000,len(pred_in_time),1000)\n",
    "time_steps_low = np.arange(0,1000,2)\n",
    "time_steps = np.concatenate([time_steps_low, time_steps_high])\n",
    "aloss = [compute_loss_analytical(t, eig_range=100) for t in time_steps]\n",
    "gd_loss = [compute_loss_gd(t) for t in time_steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_loss, ax_loss = plt.subplots(figsize=(10, 7))  # Adjust figsize for desired plot size\n",
    "\n",
    "ax_loss.scatter(time_steps, aloss, label='Analytical solution')\n",
    "ax_loss.scatter(time_steps, gd_loss, label='Gradient descent')\n",
    "ax_loss.set_xlabel(r'$t$')\n",
    "ax_loss.set_ylabel(r'Loss function', fontsize=20)\n",
    "ax_loss.set_xscale('symlog')\n",
    "ax_loss.set_title('MSE in function of training time', x=0.5, fontsize=20, fontweight='bold')\n",
    "ax_loss.legend(fontsize=20)\n",
    "#text_t = ax.text(0.05, 1.01, f't = {t}, learning rate = {learning_rate_gd}', fontsize=20, transform=ax.transAxes)\n",
    "#text.append(text_t)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "fig_loss.savefig('Loss_function_time.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "import matplotlib\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "\n",
    "# Animation function\n",
    "# Update function for predicitons\n",
    "def update_preds(t):\n",
    "    preds = preds_t(t, learning_rate=learning_rate_gd)\n",
    "    for i, (gf, gd, text_t) in enumerate(zip(scat_gf, scat_gd, text)):\n",
    "        # Update the y-data for each subplot's line\n",
    "        y = Y.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "        p = preds.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "        trained_pred = pred_in_time[int(t)][experiments[i]]\n",
    "        data_gf = np.hstack(( np.arange(y.size)[:, np.newaxis] , p))\n",
    "        data_gd = np.hstack(( np.arange(y.size)[:, np.newaxis] , trained_pred[:,np.newaxis]))\n",
    "        gf.set_offsets(data_gf)  # Example: Add phase shift based on t and subplot index\n",
    "        gd.set_offsets(data_gd)  # Example: Add phase shift based on t and subplot index\n",
    "        text_t.set_text(f't = {t}, learning rate = {learning_rate_gd}')\n",
    "    return scat_gf + scat_gd + text\n",
    "\n",
    "# Update function for epsilon\n",
    "def update_eps(t):\n",
    "    preds = preds_t(t, learning_rate=learning_rate_gd)\n",
    "    for i, (gf, gd, text_t) in enumerate(zip(scat_gf_eps, scat_gd_eps, text_eps)):\n",
    "        # Update the y-data for each subplot's line\n",
    "        y = Y.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "        p = preds.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "        trained_pred = pred_in_time[int(t)][experiments[i]]\n",
    "        data_gf = np.hstack(( np.arange(y.size)[:, np.newaxis] , p))\n",
    "        data_gd = np.hstack(( np.arange(y.size)[:, np.newaxis] , trained_pred[:,np.newaxis]))\n",
    "        gf.set_offsets(data_gf)  # Example: Add phase shift based on t and subplot index\n",
    "        gd.set_offsets(data_gd)  # Example: Add phase shift based on t and subplot index\n",
    "        text_t.set_text(f't = {t}, learning rate = {learning_rate_gd}')\n",
    "    return scat_gf + scat_gd + text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani_pred = FuncAnimation(fig_pred, update_preds, frames=np.arange(0, len(pred_in_time), 1000), interval=10, blit=True, cache_frame_data=False)\n",
    "ani_eps = FuncAnimation(fig_eps, update_eps, frames=np.arange(0, len(pred_in_time), 1000), interval=10, blit=True, cache_frame_data=False)\n",
    "\n",
    "# Save the animation in the background\n",
    "ani_pred.save('prediction_evolution.mp4', writer='ffmpeg', fps=20)\n",
    "ani_eps.save('epsilon_evolution.mp4', writer='ffmpeg', fps=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnpdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
