{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Keras backend\n"
     ]
    }
   ],
   "source": [
    "from validphys.api import API\n",
    "import sys\n",
    "\n",
    "# Add the path to the library folder\n",
    "sys.path.append('./lib')\n",
    "\n",
    "from utils import XGRID, build_fk_matrix, regularize_matrix\n",
    "from model import PDFmodel, generate_mse_loss\n",
    "from gen_dicts import generate_dicts\n",
    "from plot_utils import plot_eigvals\n",
    "from validphys.api import API\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 14132124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of DIS dataset\n",
    "dataset_inputs = [\n",
    "  #{'dataset': 'NMC_NC_NOTFIXED_DW_EM-F2', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'NMC_NC_NOTFIXED_P_EM-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'SLAC_NC_NOTFIXED_P_DW_EM-F2', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'SLAC_NC_NOTFIXED_D_DW_EM-F2', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'BCDMS_NC_NOTFIXED_P_DW_EM-F2', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'BCDMS_NC_NOTFIXED_D_DW_EM-F2', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'CHORUS_CC_NOTFIXED_PB_DW_NU-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'CHORUS_CC_NOTFIXED_PB_DW_NB-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'NUTEV_CC_NOTFIXED_FE_DW_NU-SIGMARED', 'cfac': ['MAS'], 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'NUTEV_CC_NOTFIXED_FE_DW_NB-SIGMARED', 'cfac': ['MAS'], 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'HERA_NC_318GEV_EM-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'HERA_NC_225GEV_EP-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'HERA_NC_251GEV_EP-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  {'dataset': 'HERA_NC_300GEV_EP-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'HERA_NC_318GEV_EP-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'HERA_CC_318GEV_EM-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'HERA_CC_318GEV_EP-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'HERA_NC_318GEV_EAVG_CHARM-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "  #{'dataset': 'HERA_NC_318GEV_EAVG_BOTTOM-SIGMARED', 'frac': 0.75, 'variant': 'legacy'},\n",
    "]\n",
    "\n",
    "# Dictionary for validphys API\n",
    "common_dict = dict(\n",
    "    dataset_inputs=dataset_inputs,\n",
    "    metadata_group=\"nnpdf31_process\",\n",
    "    use_cuts='internal',\n",
    "    datacuts={'q2min': 3.49, 'w2min': 12.5},\n",
    "    theoryid=40000000,\n",
    "    t0pdfset='NNPDF40_nnlo_as_01180',\n",
    "    use_t0=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve data from NNPDF\n",
    "groups_data = API.procs_data(**common_dict)\n",
    "tuple_of_dicts = generate_dicts(groups_data)\n",
    "fk_table_dict = tuple_of_dicts.fk_tables\n",
    "central_data_dict = tuple_of_dicts.central_data\n",
    "FK = build_fk_matrix(fk_table_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHAPDF 6.5.4 loading /opt/homebrew/Caskroom/miniconda/base/envs/nnpdf/share/LHAPDF/NNPDF40_nnlo_as_01180/NNPDF40_nnlo_as_01180_0000.dat\n",
      "NNPDF40_nnlo_as_01180 PDF set, member #0, version 1; LHAPDF ID = 331100\n"
     ]
    }
   ],
   "source": [
    "C = API.groups_covmat_no_table(**common_dict)\n",
    "\n",
    "# Serialize covmat\n",
    "C_index = C.index\n",
    "C_col = C.columns\n",
    "Cinv = np.linalg.inv(C)\n",
    "Cinv = pd.DataFrame(Cinv, index=C_index, columns=C_col)\n",
    "\n",
    "# Diagonalize covariance matric\n",
    "eigvals_Cinv, R_Y = np.linalg.eigh(Cinv)\n",
    "if eigvals_Cinv[-1] > eigvals_Cinv[0]:\n",
    "    eigvals_Cinv = eigvals_Cinv[::-1]\n",
    "    R_Y = R_Y[:,::-1]\n",
    "D_Y = np.zeros_like(R_Y)\n",
    "np.fill_diagonal(D_Y, eigvals_Cinv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dataframe for predictions\n",
    "Y = pd.DataFrame(np.zeros(Cinv.shape[0]), index=Cinv.index)\n",
    "for exp_name, data in central_data_dict.items():\n",
    "  if data.size == Y.loc[(slice(None), [exp_name], slice(None)), :].size:\n",
    "    Y.loc[(slice(None), [exp_name], slice(None)), :] = data\n",
    "  else:\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnpdf_model = PDFmodel(input=XGRID,\n",
    "                       outputs=9,\n",
    "                       architecture=[28,20],\n",
    "                       activations=['tanh', 'tanh'],\n",
    "                       kernel_initializer='RandomNormal',\n",
    "                       user_ki_args={'mean': 0.0, 'stddev': 1.0},\n",
    "                       seed=seed,\n",
    "                       dtype='float64')\n",
    "NTK = nnpdf_model.compute_ntk()\n",
    "\n",
    "# Flatten NTK\n",
    "prod = 1\n",
    "oldshape = NTK.shape\n",
    "for k in oldshape[2:]:\n",
    "    prod *= k\n",
    "NTK_flat = np.array(NTK).reshape(prod,-1)\n",
    "\n",
    "# Compute predictions at initialization\n",
    "f0 = nnpdf_model.predict(squeeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from GD training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('training.pkl', 'rb') as file:\n",
    "    results = pickle.load(file)\n",
    "\n",
    "pred_in_time = results[1]\n",
    "pdfs_in_time = results[2]\n",
    "learning_rate_gd = 0.00000001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing matrices from notes\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol = None#np.finfo(np.float64).eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $M = (FK)^T C_Y^{-1} (FK) = RDR^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = FK.T @ Cinv.to_numpy() @ FK\n",
    "M, (eigvals_M, R) = regularize_matrix(M, tol=tol)\n",
    "\n",
    "# Construct diagonal matrix\n",
    "D = np.zeros_like(R)\n",
    "np.fill_diagonal(D, eigvals_M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\tilde{H} = D^{1/2} R^T \\Theta R D^{1/2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is symmetric: True\n"
     ]
    }
   ],
   "source": [
    "ntk, (eigvals_ntk, R_ntk) = regularize_matrix(NTK_flat)\n",
    "H_tilde = np.sqrt(D) @ R.T @ ntk @ R @ np.sqrt(D)\n",
    "H_tilde, (eigvals_H_tilde, eigvecs_H_tilde) = regularize_matrix(H_tilde, tol=tol)\n",
    "\n",
    "# Check if symmetric\n",
    "print(f'Is symmetric: {np.allclose(H_tilde, H_tilde.T)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\tilde{H_{\\epsilon}} = D^{1/2} R^T \\Theta R D^{1/2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is symmetric: True\n"
     ]
    }
   ],
   "source": [
    "H_eps_tilde = np.sqrt(D_Y) @ R_Y.T @ FK @ ntk @ FK.T @ R_Y @ np.sqrt(D_Y)\n",
    "H_eps_tilde, (eigvals_H_eps_tilde, eigvecs_H_eps_tilde) = regularize_matrix(H_eps_tilde, tol=tol)\n",
    "\n",
    "# Check if symmetric\n",
    "print(f'Is symmetric: {np.allclose(H_eps_tilde, H_eps_tilde.T)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $b = \\Theta (FK)^T C_Y^{-1} y \\hspace{5mm} \\textrm{and} \\hspace{5mm} \\tilde{b} = D^{1/2} R^T b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = ntk @ FK.T @ Cinv.to_numpy(dtype='float64') @ Y.to_numpy('float64')\n",
    "b_tilde = np.sqrt(D) @ R.T @ b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots of the eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_eigvals(eigvals_H_eps_tilde, figsize=(10,8), title=r'$H_{\\epsilon} = D^{1/2}_Y R^T_Y (FK) \\Theta (FK)^T R_Y D^{1/2}_Y$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_eigvals(eigvals_H_tilde, \n",
    "                        figsize=(10,8), \n",
    "                        title=r'$\\tilde{H}= D^{1/2} R^T \\Theta R D^{1/2}$,  $M = RDR^T$')\n",
    "fig.savefig('../../../doc/figs/Htilde_eigvals.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_eigvals(eigvals_ntk, figsize=(10,8), title='')\n",
    "axs.set_title(r'Eigenvalues of $\\Theta$', fontsize=20)\n",
    "fig.savefig('../../../doc/figs/ntk_eigvals.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_eigvals(eigvals_M, figsize=(10,8), title=r'Eigenvalues of $M = (FK)^T C_Y^{-1} (FK)$')\n",
    "#axs.set_title(r'Eigenvalues of $\\Theta$', fontsize=20)\n",
    "#fig.savefig('../../../doc/figs/m_eigvals.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions for the null space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "from typing import Any, Tuple\n",
    "import numpy.typing as npt\n",
    "def null_space_eig(eigvals: npt.ArrayLike, eigvecs: npt.NDArray[np.float64], tol: float = None) -> Tuple[npt.NDArray[np.float64],npt.NDArray[np.float64]]:\n",
    "  \"\"\"\n",
    "  Compute the kernel and its orthogonal space given as set\n",
    "  of eigenvalues and eigenvectors.\n",
    "\n",
    "  The kernel space is constructed out of the eigenvectors whose eigenvalue\n",
    "  is zero. The eigenvalues are compared to tolerance. If the value is greater\n",
    "  than the tolerance, then it is considered non-zero.\n",
    "\n",
    "  The tolerance is a parameter of this function. If `tol` is not provided,\n",
    "  then it is defined as the product of the largest eigenvalue with the\n",
    "  smallest precision number given the type the of the eigenvalues.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  eigvals: array\n",
    "    List of eigenvalues that are compared to the tolerance.\n",
    "  eigvecs: NDArray\n",
    "    Matrix where the second index select the i-th eigenvector relative\n",
    "    to the i-th eigenvalue, and the first index runs over the components\n",
    "    of each eigenvector.\n",
    "  tol: float\n",
    "    The tolerance for the zero-value veto.\n",
    "\n",
    "  Return\n",
    "  ------\n",
    "  The two sets of basis vectors for the kernel and its orthogonal space. These\n",
    "  are subspaces of the original eigenspace provided as an argument. The indexing\n",
    "  follows the same as `eigvecs`.\n",
    "  \"\"\"\n",
    "  if tol is None:\n",
    "    tol = np.amax(eigvals, initial=0.) * np.finfo(eigvecs.dtype).eps\n",
    "  num = np.sum(eigvals > tol, dtype=int) # Number of non-zero eigenvalues\n",
    "  ker = eigvecs[:,num:]\n",
    "  orth = eigvecs[:,:num]\n",
    "  return ker, orth\n",
    "  \n",
    "def project_matrix(matrix, basis1, basis2=None):\n",
    "  \"\"\"\n",
    "  Project the matrix into a given basis. If two bases are given,\n",
    "  then the first basis specifies the projection of the matrix on\n",
    "  the right space, while the second basis for the left space.\n",
    "\n",
    "  In particular, the projection is computed as follows $\\delta$\n",
    "\n",
    "  ..math::\n",
    "\n",
    "    M_{i_{B_1} j_{B_2}} = \\sum_{i=1}^{dim(B_1)} \\sum_{j=1}^{dim(B_2)}\n",
    "    \\mathbf{v}_{B_2}^{(j)T} \\cdot M \\cdot \\mathbf{v}_{B_1}^{(i)}\n",
    "\n",
    "  where :math:`\\mathbf{v}_{B}^{(i)}` is the i-th vector of the basis B.\n",
    "\n",
    "  If `basis2` is not provided, then basis2 is taken to be standard basis\n",
    "  (i.e. the one specified by the identity matrix).\n",
    "\n",
    "  Note that the matrix is not required to be squared.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  matrix: NDArray\n",
    "    The matrix that is projected.\n",
    "  basis1: NDArray\n",
    "    The (right) basis on which the matrix is projected.\n",
    "  basis2: NDArray\n",
    "    The (left) basis on which the matrix is projected.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  The projection of the matrix into the bases `basis1` and, if \n",
    "  given `basis2`.\n",
    "  \"\"\"\n",
    "  if basis2 is None:\n",
    "    basis2 = np.eye(matrix.shape[0])\n",
    "\n",
    "  emb_space1 = basis1.shape[0] # Embedding space base 1\n",
    "  emb_space2 = basis2.shape[0] # Embedding space base 2\n",
    "\n",
    "  # Check if the bases are compatible with the matrix\n",
    "  if matrix.shape[0] != emb_space2 or matrix.shape[1] != emb_space1:\n",
    "    raise ValueError ('The matrix cannot be projected into the two bases.')\n",
    "\n",
    "  M_orth = basis2.T @ matrix @ basis1\n",
    "\n",
    "  return M_orth\n",
    "\n",
    "def project_vector(vector, basis):\n",
    "  \"\"\"\n",
    "  Project a vector into a given basis.\n",
    "  \"\"\"\n",
    "  basis_dim = basis.shape[1]\n",
    "  space_dim = basis.shape[0]\n",
    "  if space_dim != vector.shape[0]:\n",
    "    raise ValueError ('The matrix cannot be projected into the basis')\n",
    "  \n",
    "  res = [np.dot(vector, basis[:,i]) for i in range(basis_dim)]\n",
    "  return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null space of $M$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we compute the $\\textrm{ker}(M)$ and its orthogonal space $R(M)$. We then project the matrix $M$ into the bases specified by these two spaces. In particular, we apply\n",
    "$$\n",
    "M_{i_{B_1} j_{B_2}} = \\sum_{i=1}^{\\textrm{dim}(B_1)} \\sum_{j=1}^{\\textrm{dim}(B_2)}\n",
    "  (\\mathbf{v^{(j)}_{B_2}})^T \\cdot \\mathbf{M} \\cdot \\mathbf{v^{i}_{B_1}} \\,,\n",
    "$$\n",
    "where $\\mathbf{v^{i}_{B_1}}$ and $\\mathbf{v^{j}_{B_2}}$ are the i-th and j-th vectors of the respective bases.\n",
    "\n",
    "When we compute the null space, we need to decide the threshold for the smallest distinguishable eigenvalue. If no tolerance is provided to the `null_space_eig` function, the default option is used (see above). Otherwise, we can specify a custom tolerance based. We could choose such value by looking at Looking at the eigenvalues of the matrix $M$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 3124227.610877234\n",
      "2 : 1403346.4123894337\n",
      "3 : 456262.3827862444\n",
      "4 : 340401.9439217854\n",
      "5 : 102319.29860667068\n",
      "6 : 93976.8179045838\n",
      "7 : 74554.88176256223\n",
      "8 : 69484.39975297172\n",
      "9 : 51622.76207117798\n",
      "10 : 44115.20273963308\n",
      "11 : 26964.98519148168\n",
      "12 : 24523.92813802908\n",
      "13 : 21406.35767285666\n",
      "14 : 18843.31711000496\n",
      "15 : 15105.81877070103\n",
      "16 : 14233.550076906437\n",
      "17 : 9802.403011957502\n",
      "18 : 7818.862748033714\n",
      "19 : 6874.863591158361\n",
      "20 : 6321.4355947688855\n",
      "21 : 4579.068123341873\n",
      "22 : 3992.4358841940316\n",
      "23 : 3685.986052988177\n",
      "24 : 3261.302419655037\n",
      "25 : 3032.1264836600026\n",
      "26 : 2546.6484429102816\n",
      "27 : 2466.19058410403\n",
      "28 : 2352.981977993036\n",
      "29 : 2050.6676692003603\n",
      "30 : 1793.3076905141465\n",
      "31 : 1779.1202599261705\n",
      "32 : 1469.2583965877548\n",
      "33 : 1316.0734418302397\n",
      "34 : 1241.377452569326\n",
      "35 : 1154.7936746727905\n",
      "36 : 998.0188693045031\n",
      "37 : 872.984787007546\n",
      "38 : 742.4398080891484\n",
      "39 : 650.6481224644817\n",
      "40 : 638.3808183791541\n",
      "41 : 608.9775263694096\n",
      "42 : 490.85032813817134\n",
      "43 : 463.2992598851907\n",
      "44 : 409.8524590159997\n",
      "45 : 331.86562514553765\n",
      "46 : 321.09422620690844\n",
      "47 : 214.36020763157666\n",
      "48 : 201.5212535012305\n",
      "49 : 144.36130458180543\n",
      "50 : 131.94571648778958\n",
      "51 : 98.80964815380905\n",
      "52 : 77.63139715585258\n",
      "53 : 67.66381459180946\n",
      "54 : 38.26648783370083\n",
      "55 : 36.35788669537075\n",
      "56 : 32.69584043866045\n",
      "57 : 28.46932458582067\n",
      "58 : 22.639075095962898\n",
      "59 : 20.456610209008424\n",
      "60 : 16.261980400275693\n",
      "61 : 16.09914602772036\n",
      "62 : 14.009522133482692\n",
      "63 : 13.18219549797397\n",
      "64 : 11.161303372511714\n",
      "65 : 10.22292756873403\n",
      "66 : 9.992231955244977\n",
      "67 : 8.809943701949791\n",
      "68 : 8.384086791263492\n",
      "69 : 7.818630433607325\n",
      "70 : 7.390781429260532\n",
      "71 : 6.725638304129696\n",
      "72 : 6.24333218584393\n",
      "73 : 5.251515497333108\n",
      "74 : 5.151466154106759\n",
      "75 : 4.750585766892653\n",
      "76 : 4.29815489922992\n",
      "77 : 3.87356235930957\n",
      "78 : 3.7735360181858573\n",
      "79 : 2.7453377955441938\n",
      "80 : 2.4844080932673203\n",
      "81 : 2.4251026646184304\n",
      "82 : 1.8393389530579984\n",
      "83 : 1.7375861715149339\n",
      "84 : 1.6742885762650719\n",
      "85 : 1.6235916205009988\n",
      "86 : 1.289472598162542\n",
      "87 : 1.1668736276504494\n",
      "88 : 0.9286087458458762\n",
      "89 : 0.9168259425015146\n",
      "90 : 0.8215105930288091\n",
      "91 : 0.8114405052969043\n",
      "92 : 0.6674676910815003\n",
      "93 : 0.5994769533563337\n",
      "94 : 0.5645988815107215\n",
      "95 : 0.49751860082440136\n",
      "96 : 0.4762280075938159\n",
      "97 : 0.3292241169530552\n",
      "98 : 0.30602041747735104\n",
      "99 : 0.28283912138227146\n",
      "100 : 0.25302871028039325\n",
      "101 : 0.2447164271070242\n",
      "102 : 0.21480497198496332\n",
      "103 : 0.1992022293880717\n",
      "104 : 0.17108771259229494\n",
      "105 : 0.16634112521044347\n",
      "106 : 0.12925819534422353\n",
      "107 : 0.1136880990978801\n",
      "108 : 0.10872296186452848\n",
      "109 : 0.10443217467984295\n",
      "110 : 0.08884717438852642\n",
      "111 : 0.08616987438466205\n",
      "112 : 0.0736454153283359\n",
      "113 : 0.07057638575702707\n",
      "114 : 0.060566879832540374\n",
      "115 : 0.05589595143334948\n",
      "116 : 0.04780689829195094\n",
      "117 : 0.04521924564164151\n",
      "118 : 0.03878309486838696\n",
      "119 : 0.03639904953109098\n",
      "120 : 0.033174057449542146\n",
      "121 : 0.027269894326727523\n",
      "122 : 0.024641824405938425\n",
      "123 : 0.019191134409003135\n",
      "124 : 0.017368070340841844\n",
      "125 : 0.0168655488300847\n",
      "126 : 0.016365904817533555\n",
      "127 : 0.015012647989037632\n",
      "128 : 0.014623024165560359\n",
      "129 : 0.012976539923906124\n",
      "130 : 0.0126985126388607\n",
      "131 : 0.009318918151896196\n",
      "132 : 0.008725336751552485\n",
      "133 : 0.0071056316309646645\n",
      "134 : 0.005795205795168995\n",
      "135 : 0.005480124020993832\n",
      "136 : 0.005052905743169263\n",
      "137 : 0.004669943067066726\n",
      "138 : 0.004068783807581057\n",
      "139 : 0.0037999060790164085\n",
      "140 : 0.0034693017207255007\n",
      "141 : 0.0033352092373095\n",
      "142 : 0.002500207052926765\n",
      "143 : 0.0023797860031903166\n",
      "144 : 0.0022611918828579314\n",
      "145 : 0.0019913663578609445\n",
      "146 : 0.0018586927105172636\n",
      "147 : 0.0016813287397396091\n",
      "148 : 0.0015283661714181648\n",
      "149 : 0.0011005224518078002\n",
      "150 : 0.0009482368291183328\n",
      "151 : 0.0007953478088572636\n",
      "152 : 0.0006203903027777729\n",
      "153 : 0.0005407618011480332\n",
      "154 : 0.0005197957602901626\n",
      "155 : 0.0004630306142898249\n",
      "156 : 0.0003964851830738109\n",
      "157 : 0.00031505838621412986\n",
      "158 : 0.0002812956837020375\n",
      "159 : 0.00025158983537555636\n",
      "160 : 0.00022437005539170378\n",
      "161 : 0.00020221163394088624\n",
      "162 : 0.00018656318610701418\n",
      "163 : 0.0001722382429537229\n",
      "164 : 0.00015647331864693676\n",
      "165 : 0.00014445023734231235\n",
      "166 : 0.0001268591803759924\n",
      "167 : 0.00012211194976772667\n",
      "168 : 0.00010972262336521106\n",
      "169 : 0.00010078958229406656\n",
      "170 : 9.0258694453151e-05\n",
      "171 : 8.856271715297674e-05\n",
      "172 : 8.130104864422688e-05\n",
      "173 : 7.894150351657352e-05\n",
      "174 : 7.376144215160958e-05\n",
      "175 : 6.671208953523831e-05\n",
      "176 : 5.940952955679654e-05\n",
      "177 : 5.4108914341149e-05\n",
      "178 : 5.1816147470862494e-05\n",
      "179 : 5.028952532091187e-05\n",
      "180 : 4.781081646205895e-05\n",
      "181 : 4.3360306465396305e-05\n",
      "182 : 3.863815448534125e-05\n",
      "183 : 3.362156214831617e-05\n",
      "184 : 2.9750339321138514e-05\n",
      "185 : 2.8099498440035902e-05\n",
      "186 : 2.3503627883092458e-05\n",
      "187 : 2.2693641694504253e-05\n",
      "188 : 2.1827135104973558e-05\n",
      "189 : 1.7665995001423022e-05\n",
      "190 : 1.7341840331236022e-05\n",
      "191 : 1.538974164586587e-05\n",
      "192 : 1.4275760580591416e-05\n",
      "193 : 1.3439972431408832e-05\n",
      "194 : 1.3109543271788497e-05\n",
      "195 : 1.2388137329762747e-05\n",
      "196 : 1.0487192917527833e-05\n",
      "197 : 8.729047724638793e-06\n",
      "198 : 8.39806419366117e-06\n",
      "199 : 7.768880052939432e-06\n",
      "200 : 7.272809593269882e-06\n",
      "201 : 6.616675087445958e-06\n",
      "202 : 6.062788931036195e-06\n",
      "203 : 5.143275214866511e-06\n",
      "204 : 4.9153560455974675e-06\n",
      "205 : 4.277611444318941e-06\n",
      "206 : 3.816483581626017e-06\n",
      "207 : 3.3580814675348783e-06\n",
      "208 : 3.239479976626573e-06\n",
      "209 : 3.0503773772963726e-06\n",
      "210 : 2.554140634917525e-06\n",
      "211 : 2.0774683519498967e-06\n",
      "212 : 2.021935111742572e-06\n",
      "213 : 1.9686732959972954e-06\n",
      "214 : 1.8514123467274608e-06\n",
      "215 : 1.7452497141229898e-06\n",
      "216 : 1.674247706477422e-06\n",
      "217 : 1.5824557833940877e-06\n",
      "218 : 1.4990569091714183e-06\n",
      "219 : 1.1485009268394506e-06\n",
      "220 : 1.050990816702389e-06\n",
      "221 : 8.958820154126418e-07\n",
      "222 : 8.18429821543523e-07\n",
      "223 : 7.350283440472084e-07\n",
      "224 : 6.763582706861945e-07\n",
      "225 : 6.365077837942221e-07\n",
      "226 : 5.542979475940317e-07\n",
      "227 : 4.957882183276907e-07\n",
      "228 : 4.42196968718799e-07\n",
      "229 : 3.9277701404723963e-07\n",
      "230 : 3.7898392097138226e-07\n",
      "231 : 3.5191085308598327e-07\n",
      "232 : 2.9698794544991486e-07\n",
      "233 : 2.644469413100223e-07\n",
      "234 : 2.529617743617513e-07\n",
      "235 : 2.420888742334517e-07\n",
      "236 : 2.0606030658830563e-07\n",
      "237 : 1.9540876676436068e-07\n",
      "238 : 1.5296546516641885e-07\n",
      "239 : 1.4336945972233261e-07\n",
      "240 : 1.2884566865500333e-07\n",
      "241 : 1.0986801318762972e-07\n",
      "242 : 8.857430897889606e-08\n",
      "243 : 8.322490648029486e-08\n",
      "244 : 7.988176029801118e-08\n",
      "245 : 7.609324043955904e-08\n",
      "246 : 6.58246192935496e-08\n",
      "247 : 6.272985521179651e-08\n",
      "248 : 5.643342582602943e-08\n",
      "249 : 4.50768244679392e-08\n",
      "250 : 3.9738374523024635e-08\n",
      "251 : 3.839103197744252e-08\n",
      "252 : 3.348178386557211e-08\n",
      "253 : 3.315431220084582e-08\n",
      "254 : 2.1890141784793772e-08\n",
      "255 : 2.1186160232396833e-08\n",
      "256 : 2.0277648295702535e-08\n",
      "257 : 1.469411527197765e-08\n",
      "258 : 1.4472319654502495e-08\n",
      "259 : 1.2631190541623299e-08\n",
      "260 : 1.1488503278641755e-08\n",
      "261 : 7.518300158757699e-09\n",
      "262 : 6.448605120643156e-09\n",
      "263 : 5.162746640104472e-09\n",
      "264 : 4.477992147898882e-09\n",
      "265 : 3.664501591170287e-09\n",
      "266 : 2.8141915817115146e-09\n",
      "267 : 2.638813279774407e-09\n",
      "268 : 2.0397523182984648e-09\n",
      "269 : 1.6760206151229305e-09\n",
      "270 : 1.263548877886407e-09\n",
      "271 : 1.2377879033852779e-09\n",
      "272 : 1.00130547977235e-09\n",
      "273 : 9.320750925722287e-10\n",
      "274 : 9.076694441935425e-10\n",
      "275 : 8.804599483881122e-10\n",
      "276 : 0.0\n",
      "277 : 0.0\n",
      "278 : 0.0\n",
      "279 : 0.0\n",
      "280 : 0.0\n",
      "281 : 0.0\n",
      "282 : 0.0\n",
      "283 : 0.0\n",
      "284 : 0.0\n",
      "285 : 0.0\n",
      "286 : 0.0\n",
      "287 : 0.0\n",
      "288 : 0.0\n",
      "289 : 0.0\n",
      "290 : 0.0\n",
      "291 : 0.0\n",
      "292 : 0.0\n",
      "293 : 0.0\n",
      "294 : 0.0\n",
      "295 : 0.0\n",
      "296 : 0.0\n",
      "297 : 0.0\n",
      "298 : 0.0\n",
      "299 : 0.0\n",
      "300 : 0.0\n",
      "301 : 0.0\n",
      "302 : 0.0\n",
      "303 : 0.0\n",
      "304 : 0.0\n",
      "305 : 0.0\n",
      "306 : 0.0\n",
      "307 : 0.0\n",
      "308 : 0.0\n",
      "309 : 0.0\n",
      "310 : 0.0\n",
      "311 : 0.0\n",
      "312 : 0.0\n",
      "313 : 0.0\n",
      "314 : 0.0\n",
      "315 : 0.0\n",
      "316 : 0.0\n",
      "317 : 0.0\n",
      "318 : 0.0\n",
      "319 : 0.0\n",
      "320 : 0.0\n",
      "321 : 0.0\n",
      "322 : 0.0\n",
      "323 : 0.0\n",
      "324 : 0.0\n",
      "325 : 0.0\n",
      "326 : 0.0\n",
      "327 : 0.0\n",
      "328 : 0.0\n",
      "329 : 0.0\n",
      "330 : 0.0\n",
      "331 : 0.0\n",
      "332 : 0.0\n",
      "333 : 0.0\n",
      "334 : 0.0\n",
      "335 : 0.0\n",
      "336 : 0.0\n",
      "337 : 0.0\n",
      "338 : 0.0\n",
      "339 : 0.0\n",
      "340 : 0.0\n",
      "341 : 0.0\n",
      "342 : 0.0\n",
      "343 : 0.0\n",
      "344 : 0.0\n",
      "345 : 0.0\n",
      "346 : 0.0\n",
      "347 : 0.0\n",
      "348 : 0.0\n",
      "349 : 0.0\n",
      "350 : 0.0\n",
      "351 : 0.0\n",
      "352 : 0.0\n",
      "353 : 0.0\n",
      "354 : 0.0\n",
      "355 : 0.0\n",
      "356 : 0.0\n",
      "357 : 0.0\n",
      "358 : 0.0\n",
      "359 : 0.0\n",
      "360 : 0.0\n",
      "361 : 0.0\n",
      "362 : 0.0\n",
      "363 : 0.0\n",
      "364 : 0.0\n",
      "365 : 0.0\n",
      "366 : 0.0\n",
      "367 : 0.0\n",
      "368 : 0.0\n",
      "369 : 0.0\n",
      "370 : 0.0\n",
      "371 : 0.0\n",
      "372 : 0.0\n",
      "373 : 0.0\n",
      "374 : 0.0\n",
      "375 : 0.0\n",
      "376 : 0.0\n",
      "377 : 0.0\n",
      "378 : 0.0\n",
      "379 : 0.0\n",
      "380 : 0.0\n",
      "381 : 0.0\n",
      "382 : 0.0\n",
      "383 : 0.0\n",
      "384 : 0.0\n",
      "385 : 0.0\n",
      "386 : 0.0\n",
      "387 : 0.0\n",
      "388 : 0.0\n",
      "389 : 0.0\n",
      "390 : 0.0\n",
      "391 : 0.0\n",
      "392 : 0.0\n",
      "393 : 0.0\n",
      "394 : 0.0\n",
      "395 : 0.0\n",
      "396 : 0.0\n",
      "397 : 0.0\n",
      "398 : 0.0\n",
      "399 : 0.0\n",
      "400 : 0.0\n",
      "401 : 0.0\n",
      "402 : 0.0\n",
      "403 : 0.0\n",
      "404 : 0.0\n",
      "405 : 0.0\n",
      "406 : 0.0\n",
      "407 : 0.0\n",
      "408 : 0.0\n",
      "409 : 0.0\n",
      "410 : 0.0\n",
      "411 : 0.0\n",
      "412 : 0.0\n",
      "413 : 0.0\n",
      "414 : 0.0\n",
      "415 : 0.0\n",
      "416 : 0.0\n",
      "417 : 0.0\n",
      "418 : 0.0\n",
      "419 : 0.0\n",
      "420 : 0.0\n",
      "421 : 0.0\n",
      "422 : 0.0\n",
      "423 : 0.0\n",
      "424 : 0.0\n",
      "425 : 0.0\n",
      "426 : 0.0\n",
      "427 : 0.0\n",
      "428 : 0.0\n",
      "429 : 0.0\n",
      "430 : 0.0\n",
      "431 : 0.0\n",
      "432 : 0.0\n",
      "433 : 0.0\n",
      "434 : 0.0\n",
      "435 : 0.0\n",
      "436 : 0.0\n",
      "437 : 0.0\n",
      "438 : 0.0\n",
      "439 : 0.0\n",
      "440 : 0.0\n",
      "441 : 0.0\n",
      "442 : 0.0\n",
      "443 : 0.0\n",
      "444 : 0.0\n",
      "445 : 0.0\n",
      "446 : 0.0\n",
      "447 : 0.0\n",
      "448 : 0.0\n",
      "449 : 0.0\n",
      "450 : 0.0\n"
     ]
    }
   ],
   "source": [
    "for i, val in enumerate(eigvals_M):\n",
    "  print(f'{i+1} : {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ker_M, orth_M = null_space_eig(eigvals_M, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_pp = project_matrix(M, orth_M, orth_M)\n",
    "M_kk = project_matrix(M, ker_M, ker_M)\n",
    "M_pk = project_matrix(M, ker_M, orth_M)\n",
    "M_kp = project_matrix(M, orth_M, ker_M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the matrix $M$ is decomposed as follows\n",
    "$$\n",
    "\\mathbf{M} = \\left(\\begin{matrix}\n",
    "\\mathbf{M}_{KK} & \\mathbf{M}_{K \\bot}\\\\\n",
    "\\mathbf{M}_{\\bot K} & \\mathbf{M}_{\\bot \\bot}\\\\\n",
    "\\end{matrix} \\right) \\,.\n",
    "$$\n",
    "Note that, by definition of null space, only $M_{\\bot\\bot} \\neq 0$. The next cell checks if that is effectively true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pp ?= 0 : False\n",
      "M_kk ?= 0 : True\n",
      "M_kp ?= 0 : True\n",
      "M_pk ?= 0 : True\n"
     ]
    }
   ],
   "source": [
    "print(f'M_pp ?= 0 : {np.allclose(np.zeros_like(M_pp), M_pp)}')\n",
    "print(f'M_kk ?= 0 : {np.allclose(np.zeros_like(M_kk), M_kk)}')\n",
    "print(f'M_kp ?= 0 : {np.allclose(np.zeros_like(M_kp), M_kp)}')\n",
    "print(f'M_pk ?= 0 : {np.allclose(np.zeros_like(M_pk), M_pk)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By constructing the matrix $M_{\\bot\\bot}$, we have projected out the null modes. Hence, this matrix must be invertible. We check that in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pp_inv @ M_pp ?= Id: True\n",
      "M_pp @ M_pp_inv ?= Id: True\n"
     ]
    }
   ],
   "source": [
    "M_pp_inv = np.linalg.inv(M_pp)\n",
    "print(f'M_pp_inv @ M_pp ?= Id: {np.allclose(M_pp_inv @ M_pp, np.eye(M_pp.shape[0]))}')\n",
    "print(f'M_pp @ M_pp_inv ?= Id: {np.allclose(M_pp @ M_pp_inv, np.eye(M_pp.shape[0]))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "## Projection for FK - WIP\n",
    "The same projection should be applied to the FK tables. Note the $ker(FK) = ker(M)$ (see notes), and hence we don't need to compute the null-space of the FK tables. However, it is interesting to see that despite the two null-spaces should be the same, when we compute $ker(FK)$ numerically we obtain something different..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FK, (s_FK, vh_FK) = regularize_matrix(FK, tol=np.finfo(FK.dtype).eps * np.amax(eigvals_M, initial=0.))\n",
    "#ker_FK, orth_FK = nullspace(FK, orth_space=True, rcond=np.finfo('float64').eps * np.amax(eigvals_M, initial=0.) / np.amax(s_FK, initial=0.))\n",
    "#print(f'ker(FK): {ker_FK.shape} != ker(M): {ker_M.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two spaces are different even if we set the same relative condition number. The reason is that the function `scipy.linalg.null_space` defines the tolerance as `tol = rcond * max(s)`, where `s` are the singular values of the matrix. The order of magnitude of the highest singular value of $(FK)$ is different from the one of $M$, and this should be enough to explain the difference we observe. We should see the same answer provided we use the same tolerance for both extraction.\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to project $(FK)$ into these two spaces. Remember that $(FK)$ is a linear map from the space of PDF to the space of the data\n",
    "$$\n",
    "(FK) : \\mathbb{R}^{\\textrm{PDF}} \\longrightarrow \\mathbb{R}^{\\textrm{Data}} \\,.\n",
    "$$\n",
    "The projection is then applied to the right-space only, which is the PDF space. Hence, after projection, the $(FK)$ table can be written as\n",
    "$$\n",
    "(FK) = \\left( \\, (FK)_{K} \\hspace{5mm}  (FK)_{\\bot} \\,\\right) \\,,\n",
    "$$\n",
    "where each $(FK)_{B}$ is a linear map from PDF to data space. Note that $\\textrm{ker}(M) = \\textrm{ker}(FK)$. Thus, also in this case $(FK)_{K}$. We can check that in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FK, (s_FK, vh_FK) = regularize_matrix(FK, tol=np.finfo(FK.dtype).eps * np.amax(eigvals_M, initial=0.)/ np.amax(s_FK, initial=0.))\n",
    "FK_p = project_matrix(FK, orth_M, np.eye(FK.shape[0]))\n",
    "FK_k = project_matrix(FK, ker_M, np.eye(FK.shape[0]))\n",
    "ntk_pp = project_matrix(ntk, orth_M, orth_M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A naive comparison of the two components $(FK)_K$ and $(FK)_{\\bot}$ would not lead to the desired result, as shown in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FK_k ?= 0 : False\n",
      "FK_p ?= 0 : False\n"
     ]
    }
   ],
   "source": [
    "atol =  np.amax(eigvals_M, initial=0.) * np.finfo(eigvals_M.dtype).eps\n",
    "print(f'FK_k ?= 0 : {np.allclose(np.zeros_like(FK_k), FK_k)}')\n",
    "print(f'FK_p ?= 0 : {np.allclose(np.zeros_like(FK_p), FK_p)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason being that the tolerance used to construct $\\textrm{Ker}(M)$ and $R(M)$ was defined using the largest eigenvalue of the the matrix $M$. When we move to $(FK)$, we then need to scale the tolerance appropriately so that we have consistent results. In that case, we have $M \\sim (FK)^2$, and we could expect that $\\textrm{tol}_{FK} = \\sqrt{\\textrm{tol}_M}$. Let's try and see if we get the expected result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing with tolerance = 2.6338524741395634e-05.3f.\n",
      "FK_k ?= 0 : True\n",
      "FK_p ?= 0 : False\n"
     ]
    }
   ],
   "source": [
    "tol =  np.sqrt(np.amax(eigvals_M, initial=0.) * np.finfo(eigvals_M.dtype).eps)\n",
    "print(f'Comparing with tolerance = {tol}.')\n",
    "print(f'FK_k ?= 0 : {np.allclose(np.zeros_like(FK_k), FK_k, atol=tol)}')\n",
    "print(f'FK_p ?= 0 : {np.allclose(np.zeros_like(FK_p), FK_p, atol=tol)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As consistency check, we can verify that $(FK) \\Theta (FK)^T = (FK_{\\bot}) \\Theta_{\\bot\\bot} (FK_{\\bot})^T$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = FK_p @ ntk_pp @ FK_p.T\n",
    "test2 = FK @ ntk @ FK.T\n",
    "np.allclose(test1, test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation of $f_{\\infty}$, $\\varepsilon_{\\infty}$ and evolution\n",
    "We now compute the limiting solution $f_{\\infty}$, which is the value that minimizes the loss function.\n",
    "$$\n",
    "f_{\\infty} = \\mathbf{M}_{\\bot\\bot}^{-1} (FK)_{\\bot}^T C_Y^{-1} y \\,.\n",
    "$$\n",
    "We also compute\n",
    "$$\n",
    "\\varepsilon_{\\infty} = y - (FK)_{\\bot}f_{\\infty} = \\biggl(1 - (FK)_{\\bot} \\mathbf{M}_{\\bot\\bot}^{-1} (FK)_{\\bot}^T C_Y^{-1}\\biggr) y\\,,\n",
    "$$\n",
    "together with the minimum of the loss-function\n",
    "$$\n",
    "\\mathcal{L}^{*} = \\frac{1}{2} y^T C_Y^{-1} \\varepsilon_{\\infty}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_inf = M_pp_inv @ FK_p.T @ Cinv.to_numpy(dtype='float64') @ Y.to_numpy(dtype='float64')[:,0]\n",
    "eps_inf = Y.to_numpy(dtype='float64')[:,0] - FK_p @ f_inf\n",
    "L_inf = 0.5 * Y.to_numpy(dtype='float64')[:,0].T @ Cinv.to_numpy(dtype='float64') @ eps_inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also compute the following quantities, which will be useful the description of the evolution\n",
    "$$\n",
    "\\begin{align}\n",
    "& \\tilde{\\varepsilon}_{\\infty} = D_{Y}^{1/2} \\, R_Y^T \\varepsilon_{\\infty} \\hspace{5mm} \\textrm{where} \\hspace{5mm} C_Y^{-1} = R_Y D_Y R_Y^T \\\\\n",
    "& \\tilde{H}_{\\varepsilon} = D_{Y}^{1/2} \\, R_Y^T \\, (FK) \\, \\Theta \\, (FK)^T \\, R_Y \\, D_{Y}^{1/2}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_inf_tilde = np.sqrt(D_Y) @ R_Y.T @ eps_inf\n",
    "H_eps_tilde = np.sqrt(D_Y) @ R_Y.T @ FK @ ntk @ FK.T @ R_Y @ np.sqrt(D_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check eq.(67) of the paper, that is\n",
    "$$\n",
    "\\tilde{H}_{\\varepsilon} \\, \\tilde{\\varepsilon}_{t} = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07907211037023275"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = H_eps_tilde @ eps_inf_tilde\n",
    "np.linalg.norm(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEPRECATED\n",
    "-------------\n",
    "This part needs to be updated..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolution of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "# Construct dataframe for predictions\n",
    "Y = pd.DataFrame(np.zeros(Cinv.shape[0]), index=Cinv.index)\n",
    "for exp_name, data in central_data_dict.items():\n",
    "  if data.size == Y.loc[(slice(None), [exp_name], slice(None)), :].size:\n",
    "    Y.loc[(slice(None), [exp_name], slice(None)), :] = data\n",
    "  else:\n",
    "    raise ValueError\n",
    "  \n",
    "eps_0 = Y.to_numpy()[:,0] - FK @ f0.flatten()\n",
    "Ly = (L @ Y).to_numpy()[:,0]\n",
    "L_eps0 = L @ eps_0\n",
    "\n",
    "L_eps0_tilde = [np.dot(L_eps0, eigvecs[:,k]) for k in range(eigvecs.shape[1])]\n",
    "pre_computed_coefficients = [Linv @ eigvecs[:,k] * L_eps0_tilde[k] for k in range(eigvals_reg.size)] \n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def preds_t(t, learning_rate = 0.00001, eig_range=None):\n",
    "  if eig_range is None:\n",
    "    eig_range = eigvals_reg.size\n",
    "  predictions = [pre_computed_coefficients[k] * np.exp(-eigvals_reg[k] * learning_rate* t) for k in range(eig_range)] \n",
    "  predictions = np.sum(predictions, axis=0)\n",
    "\n",
    "  predictions = pd.DataFrame(predictions, index=Y.index)\n",
    "  predictions = Y - predictions\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = ['NMC_NC_NOTFIXED_P_EM-SIGMARED', 'SLAC_NC_NOTFIXED_P_EM-F2', 'BCDMS_NC_NOTFIXED_D_EM-F2', 'HERA_NC_318GEV_EM-SIGMARED']\n",
    "exp_titles = ['NMC', 'SLAC NC P', 'BCDMS NC D', 'HERA NC 318GEV']\n",
    "y_labels = [r'$\\sigma$', r'$F_2$', r'$F_2$', r'$\\sigma$']\n",
    "t = 0.\n",
    "fig_pred, axes_pred = plt.subplots(2, 2, figsize=(25, 25))  # Adjust figsize for desired plot size\n",
    "preds = preds_t(t, learning_rate=learning_rate_gd)\n",
    "\n",
    "scat_gf = []\n",
    "scat_gd = []\n",
    "text = []\n",
    "for i, ax in enumerate(axes_pred.flat):\n",
    "    y = Y.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "    p = preds.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "    trained_pred = pred_in_time[0][experiments[i]]\n",
    "    ax.scatter(np.arange(y.size), y, color='green', label='Central data', marker='o', s=100, alpha=0.4)\n",
    "    gf = ax.scatter(np.arange(y.size), p, color='orange', label='Analytical solution', marker='^', s=100)\n",
    "    gd = ax.scatter(np.arange(y.size), trained_pred, color='red', label='Gradient descent', marker='v', s=100)\n",
    "    scat_gf.append(gf)\n",
    "    scat_gd.append(gd)\n",
    "    #ax.set_xlabel(r'$x$')\n",
    "    ax.set_ylabel(y_labels[i], fontsize=20)\n",
    "    #ax.set_xscale('log')\n",
    "    ax.set_title(exp_titles[i], x=0.8,fontsize=20, fontweight='bold')\n",
    "    ax.legend(fontsize=20)\n",
    "    text_t = ax.text(0.05, 1.01, f't = {t}, learning rate = {learning_rate_gd}', fontsize=20, transform=ax.transAxes)\n",
    "    text.append(text_t)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "#fig.savefig('data_evolution.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = ['NMC_NC_NOTFIXED_P_EM-SIGMARED', 'SLAC_NC_NOTFIXED_P_EM-F2', 'BCDMS_NC_NOTFIXED_D_EM-F2', 'HERA_NC_318GEV_EM-SIGMARED']\n",
    "exp_titles = ['NMC', 'SLAC NC P', 'BCDMS NC D', 'HERA NC 318GEV']\n",
    "y_labels = [r'$\\sigma$', r'$F_2$', r'$F_2$', r'$\\sigma$']\n",
    "t = 0.\n",
    "fig_eps, axes_eps = plt.subplots(2, 2, figsize=(25, 25))  # Adjust figsize for desired plot size\n",
    "preds = preds_t(t, learning_rate=learning_rate_gd)\n",
    "\n",
    "scat_gf_eps = []\n",
    "scat_gd_eps = []\n",
    "text_eps = []\n",
    "for i, ax in enumerate(axes_eps.flat):\n",
    "    y = Y.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "    p = y - preds.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "    trained_pred = y[:,0] - pred_in_time[int(t)][experiments[i]].numpy()\n",
    "    ax.scatter(np.arange(y.size), y, color='green', label='Central data', marker='o', s=100, alpha=0.4)\n",
    "    gf = ax.scatter(np.arange(y.size), p, color='orange', label='Analytical solution', marker='^', s=100)\n",
    "    gd = ax.scatter(np.arange(y.size), trained_pred, color='red', label='Gradient descent', marker='v', s=100)\n",
    "    scat_gf_eps.append(gf)\n",
    "    scat_gd_eps.append(gd)\n",
    "    #ax.set_xlabel(r'$x$')\n",
    "    ax.set_ylabel(r'$\\epsilon$', fontsize=20)\n",
    "    #ax.set_xscale('log')\n",
    "    ax.set_title(exp_titles[i], x=0.8,fontsize=20, fontweight='bold')\n",
    "    ax.legend(fontsize=20)\n",
    "    text_t = ax.text(0.05, 1.01, f't = {t}, learning rate = {learning_rate_gd}', fontsize=20, transform=ax.transAxes)\n",
    "    text_eps.append(text_t)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "#fig.savefig('data_evolution.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_analytical(t, eig_range=None):\n",
    "  preds = preds_t(t, learning_rate=learning_rate_gd, eig_range=eig_range)\n",
    "  loss = 0\n",
    "  ndata = 0\n",
    "  for exp in Y.index.get_level_values('dataset').unique():\n",
    "    y = Y.xs(level='dataset', key=exp).to_numpy()\n",
    "    Cinv_exp = Cinv.xs(level=\"dataset\", key=exp).T.xs(level=\"dataset\", key=exp).to_numpy()\n",
    "    p = preds.xs(level='dataset', key=exp).to_numpy()\n",
    "    R = y[:,0] - p[:,0]\n",
    "    loss += 0.5 * R.T @ Cinv_exp @ R\n",
    "    ndata += Cinv_exp.shape[0]\n",
    "  return float(loss) / ndata\n",
    "\n",
    "def compute_loss_gd(t):\n",
    "  preds = pred_in_time[int(t)]\n",
    "  loss = 0\n",
    "  ndata = 0\n",
    "  for exp, pred in preds.items():\n",
    "    y = Y.xs(level='dataset', key=exp).to_numpy()\n",
    "    Cinv_exp = tf.convert_to_tensor(Cinv.xs(level=\"dataset\", key=exp).T.xs(level=\"dataset\", key=exp).to_numpy(), name=f'Cinv_{exp}', dtype='float32')\n",
    "    R = tf.convert_to_tensor(y[:,0] - pred, name=f'residue_{exp}', dtype='float32')\n",
    "    Cinv_R = tf.linalg.matvec(Cinv_exp, R)\n",
    "    loss += 0.5 * tf.reduce_sum(tf.multiply(R, Cinv_R))\n",
    "    ndata += Cinv_exp.shape[0]\n",
    "  return float(loss) / ndata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps_high = np.arange(1000,len(pred_in_time),1000)\n",
    "time_steps_low = np.arange(0,1000,2)\n",
    "time_steps = np.concatenate([time_steps_low, time_steps_high])\n",
    "aloss = [compute_loss_analytical(t, eig_range=100) for t in time_steps]\n",
    "gd_loss = [compute_loss_gd(t) for t in time_steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_loss, ax_loss = plt.subplots(figsize=(10, 7))  # Adjust figsize for desired plot size\n",
    "\n",
    "ax_loss.scatter(time_steps, aloss, label='Analytical solution')\n",
    "ax_loss.scatter(time_steps, gd_loss, label='Gradient descent')\n",
    "ax_loss.set_xlabel(r'$t$')\n",
    "ax_loss.set_ylabel(r'Loss function', fontsize=20)\n",
    "ax_loss.set_xscale('symlog')\n",
    "ax_loss.set_title('MSE in function of training time', x=0.5, fontsize=20, fontweight='bold')\n",
    "ax_loss.legend(fontsize=20)\n",
    "#text_t = ax.text(0.05, 1.01, f't = {t}, learning rate = {learning_rate_gd}', fontsize=20, transform=ax.transAxes)\n",
    "#text.append(text_t)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "fig_loss.savefig('Loss_function_time.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "import matplotlib\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "\n",
    "# Animation function\n",
    "# Update function for predicitons\n",
    "def update_preds(t):\n",
    "    preds = preds_t(t, learning_rate=learning_rate_gd)\n",
    "    for i, (gf, gd, text_t) in enumerate(zip(scat_gf, scat_gd, text)):\n",
    "        # Update the y-data for each subplot's line\n",
    "        y = Y.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "        p = preds.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "        trained_pred = pred_in_time[int(t)][experiments[i]]\n",
    "        data_gf = np.hstack(( np.arange(y.size)[:, np.newaxis] , p))\n",
    "        data_gd = np.hstack(( np.arange(y.size)[:, np.newaxis] , trained_pred[:,np.newaxis]))\n",
    "        gf.set_offsets(data_gf)  # Example: Add phase shift based on t and subplot index\n",
    "        gd.set_offsets(data_gd)  # Example: Add phase shift based on t and subplot index\n",
    "        text_t.set_text(f't = {t}, learning rate = {learning_rate_gd}')\n",
    "    return scat_gf + scat_gd + text\n",
    "\n",
    "# Update function for epsilon\n",
    "def update_eps(t):\n",
    "    preds = preds_t(t, learning_rate=learning_rate_gd)\n",
    "    for i, (gf, gd, text_t) in enumerate(zip(scat_gf_eps, scat_gd_eps, text_eps)):\n",
    "        # Update the y-data for each subplot's line\n",
    "        y = Y.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "        p = preds.xs(level='dataset', key=experiments[i]).to_numpy()\n",
    "        trained_pred = pred_in_time[int(t)][experiments[i]]\n",
    "        data_gf = np.hstack(( np.arange(y.size)[:, np.newaxis] , p))\n",
    "        data_gd = np.hstack(( np.arange(y.size)[:, np.newaxis] , trained_pred[:,np.newaxis]))\n",
    "        gf.set_offsets(data_gf)  # Example: Add phase shift based on t and subplot index\n",
    "        gd.set_offsets(data_gd)  # Example: Add phase shift based on t and subplot index\n",
    "        text_t.set_text(f't = {t}, learning rate = {learning_rate_gd}')\n",
    "    return scat_gf + scat_gd + text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani_pred = FuncAnimation(fig_pred, update_preds, frames=np.arange(0, len(pred_in_time), 1000), interval=10, blit=True, cache_frame_data=False)\n",
    "ani_eps = FuncAnimation(fig_eps, update_eps, frames=np.arange(0, len(pred_in_time), 1000), interval=10, blit=True, cache_frame_data=False)\n",
    "\n",
    "# Save the animation in the background\n",
    "ani_pred.save('prediction_evolution.mp4', writer='ffmpeg', fps=20)\n",
    "ani_eps.save('epsilon_evolution.mp4', writer='ffmpeg', fps=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnpdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
